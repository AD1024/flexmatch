type List[A] {
  Cons(A, List[A]),
  Nil,
}

type Option[A] {
  Some(A),
  None,
}

type Tree[A] {
  Rose(A, List[Tree[A]]),
}

type tensor_float16_t {
  tensor_nil_float16,
  tensor0_float16(float16),
  tensor1_float16(Tensor[(?), float16]),
  tensor2_float16(Tensor[(?, ?), float16]),
  tensor3_float16(Tensor[(?, ?, ?), float16]),
  tensor4_float16(Tensor[(?, ?, ?, ?), float16]),
  tensor5_float16(Tensor[(?, ?, ?, ?, ?), float16]),
  tensor6_float16(Tensor[(?, ?, ?, ?, ?, ?), float16]),
}

type tensor_float32_t {
  tensor_nil_float32,
  tensor0_float32(float32),
  tensor1_float32(Tensor[(?), float32]),
  tensor2_float32(Tensor[(?, ?), float32]),
  tensor3_float32(Tensor[(?, ?, ?), float32]),
  tensor4_float32(Tensor[(?, ?, ?, ?), float32]),
  tensor5_float32(Tensor[(?, ?, ?, ?, ?), float32]),
  tensor6_float32(Tensor[(?, ?, ?, ?, ?, ?), float32]),
}

type tensor_float64_t {
  tensor_nil_float64,
  tensor0_float64(float64),
  tensor1_float64(Tensor[(?), float64]),
  tensor2_float64(Tensor[(?, ?), float64]),
  tensor3_float64(Tensor[(?, ?, ?), float64]),
  tensor4_float64(Tensor[(?, ?, ?, ?), float64]),
  tensor5_float64(Tensor[(?, ?, ?, ?, ?), float64]),
  tensor6_float64(Tensor[(?, ?, ?, ?, ?, ?), float64]),
}

type tensor_int16_t {
  tensor_nil_int16,
  tensor0_int16(int16),
  tensor1_int16(Tensor[(?), int16]),
  tensor2_int16(Tensor[(?, ?), int16]),
  tensor3_int16(Tensor[(?, ?, ?), int16]),
  tensor4_int16(Tensor[(?, ?, ?, ?), int16]),
  tensor5_int16(Tensor[(?, ?, ?, ?, ?), int16]),
  tensor6_int16(Tensor[(?, ?, ?, ?, ?, ?), int16]),
}

type tensor_int32_t {
  tensor_nil_int32,
  tensor0_int32(int32),
  tensor1_int32(Tensor[(?), int32]),
  tensor2_int32(Tensor[(?, ?), int32]),
  tensor3_int32(Tensor[(?, ?, ?), int32]),
  tensor4_int32(Tensor[(?, ?, ?, ?), int32]),
  tensor5_int32(Tensor[(?, ?, ?, ?, ?), int32]),
  tensor6_int32(Tensor[(?, ?, ?, ?, ?, ?), int32]),
}

type tensor_int64_t {
  tensor_nil_int64,
  tensor0_int64(int64),
  tensor1_int64(Tensor[(?), int64]),
  tensor2_int64(Tensor[(?, ?), int64]),
  tensor3_int64(Tensor[(?, ?, ?), int64]),
  tensor4_int64(Tensor[(?, ?, ?, ?), int64]),
  tensor5_int64(Tensor[(?, ?, ?, ?, ?), int64]),
  tensor6_int64(Tensor[(?, ?, ?, ?, ?, ?), int64]),
}

type tensor_int8_t {
  tensor_nil_int8,
  tensor0_int8(int8),
  tensor1_int8(Tensor[(?), int8]),
  tensor2_int8(Tensor[(?, ?), int8]),
  tensor3_int8(Tensor[(?, ?, ?), int8]),
  tensor4_int8(Tensor[(?, ?, ?, ?), int8]),
  tensor5_int8(Tensor[(?, ?, ?, ?, ?), int8]),
  tensor6_int8(Tensor[(?, ?, ?, ?, ?, ?), int8]),
}

type tensor_uint16_t {
  tensor_nil_uint16,
  tensor0_uint16(uint16),
  tensor1_uint16(Tensor[(?), uint16]),
  tensor2_uint16(Tensor[(?, ?), uint16]),
  tensor3_uint16(Tensor[(?, ?, ?), uint16]),
  tensor4_uint16(Tensor[(?, ?, ?, ?), uint16]),
  tensor5_uint16(Tensor[(?, ?, ?, ?, ?), uint16]),
  tensor6_uint16(Tensor[(?, ?, ?, ?, ?, ?), uint16]),
}

type tensor_uint8_t {
  tensor_nil_uint8,
  tensor0_uint8(uint8),
  tensor1_uint8(Tensor[(?), uint8]),
  tensor2_uint8(Tensor[(?, ?), uint8]),
  tensor3_uint8(Tensor[(?, ?, ?), uint8]),
  tensor4_uint8(Tensor[(?, ?, ?, ?), uint8]),
  tensor5_uint8(Tensor[(?, ?, ?, ?, ?), uint8]),
  tensor6_uint8(Tensor[(?, ?, ?, ?, ?, ?), uint8]),
}

def @compose[A, B, C](%f: fn (B) -> C, %g: fn (A) -> B) -> fn (A) -> C {
  fn (%x: A) -> C {
    %0 = %g(%x) /* /root/tvm/python/tvm/relay/std/prelude.rly */ /* ty=B */;
    %f(%0) /* /root/tvm/python/tvm/relay/std/prelude.rly */ /* ty=C */
  }
}

def @concat[A](%xs: List[A], %ys: List[A]) -> List[A] {
  @foldr(Cons, %ys, %xs) /* /root/tvm/python/tvm/relay/std/prelude.rly */ /* ty=List[A] */
}

def @filter[A](%f1: fn (A) -> bool, %xs1: List[A]) -> List[A] {
  match (%xs1) {
    Cons(%x1: A, %rest: List[A]) => {
      %1 = %f1(%x1) /* /root/tvm/python/tvm/relay/std/prelude.rly */ /* ty=bool */;
      if (%1) {
        %2 = @filter(%f1, %rest) /* /root/tvm/python/tvm/relay/std/prelude.rly */ /* ty=List[A] */;
        Cons(%x1, %2) /* /root/tvm/python/tvm/relay/std/prelude.rly */ /* ty=List[A] */
      } else {
        @filter(%f1, %rest) /* /root/tvm/python/tvm/relay/std/prelude.rly */ /* ty=List[A] */
      }
    },
    Nil => {
      Nil /* ty=List[A] */
    },
  }
}

def @flip[A, B, C](%f2: fn (A, B) -> C) -> fn (B, A) -> C {
  fn (%b: B, %a: A) -> C {
    %f2(%a, %b) /* /root/tvm/python/tvm/relay/std/prelude.rly */ /* ty=C */
  }
}

def @foldl[A, B](%f3: fn (A, B) -> A, %acc: A, %xs2: List[B]) -> A {
  match (%xs2) {
    Cons(%x2: B, %rest1: List[B]) => {
      %3 = %f3(%acc, %x2) /* /root/tvm/python/tvm/relay/std/prelude.rly */ /* ty=A */;
      @foldl(%f3, %3, %rest1) /* /root/tvm/python/tvm/relay/std/prelude.rly */ /* ty=A */
    },
    Nil => {
      %acc
    },
  }
}

def @foldr[A, B](%f4: fn (A, B) -> B, %acc1: B, %xs3: List[A]) -> B {
  match (%xs3) {
    Cons(%x3: A, %rest2: List[A]) => {
      %4 = @foldr(%f4, %acc1, %rest2) /* /root/tvm/python/tvm/relay/std/prelude.rly */ /* ty=B */;
      %f4(%x3, %4) /* /root/tvm/python/tvm/relay/std/prelude.rly */ /* ty=B */
    },
    Nil => {
      %acc1
    },
  }
}

def @foldr1[A](%f5: fn (A, A) -> A, %xs4: List[A]) -> A {
  match? (%xs4) {
    Cons(%x4: A, Nil) => {
      %x4
    },
    Cons(%x5: A, %rest3: List[A]) => {
      %5 = @foldr1(%f5, %rest3) /* /root/tvm/python/tvm/relay/std/prelude.rly */ /* ty=A */;
      %f5(%x5, %5) /* /root/tvm/python/tvm/relay/std/prelude.rly */ /* ty=A */
    },
  }
}

def @hd[A](%xs5: List[A]) -> A {
  match? (%xs5) {
    Cons(%x6: A, _) => {
      %x6
    },
  }
}

def @id[A](%x7: A) -> A {
  %x7
}

def @iterate[A](%f6: fn (A) -> A, %n: int32) -> fn (A) -> A {
  %6 = equal(%n, 0 /* ty=int32 */) /* /root/tvm/python/tvm/relay/std/prelude.rly */ /* ty=bool */;
  if (%6) {
    @id
  } else {
    %7 = subtract(%n, 1 /* ty=int32 */) /* /root/tvm/python/tvm/relay/std/prelude.rly */ /* ty=int32 */;
    %8 = @iterate(%f6, %7) /* /root/tvm/python/tvm/relay/std/prelude.rly */ /* ty=fn (A) -> A */;
    @compose(%f6, %8) /* /root/tvm/python/tvm/relay/std/prelude.rly */ /* ty=fn (A) -> A */
  }
}

def @length[A](%xs6: List[A]) -> int32 {
  match (%xs6) {
    Cons(_, %rest4: List[A]) => {
      %9 = @length(%rest4) /* /root/tvm/python/tvm/relay/std/prelude.rly */ /* ty=int32 */;
      add(1 /* ty=int32 */, %9) /* /root/tvm/python/tvm/relay/std/prelude.rly */ /* ty=int32 */
    },
    Nil => {
      0 /* ty=int32 */
    },
  }
}

def @main(%input_tensor: Tensor[(?, 224, 224, 3), float32], %resnet_model/conv2d/kernel: Tensor[(7, 7, 3, 64), float32], %resnet_model/batch_normalization/gamma: Tensor[(64), float32], %resnet_model/batch_normalization/beta: Tensor[(64), float32], %resnet_model/batch_normalization/moving_mean: Tensor[(64), float32], %resnet_model/batch_normalization/moving_variance: Tensor[(64), float32], %resnet_model/conv2d_2/kernel: Tensor[(1, 1, 64, 64), float32], %resnet_model/batch_normalization_2/gamma: Tensor[(64), float32], %resnet_model/batch_normalization_2/beta: Tensor[(64), float32], %resnet_model/batch_normalization_2/moving_mean: Tensor[(64), float32], %resnet_model/batch_normalization_2/moving_variance: Tensor[(64), float32], %resnet_model/conv2d_3/kernel: Tensor[(3, 3, 64, 64), float32], %resnet_model/batch_normalization_3/gamma: Tensor[(64), float32], %resnet_model/batch_normalization_3/beta: Tensor[(64), float32], %resnet_model/batch_normalization_3/moving_mean: Tensor[(64), float32], %resnet_model/batch_normalization_3/moving_variance: Tensor[(64), float32], %resnet_model/conv2d_4/kernel: Tensor[(1, 1, 64, 256), float32], %resnet_model/batch_normalization_4/gamma: Tensor[(256), float32], %resnet_model/batch_normalization_4/beta: Tensor[(256), float32], %resnet_model/batch_normalization_4/moving_mean: Tensor[(256), float32], %resnet_model/batch_normalization_4/moving_variance: Tensor[(256), float32], %resnet_model/conv2d_1/kernel: Tensor[(1, 1, 64, 256), float32], %resnet_model/batch_normalization_1/gamma: Tensor[(256), float32], %resnet_model/batch_normalization_1/beta: Tensor[(256), float32], %resnet_model/batch_normalization_1/moving_mean: Tensor[(256), float32], %resnet_model/batch_normalization_1/moving_variance: Tensor[(256), float32], %resnet_model/conv2d_5/kernel: Tensor[(1, 1, 256, 64), float32], %resnet_model/batch_normalization_5/gamma: Tensor[(64), float32], %resnet_model/batch_normalization_5/beta: Tensor[(64), float32], %resnet_model/batch_normalization_5/moving_mean: Tensor[(64), float32], %resnet_model/batch_normalization_5/moving_variance: Tensor[(64), float32], %resnet_model/conv2d_6/kernel: Tensor[(3, 3, 64, 64), float32], %resnet_model/batch_normalization_6/gamma: Tensor[(64), float32], %resnet_model/batch_normalization_6/beta: Tensor[(64), float32], %resnet_model/batch_normalization_6/moving_mean: Tensor[(64), float32], %resnet_model/batch_normalization_6/moving_variance: Tensor[(64), float32], %resnet_model/conv2d_7/kernel: Tensor[(1, 1, 64, 256), float32], %resnet_model/batch_normalization_7/gamma: Tensor[(256), float32], %resnet_model/batch_normalization_7/beta: Tensor[(256), float32], %resnet_model/batch_normalization_7/moving_mean: Tensor[(256), float32], %resnet_model/batch_normalization_7/moving_variance: Tensor[(256), float32], %resnet_model/conv2d_8/kernel: Tensor[(1, 1, 256, 64), float32], %resnet_model/batch_normalization_8/gamma: Tensor[(64), float32], %resnet_model/batch_normalization_8/beta: Tensor[(64), float32], %resnet_model/batch_normalization_8/moving_mean: Tensor[(64), float32], %resnet_model/batch_normalization_8/moving_variance: Tensor[(64), float32], %resnet_model/conv2d_9/kernel: Tensor[(3, 3, 64, 64), float32], %resnet_model/batch_normalization_9/gamma: Tensor[(64), float32], %resnet_model/batch_normalization_9/beta: Tensor[(64), float32], %resnet_model/batch_normalization_9/moving_mean: Tensor[(64), float32], %resnet_model/batch_normalization_9/moving_variance: Tensor[(64), float32], %resnet_model/conv2d_10/kernel: Tensor[(1, 1, 64, 256), float32], %resnet_model/batch_normalization_10/gamma: Tensor[(256), float32], %resnet_model/batch_normalization_10/beta: Tensor[(256), float32], %resnet_model/batch_normalization_10/moving_mean: Tensor[(256), float32], %resnet_model/batch_normalization_10/moving_variance: Tensor[(256), float32], %resnet_model/conv2d_12/kernel: Tensor[(1, 1, 256, 128), float32], %resnet_model/batch_normalization_12/gamma: Tensor[(128), float32], %resnet_model/batch_normalization_12/beta: Tensor[(128), float32], %resnet_model/batch_normalization_12/moving_mean: Tensor[(128), float32], %resnet_model/batch_normalization_12/moving_variance: Tensor[(128), float32], %resnet_model/conv2d_13/kernel: Tensor[(3, 3, 128, 128), float32], %resnet_model/batch_normalization_13/gamma: Tensor[(128), float32], %resnet_model/batch_normalization_13/beta: Tensor[(128), float32], %resnet_model/batch_normalization_13/moving_mean: Tensor[(128), float32], %resnet_model/batch_normalization_13/moving_variance: Tensor[(128), float32], %resnet_model/conv2d_14/kernel: Tensor[(1, 1, 128, 512), float32], %resnet_model/batch_normalization_14/gamma: Tensor[(512), float32], %resnet_model/batch_normalization_14/beta: Tensor[(512), float32], %resnet_model/batch_normalization_14/moving_mean: Tensor[(512), float32], %resnet_model/batch_normalization_14/moving_variance: Tensor[(512), float32], %resnet_model/conv2d_11/kernel: Tensor[(1, 1, 256, 512), float32], %resnet_model/batch_normalization_11/gamma: Tensor[(512), float32], %resnet_model/batch_normalization_11/beta: Tensor[(512), float32], %resnet_model/batch_normalization_11/moving_mean: Tensor[(512), float32], %resnet_model/batch_normalization_11/moving_variance: Tensor[(512), float32], %resnet_model/conv2d_15/kernel: Tensor[(1, 1, 512, 128), float32], %resnet_model/batch_normalization_15/gamma: Tensor[(128), float32], %resnet_model/batch_normalization_15/beta: Tensor[(128), float32], %resnet_model/batch_normalization_15/moving_mean: Tensor[(128), float32], %resnet_model/batch_normalization_15/moving_variance: Tensor[(128), float32], %resnet_model/conv2d_16/kernel: Tensor[(3, 3, 128, 128), float32], %resnet_model/batch_normalization_16/gamma: Tensor[(128), float32], %resnet_model/batch_normalization_16/beta: Tensor[(128), float32], %resnet_model/batch_normalization_16/moving_mean: Tensor[(128), float32], %resnet_model/batch_normalization_16/moving_variance: Tensor[(128), float32], %resnet_model/conv2d_17/kernel: Tensor[(1, 1, 128, 512), float32], %resnet_model/batch_normalization_17/gamma: Tensor[(512), float32], %resnet_model/batch_normalization_17/beta: Tensor[(512), float32], %resnet_model/batch_normalization_17/moving_mean: Tensor[(512), float32], %resnet_model/batch_normalization_17/moving_variance: Tensor[(512), float32], %resnet_model/conv2d_18/kernel: Tensor[(1, 1, 512, 128), float32], %resnet_model/batch_normalization_18/gamma: Tensor[(128), float32], %resnet_model/batch_normalization_18/beta: Tensor[(128), float32], %resnet_model/batch_normalization_18/moving_mean: Tensor[(128), float32], %resnet_model/batch_normalization_18/moving_variance: Tensor[(128), float32], %resnet_model/conv2d_19/kernel: Tensor[(3, 3, 128, 128), float32], %resnet_model/batch_normalization_19/gamma: Tensor[(128), float32], %resnet_model/batch_normalization_19/beta: Tensor[(128), float32], %resnet_model/batch_normalization_19/moving_mean: Tensor[(128), float32], %resnet_model/batch_normalization_19/moving_variance: Tensor[(128), float32], %resnet_model/conv2d_20/kernel: Tensor[(1, 1, 128, 512), float32], %resnet_model/batch_normalization_20/gamma: Tensor[(512), float32], %resnet_model/batch_normalization_20/beta: Tensor[(512), float32], %resnet_model/batch_normalization_20/moving_mean: Tensor[(512), float32], %resnet_model/batch_normalization_20/moving_variance: Tensor[(512), float32], %resnet_model/conv2d_21/kernel: Tensor[(1, 1, 512, 128), float32], %resnet_model/batch_normalization_21/gamma: Tensor[(128), float32], %resnet_model/batch_normalization_21/beta: Tensor[(128), float32], %resnet_model/batch_normalization_21/moving_mean: Tensor[(128), float32], %resnet_model/batch_normalization_21/moving_variance: Tensor[(128), float32], %resnet_model/conv2d_22/kernel: Tensor[(3, 3, 128, 128), float32], %resnet_model/batch_normalization_22/gamma: Tensor[(128), float32], %resnet_model/batch_normalization_22/beta: Tensor[(128), float32], %resnet_model/batch_normalization_22/moving_mean: Tensor[(128), float32], %resnet_model/batch_normalization_22/moving_variance: Tensor[(128), float32], %resnet_model/conv2d_23/kernel: Tensor[(1, 1, 128, 512), float32], %resnet_model/batch_normalization_23/gamma: Tensor[(512), float32], %resnet_model/batch_normalization_23/beta: Tensor[(512), float32], %resnet_model/batch_normalization_23/moving_mean: Tensor[(512), float32], %resnet_model/batch_normalization_23/moving_variance: Tensor[(512), float32], %resnet_model/conv2d_25/kernel: Tensor[(1, 1, 512, 256), float32], %resnet_model/batch_normalization_25/gamma: Tensor[(256), float32], %resnet_model/batch_normalization_25/beta: Tensor[(256), float32], %resnet_model/batch_normalization_25/moving_mean: Tensor[(256), float32], %resnet_model/batch_normalization_25/moving_variance: Tensor[(256), float32], %resnet_model/conv2d_26/kernel: Tensor[(3, 3, 256, 256), float32], %resnet_model/batch_normalization_26/gamma: Tensor[(256), float32], %resnet_model/batch_normalization_26/beta: Tensor[(256), float32], %resnet_model/batch_normalization_26/moving_mean: Tensor[(256), float32], %resnet_model/batch_normalization_26/moving_variance: Tensor[(256), float32], %resnet_model/conv2d_27/kernel: Tensor[(1, 1, 256, 1024), float32], %resnet_model/batch_normalization_27/gamma: Tensor[(1024), float32], %resnet_model/batch_normalization_27/beta: Tensor[(1024), float32], %resnet_model/batch_normalization_27/moving_mean: Tensor[(1024), float32], %resnet_model/batch_normalization_27/moving_variance: Tensor[(1024), float32], %resnet_model/conv2d_24/kernel: Tensor[(1, 1, 512, 1024), float32], %resnet_model/batch_normalization_24/gamma: Tensor[(1024), float32], %resnet_model/batch_normalization_24/beta: Tensor[(1024), float32], %resnet_model/batch_normalization_24/moving_mean: Tensor[(1024), float32], %resnet_model/batch_normalization_24/moving_variance: Tensor[(1024), float32], %resnet_model/conv2d_28/kernel: Tensor[(1, 1, 1024, 256), float32], %resnet_model/batch_normalization_28/gamma: Tensor[(256), float32], %resnet_model/batch_normalization_28/beta: Tensor[(256), float32], %resnet_model/batch_normalization_28/moving_mean: Tensor[(256), float32], %resnet_model/batch_normalization_28/moving_variance: Tensor[(256), float32], %resnet_model/conv2d_29/kernel: Tensor[(3, 3, 256, 256), float32], %resnet_model/batch_normalization_29/gamma: Tensor[(256), float32], %resnet_model/batch_normalization_29/beta: Tensor[(256), float32], %resnet_model/batch_normalization_29/moving_mean: Tensor[(256), float32], %resnet_model/batch_normalization_29/moving_variance: Tensor[(256), float32], %resnet_model/conv2d_30/kernel: Tensor[(1, 1, 256, 1024), float32], %resnet_model/batch_normalization_30/gamma: Tensor[(1024), float32], %resnet_model/batch_normalization_30/beta: Tensor[(1024), float32], %resnet_model/batch_normalization_30/moving_mean: Tensor[(1024), float32], %resnet_model/batch_normalization_30/moving_variance: Tensor[(1024), float32], %resnet_model/conv2d_31/kernel: Tensor[(1, 1, 1024, 256), float32], %resnet_model/batch_normalization_31/gamma: Tensor[(256), float32], %resnet_model/batch_normalization_31/beta: Tensor[(256), float32], %resnet_model/batch_normalization_31/moving_mean: Tensor[(256), float32], %resnet_model/batch_normalization_31/moving_variance: Tensor[(256), float32], %resnet_model/conv2d_32/kernel: Tensor[(3, 3, 256, 256), float32], %resnet_model/batch_normalization_32/gamma: Tensor[(256), float32], %resnet_model/batch_normalization_32/beta: Tensor[(256), float32], %resnet_model/batch_normalization_32/moving_mean: Tensor[(256), float32], %resnet_model/batch_normalization_32/moving_variance: Tensor[(256), float32], %resnet_model/conv2d_33/kernel: Tensor[(1, 1, 256, 1024), float32], %resnet_model/batch_normalization_33/gamma: Tensor[(1024), float32], %resnet_model/batch_normalization_33/beta: Tensor[(1024), float32], %resnet_model/batch_normalization_33/moving_mean: Tensor[(1024), float32], %resnet_model/batch_normalization_33/moving_variance: Tensor[(1024), float32], %resnet_model/conv2d_34/kernel: Tensor[(1, 1, 1024, 256), float32], %resnet_model/batch_normalization_34/gamma: Tensor[(256), float32], %resnet_model/batch_normalization_34/beta: Tensor[(256), float32], %resnet_model/batch_normalization_34/moving_mean: Tensor[(256), float32], %resnet_model/batch_normalization_34/moving_variance: Tensor[(256), float32], %resnet_model/conv2d_35/kernel: Tensor[(3, 3, 256, 256), float32], %resnet_model/batch_normalization_35/gamma: Tensor[(256), float32], %resnet_model/batch_normalization_35/beta: Tensor[(256), float32], %resnet_model/batch_normalization_35/moving_mean: Tensor[(256), float32], %resnet_model/batch_normalization_35/moving_variance: Tensor[(256), float32], %resnet_model/conv2d_36/kernel: Tensor[(1, 1, 256, 1024), float32], %resnet_model/batch_normalization_36/gamma: Tensor[(1024), float32], %resnet_model/batch_normalization_36/beta: Tensor[(1024), float32], %resnet_model/batch_normalization_36/moving_mean: Tensor[(1024), float32], %resnet_model/batch_normalization_36/moving_variance: Tensor[(1024), float32], %resnet_model/conv2d_37/kernel: Tensor[(1, 1, 1024, 256), float32], %resnet_model/batch_normalization_37/gamma: Tensor[(256), float32], %resnet_model/batch_normalization_37/beta: Tensor[(256), float32], %resnet_model/batch_normalization_37/moving_mean: Tensor[(256), float32], %resnet_model/batch_normalization_37/moving_variance: Tensor[(256), float32], %resnet_model/conv2d_38/kernel: Tensor[(3, 3, 256, 256), float32], %resnet_model/batch_normalization_38/gamma: Tensor[(256), float32], %resnet_model/batch_normalization_38/beta: Tensor[(256), float32], %resnet_model/batch_normalization_38/moving_mean: Tensor[(256), float32], %resnet_model/batch_normalization_38/moving_variance: Tensor[(256), float32], %resnet_model/conv2d_39/kernel: Tensor[(1, 1, 256, 1024), float32], %resnet_model/batch_normalization_39/gamma: Tensor[(1024), float32], %resnet_model/batch_normalization_39/beta: Tensor[(1024), float32], %resnet_model/batch_normalization_39/moving_mean: Tensor[(1024), float32], %resnet_model/batch_normalization_39/moving_variance: Tensor[(1024), float32], %resnet_model/conv2d_40/kernel: Tensor[(1, 1, 1024, 256), float32], %resnet_model/batch_normalization_40/gamma: Tensor[(256), float32], %resnet_model/batch_normalization_40/beta: Tensor[(256), float32], %resnet_model/batch_normalization_40/moving_mean: Tensor[(256), float32], %resnet_model/batch_normalization_40/moving_variance: Tensor[(256), float32], %resnet_model/conv2d_41/kernel: Tensor[(3, 3, 256, 256), float32], %resnet_model/batch_normalization_41/gamma: Tensor[(256), float32], %resnet_model/batch_normalization_41/beta: Tensor[(256), float32], %resnet_model/batch_normalization_41/moving_mean: Tensor[(256), float32], %resnet_model/batch_normalization_41/moving_variance: Tensor[(256), float32], %resnet_model/conv2d_42/kernel: Tensor[(1, 1, 256, 1024), float32], %resnet_model/batch_normalization_42/gamma: Tensor[(1024), float32], %resnet_model/batch_normalization_42/beta: Tensor[(1024), float32], %resnet_model/batch_normalization_42/moving_mean: Tensor[(1024), float32], %resnet_model/batch_normalization_42/moving_variance: Tensor[(1024), float32], %resnet_model/conv2d_44/kernel: Tensor[(1, 1, 1024, 512), float32], %resnet_model/batch_normalization_44/gamma: Tensor[(512), float32], %resnet_model/batch_normalization_44/beta: Tensor[(512), float32], %resnet_model/batch_normalization_44/moving_mean: Tensor[(512), float32], %resnet_model/batch_normalization_44/moving_variance: Tensor[(512), float32], %resnet_model/conv2d_45/kernel: Tensor[(3, 3, 512, 512), float32], %resnet_model/batch_normalization_45/gamma: Tensor[(512), float32], %resnet_model/batch_normalization_45/beta: Tensor[(512), float32], %resnet_model/batch_normalization_45/moving_mean: Tensor[(512), float32], %resnet_model/batch_normalization_45/moving_variance: Tensor[(512), float32], %resnet_model/conv2d_46/kernel: Tensor[(1, 1, 512, 2048), float32], %resnet_model/batch_normalization_46/gamma: Tensor[(2048), float32], %resnet_model/batch_normalization_46/beta: Tensor[(2048), float32], %resnet_model/batch_normalization_46/moving_mean: Tensor[(2048), float32], %resnet_model/batch_normalization_46/moving_variance: Tensor[(2048), float32], %resnet_model/conv2d_43/kernel: Tensor[(1, 1, 1024, 2048), float32], %resnet_model/batch_normalization_43/gamma: Tensor[(2048), float32], %resnet_model/batch_normalization_43/beta: Tensor[(2048), float32], %resnet_model/batch_normalization_43/moving_mean: Tensor[(2048), float32], %resnet_model/batch_normalization_43/moving_variance: Tensor[(2048), float32], %resnet_model/conv2d_47/kernel: Tensor[(1, 1, 2048, 512), float32], %resnet_model/batch_normalization_47/gamma: Tensor[(512), float32], %resnet_model/batch_normalization_47/beta: Tensor[(512), float32], %resnet_model/batch_normalization_47/moving_mean: Tensor[(512), float32], %resnet_model/batch_normalization_47/moving_variance: Tensor[(512), float32], %resnet_model/conv2d_48/kernel: Tensor[(3, 3, 512, 512), float32], %resnet_model/batch_normalization_48/gamma: Tensor[(512), float32], %resnet_model/batch_normalization_48/beta: Tensor[(512), float32], %resnet_model/batch_normalization_48/moving_mean: Tensor[(512), float32], %resnet_model/batch_normalization_48/moving_variance: Tensor[(512), float32], %resnet_model/conv2d_49/kernel: Tensor[(1, 1, 512, 2048), float32], %resnet_model/batch_normalization_49/gamma: Tensor[(2048), float32], %resnet_model/batch_normalization_49/beta: Tensor[(2048), float32], %resnet_model/batch_normalization_49/moving_mean: Tensor[(2048), float32], %resnet_model/batch_normalization_49/moving_variance: Tensor[(2048), float32], %resnet_model/conv2d_50/kernel: Tensor[(1, 1, 2048, 512), float32], %resnet_model/batch_normalization_50/gamma: Tensor[(512), float32], %resnet_model/batch_normalization_50/beta: Tensor[(512), float32], %resnet_model/batch_normalization_50/moving_mean: Tensor[(512), float32], %resnet_model/batch_normalization_50/moving_variance: Tensor[(512), float32], %resnet_model/conv2d_51/kernel: Tensor[(3, 3, 512, 512), float32], %resnet_model/batch_normalization_51/gamma: Tensor[(512), float32], %resnet_model/batch_normalization_51/beta: Tensor[(512), float32], %resnet_model/batch_normalization_51/moving_mean: Tensor[(512), float32], %resnet_model/batch_normalization_51/moving_variance: Tensor[(512), float32], %resnet_model/conv2d_52/kernel: Tensor[(1, 1, 512, 2048), float32], %resnet_model/batch_normalization_52/gamma: Tensor[(2048), float32], %resnet_model/batch_normalization_52/beta: Tensor[(2048), float32], %resnet_model/batch_normalization_52/moving_mean: Tensor[(2048), float32], %resnet_model/batch_normalization_52/moving_variance: Tensor[(2048), float32], %resnet_model/dense/kernel: Tensor[(2048, 1001), float32], %resnet_model/dense/bias: Tensor[(1001), float32]) -> Tensor[(?, 1001), float32] {
  %10 = nn.pad(%input_tensor, 0 /* ty=int32 */, pad_width=[[0, 0], [3, 3], [3, 3], [0, 0]]) /* resnet_model/Pad */ /* ty=Tensor[(?, 230, 230, 3), float32] */;
  %11 = add(%resnet_model/batch_normalization/moving_variance, 1.001e-05f /* ty=float32 */) /* ty=Tensor[(64), float32] */;
  %12 = sqrt(%11) /* ty=Tensor[(64), float32] */;
  %13 = divide(1f /* ty=float32 */, %12) /* ty=Tensor[(64), float32] */;
  %14 = nn.conv2d(%10, %resnet_model/conv2d/kernel, strides=[2, 2], padding=[0, 0, 0, 0], channels=64, kernel_size=[7, 7], data_layout="NHWC", kernel_layout="HWIO") /* resnet_model/conv2d/Conv2D */ /* ty=Tensor[(?, 112, 112, 64), float32] */;
  %15 = multiply(%13, %resnet_model/batch_normalization/gamma) /* ty=Tensor[(64), float32] */;
  %16 = negative(%resnet_model/batch_normalization/moving_mean) /* ty=Tensor[(64), float32] */;
  %17 = multiply(%16, %15) /* ty=Tensor[(64), float32] */;
  %18 = multiply(%14, %15) /* ty=Tensor[(?, 112, 112, 64), float32] */;
  %19 = add(%17, %resnet_model/batch_normalization/beta) /* ty=Tensor[(64), float32] */;
  %20 = add(%18, %19) /* ty=Tensor[(?, 112, 112, 64), float32] */;
  %21 = nn.relu(%20) /* resnet_model/Relu */ /* ty=Tensor[(?, 112, 112, 64), float32] */;
  %22 = nn.max_pool2d(%21, pool_size=[3, 3], strides=[2, 2], padding=[0, 0, 1, 1], layout="NHWC") /* resnet_model/max_pooling2d/MaxPool */ /* ty=Tensor[(?, 56, 56, 64), float32] */;
  %23 = add(%resnet_model/batch_normalization_2/moving_variance, 1.001e-05f /* ty=float32 */) /* ty=Tensor[(64), float32] */;
  %24 = sqrt(%23) /* ty=Tensor[(64), float32] */;
  %25 = divide(1f /* ty=float32 */, %24) /* ty=Tensor[(64), float32] */;
  %26 = nn.conv2d(%22, %resnet_model/conv2d_2/kernel, padding=[0, 0, 0, 0], channels=64, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO") /* resnet_model/conv2d_2/Conv2D */ /* ty=Tensor[(?, 56, 56, 64), float32] */;
  %27 = multiply(%25, %resnet_model/batch_normalization_2/gamma) /* ty=Tensor[(64), float32] */;
  %28 = negative(%resnet_model/batch_normalization_2/moving_mean) /* ty=Tensor[(64), float32] */;
  %29 = multiply(%28, %27) /* ty=Tensor[(64), float32] */;
  %30 = multiply(%26, %27) /* ty=Tensor[(?, 56, 56, 64), float32] */;
  %31 = add(%29, %resnet_model/batch_normalization_2/beta) /* ty=Tensor[(64), float32] */;
  %32 = add(%30, %31) /* ty=Tensor[(?, 56, 56, 64), float32] */;
  %33 = nn.relu(%32) /* resnet_model/Relu_1 */ /* ty=Tensor[(?, 56, 56, 64), float32] */;
  %34 = add(%resnet_model/batch_normalization_3/moving_variance, 1.001e-05f /* ty=float32 */) /* ty=Tensor[(64), float32] */;
  %35 = sqrt(%34) /* ty=Tensor[(64), float32] */;
  %36 = divide(1f /* ty=float32 */, %35) /* ty=Tensor[(64), float32] */;
  %37 = nn.conv2d(%33, %resnet_model/conv2d_3/kernel, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWIO") /* resnet_model/conv2d_3/Conv2D */ /* ty=Tensor[(?, 56, 56, 64), float32] */;
  %38 = multiply(%36, %resnet_model/batch_normalization_3/gamma) /* ty=Tensor[(64), float32] */;
  %39 = negative(%resnet_model/batch_normalization_3/moving_mean) /* ty=Tensor[(64), float32] */;
  %40 = multiply(%39, %38) /* ty=Tensor[(64), float32] */;
  %41 = multiply(%37, %38) /* ty=Tensor[(?, 56, 56, 64), float32] */;
  %42 = add(%40, %resnet_model/batch_normalization_3/beta) /* ty=Tensor[(64), float32] */;
  %43 = add(%41, %42) /* ty=Tensor[(?, 56, 56, 64), float32] */;
  %44 = nn.relu(%43) /* resnet_model/Relu_2 */ /* ty=Tensor[(?, 56, 56, 64), float32] */;
  %45 = add(%resnet_model/batch_normalization_4/moving_variance, 1.001e-05f /* ty=float32 */) /* ty=Tensor[(256), float32] */;
  %46 = sqrt(%45) /* ty=Tensor[(256), float32] */;
  %47 = divide(1f /* ty=float32 */, %46) /* ty=Tensor[(256), float32] */;
  %48 = nn.conv2d(%44, %resnet_model/conv2d_4/kernel, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO") /* resnet_model/conv2d_4/Conv2D */ /* ty=Tensor[(?, 56, 56, 256), float32] */;
  %49 = multiply(%47, %resnet_model/batch_normalization_4/gamma) /* ty=Tensor[(256), float32] */;
  %50 = negative(%resnet_model/batch_normalization_4/moving_mean) /* ty=Tensor[(256), float32] */;
  %51 = multiply(%50, %49) /* ty=Tensor[(256), float32] */;
  %52 = multiply(%48, %49) /* ty=Tensor[(?, 56, 56, 256), float32] */;
  %53 = add(%51, %resnet_model/batch_normalization_4/beta) /* ty=Tensor[(256), float32] */;
  %54 = add(%resnet_model/batch_normalization_1/moving_variance, 1.001e-05f /* ty=float32 */) /* ty=Tensor[(256), float32] */;
  %55 = sqrt(%54) /* ty=Tensor[(256), float32] */;
  %56 = divide(1f /* ty=float32 */, %55) /* ty=Tensor[(256), float32] */;
  %57 = nn.conv2d(%22, %resnet_model/conv2d_1/kernel, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO") /* resnet_model/conv2d_1/Conv2D */ /* ty=Tensor[(?, 56, 56, 256), float32] */;
  %58 = multiply(%56, %resnet_model/batch_normalization_1/gamma) /* ty=Tensor[(256), float32] */;
  %59 = negative(%resnet_model/batch_normalization_1/moving_mean) /* ty=Tensor[(256), float32] */;
  %60 = multiply(%59, %58) /* ty=Tensor[(256), float32] */;
  %61 = multiply(%57, %58) /* ty=Tensor[(?, 56, 56, 256), float32] */;
  %62 = add(%60, %resnet_model/batch_normalization_1/beta) /* ty=Tensor[(256), float32] */;
  %63 = add(%52, %53) /* ty=Tensor[(?, 56, 56, 256), float32] */;
  %64 = add(%61, %62) /* ty=Tensor[(?, 56, 56, 256), float32] */;
  %65 = add(%63, %64) /* resnet_model/add */ /* ty=Tensor[(?, 56, 56, 256), float32] */;
  %66 = nn.relu(%65) /* resnet_model/Relu_3 */ /* ty=Tensor[(?, 56, 56, 256), float32] */;
  %67 = add(%resnet_model/batch_normalization_5/moving_variance, 1.001e-05f /* ty=float32 */) /* ty=Tensor[(64), float32] */;
  %68 = sqrt(%67) /* ty=Tensor[(64), float32] */;
  %69 = divide(1f /* ty=float32 */, %68) /* ty=Tensor[(64), float32] */;
  %70 = nn.conv2d(%66, %resnet_model/conv2d_5/kernel, padding=[0, 0, 0, 0], channels=64, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO") /* resnet_model/conv2d_5/Conv2D */ /* ty=Tensor[(?, 56, 56, 64), float32] */;
  %71 = multiply(%69, %resnet_model/batch_normalization_5/gamma) /* ty=Tensor[(64), float32] */;
  %72 = negative(%resnet_model/batch_normalization_5/moving_mean) /* ty=Tensor[(64), float32] */;
  %73 = multiply(%72, %71) /* ty=Tensor[(64), float32] */;
  %74 = multiply(%70, %71) /* ty=Tensor[(?, 56, 56, 64), float32] */;
  %75 = add(%73, %resnet_model/batch_normalization_5/beta) /* ty=Tensor[(64), float32] */;
  %76 = add(%74, %75) /* ty=Tensor[(?, 56, 56, 64), float32] */;
  %77 = nn.relu(%76) /* resnet_model/Relu_4 */ /* ty=Tensor[(?, 56, 56, 64), float32] */;
  %78 = add(%resnet_model/batch_normalization_6/moving_variance, 1.001e-05f /* ty=float32 */) /* ty=Tensor[(64), float32] */;
  %79 = sqrt(%78) /* ty=Tensor[(64), float32] */;
  %80 = divide(1f /* ty=float32 */, %79) /* ty=Tensor[(64), float32] */;
  %81 = nn.conv2d(%77, %resnet_model/conv2d_6/kernel, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWIO") /* resnet_model/conv2d_6/Conv2D */ /* ty=Tensor[(?, 56, 56, 64), float32] */;
  %82 = multiply(%80, %resnet_model/batch_normalization_6/gamma) /* ty=Tensor[(64), float32] */;
  %83 = negative(%resnet_model/batch_normalization_6/moving_mean) /* ty=Tensor[(64), float32] */;
  %84 = multiply(%83, %82) /* ty=Tensor[(64), float32] */;
  %85 = multiply(%81, %82) /* ty=Tensor[(?, 56, 56, 64), float32] */;
  %86 = add(%84, %resnet_model/batch_normalization_6/beta) /* ty=Tensor[(64), float32] */;
  %87 = add(%85, %86) /* ty=Tensor[(?, 56, 56, 64), float32] */;
  %88 = nn.relu(%87) /* resnet_model/Relu_5 */ /* ty=Tensor[(?, 56, 56, 64), float32] */;
  %89 = add(%resnet_model/batch_normalization_7/moving_variance, 1.001e-05f /* ty=float32 */) /* ty=Tensor[(256), float32] */;
  %90 = sqrt(%89) /* ty=Tensor[(256), float32] */;
  %91 = divide(1f /* ty=float32 */, %90) /* ty=Tensor[(256), float32] */;
  %92 = nn.conv2d(%88, %resnet_model/conv2d_7/kernel, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO") /* resnet_model/conv2d_7/Conv2D */ /* ty=Tensor[(?, 56, 56, 256), float32] */;
  %93 = multiply(%91, %resnet_model/batch_normalization_7/gamma) /* ty=Tensor[(256), float32] */;
  %94 = negative(%resnet_model/batch_normalization_7/moving_mean) /* ty=Tensor[(256), float32] */;
  %95 = multiply(%94, %93) /* ty=Tensor[(256), float32] */;
  %96 = multiply(%92, %93) /* ty=Tensor[(?, 56, 56, 256), float32] */;
  %97 = add(%95, %resnet_model/batch_normalization_7/beta) /* ty=Tensor[(256), float32] */;
  %98 = add(%96, %97) /* ty=Tensor[(?, 56, 56, 256), float32] */;
  %99 = add(%98, %66) /* resnet_model/add_1 */ /* ty=Tensor[(?, 56, 56, 256), float32] */;
  %100 = nn.relu(%99) /* resnet_model/Relu_6 */ /* ty=Tensor[(?, 56, 56, 256), float32] */;
  %101 = add(%resnet_model/batch_normalization_8/moving_variance, 1.001e-05f /* ty=float32 */) /* ty=Tensor[(64), float32] */;
  %102 = sqrt(%101) /* ty=Tensor[(64), float32] */;
  %103 = divide(1f /* ty=float32 */, %102) /* ty=Tensor[(64), float32] */;
  %104 = nn.conv2d(%100, %resnet_model/conv2d_8/kernel, padding=[0, 0, 0, 0], channels=64, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO") /* resnet_model/conv2d_8/Conv2D */ /* ty=Tensor[(?, 56, 56, 64), float32] */;
  %105 = multiply(%103, %resnet_model/batch_normalization_8/gamma) /* ty=Tensor[(64), float32] */;
  %106 = negative(%resnet_model/batch_normalization_8/moving_mean) /* ty=Tensor[(64), float32] */;
  %107 = multiply(%106, %105) /* ty=Tensor[(64), float32] */;
  %108 = multiply(%104, %105) /* ty=Tensor[(?, 56, 56, 64), float32] */;
  %109 = add(%107, %resnet_model/batch_normalization_8/beta) /* ty=Tensor[(64), float32] */;
  %110 = add(%108, %109) /* ty=Tensor[(?, 56, 56, 64), float32] */;
  %111 = nn.relu(%110) /* resnet_model/Relu_7 */ /* ty=Tensor[(?, 56, 56, 64), float32] */;
  %112 = add(%resnet_model/batch_normalization_9/moving_variance, 1.001e-05f /* ty=float32 */) /* ty=Tensor[(64), float32] */;
  %113 = sqrt(%112) /* ty=Tensor[(64), float32] */;
  %114 = divide(1f /* ty=float32 */, %113) /* ty=Tensor[(64), float32] */;
  %115 = nn.conv2d(%111, %resnet_model/conv2d_9/kernel, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWIO") /* resnet_model/conv2d_9/Conv2D */ /* ty=Tensor[(?, 56, 56, 64), float32] */;
  %116 = multiply(%114, %resnet_model/batch_normalization_9/gamma) /* ty=Tensor[(64), float32] */;
  %117 = negative(%resnet_model/batch_normalization_9/moving_mean) /* ty=Tensor[(64), float32] */;
  %118 = multiply(%117, %116) /* ty=Tensor[(64), float32] */;
  %119 = multiply(%115, %116) /* ty=Tensor[(?, 56, 56, 64), float32] */;
  %120 = add(%118, %resnet_model/batch_normalization_9/beta) /* ty=Tensor[(64), float32] */;
  %121 = add(%119, %120) /* ty=Tensor[(?, 56, 56, 64), float32] */;
  %122 = nn.relu(%121) /* resnet_model/Relu_8 */ /* ty=Tensor[(?, 56, 56, 64), float32] */;
  %123 = add(%resnet_model/batch_normalization_10/moving_variance, 1.001e-05f /* ty=float32 */) /* ty=Tensor[(256), float32] */;
  %124 = sqrt(%123) /* ty=Tensor[(256), float32] */;
  %125 = divide(1f /* ty=float32 */, %124) /* ty=Tensor[(256), float32] */;
  %126 = nn.conv2d(%122, %resnet_model/conv2d_10/kernel, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO") /* resnet_model/conv2d_10/Conv2D */ /* ty=Tensor[(?, 56, 56, 256), float32] */;
  %127 = multiply(%125, %resnet_model/batch_normalization_10/gamma) /* ty=Tensor[(256), float32] */;
  %128 = negative(%resnet_model/batch_normalization_10/moving_mean) /* ty=Tensor[(256), float32] */;
  %129 = multiply(%128, %127) /* ty=Tensor[(256), float32] */;
  %130 = multiply(%126, %127) /* ty=Tensor[(?, 56, 56, 256), float32] */;
  %131 = add(%129, %resnet_model/batch_normalization_10/beta) /* ty=Tensor[(256), float32] */;
  %132 = add(%130, %131) /* ty=Tensor[(?, 56, 56, 256), float32] */;
  %133 = add(%132, %100) /* resnet_model/add_2 */ /* ty=Tensor[(?, 56, 56, 256), float32] */;
  %134 = nn.relu(%133) /* resnet_model/Relu_9 */ /* ty=Tensor[(?, 56, 56, 256), float32] */;
  %135 = add(%resnet_model/batch_normalization_12/moving_variance, 1.001e-05f /* ty=float32 */) /* ty=Tensor[(128), float32] */;
  %136 = sqrt(%135) /* ty=Tensor[(128), float32] */;
  %137 = divide(1f /* ty=float32 */, %136) /* ty=Tensor[(128), float32] */;
  %138 = nn.conv2d(%134, %resnet_model/conv2d_12/kernel, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO") /* resnet_model/conv2d_12/Conv2D */ /* ty=Tensor[(?, 56, 56, 128), float32] */;
  %139 = multiply(%137, %resnet_model/batch_normalization_12/gamma) /* ty=Tensor[(128), float32] */;
  %140 = negative(%resnet_model/batch_normalization_12/moving_mean) /* ty=Tensor[(128), float32] */;
  %141 = multiply(%140, %139) /* ty=Tensor[(128), float32] */;
  %142 = multiply(%138, %139) /* ty=Tensor[(?, 56, 56, 128), float32] */;
  %143 = add(%141, %resnet_model/batch_normalization_12/beta) /* ty=Tensor[(128), float32] */;
  %144 = add(%142, %143) /* ty=Tensor[(?, 56, 56, 128), float32] */;
  %145 = nn.relu(%144) /* resnet_model/Relu_10 */ /* ty=Tensor[(?, 56, 56, 128), float32] */;
  %146 = nn.pad(%145, 0 /* ty=int32 */, pad_width=[[0, 0], [1, 1], [1, 1], [0, 0]]) /* resnet_model/Pad_2 */ /* ty=Tensor[(?, 58, 58, 128), float32] */;
  %147 = add(%resnet_model/batch_normalization_13/moving_variance, 1.001e-05f /* ty=float32 */) /* ty=Tensor[(128), float32] */;
  %148 = sqrt(%147) /* ty=Tensor[(128), float32] */;
  %149 = divide(1f /* ty=float32 */, %148) /* ty=Tensor[(128), float32] */;
  %150 = nn.conv2d(%146, %resnet_model/conv2d_13/kernel, strides=[2, 2], padding=[0, 0, 0, 0], channels=128, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWIO") /* resnet_model/conv2d_13/Conv2D */ /* ty=Tensor[(?, 28, 28, 128), float32] */;
  %151 = multiply(%149, %resnet_model/batch_normalization_13/gamma) /* ty=Tensor[(128), float32] */;
  %152 = negative(%resnet_model/batch_normalization_13/moving_mean) /* ty=Tensor[(128), float32] */;
  %153 = multiply(%152, %151) /* ty=Tensor[(128), float32] */;
  %154 = multiply(%150, %151) /* ty=Tensor[(?, 28, 28, 128), float32] */;
  %155 = add(%153, %resnet_model/batch_normalization_13/beta) /* ty=Tensor[(128), float32] */;
  %156 = add(%154, %155) /* ty=Tensor[(?, 28, 28, 128), float32] */;
  %157 = nn.relu(%156) /* resnet_model/Relu_11 */ /* ty=Tensor[(?, 28, 28, 128), float32] */;
  %158 = add(%resnet_model/batch_normalization_14/moving_variance, 1.001e-05f /* ty=float32 */) /* ty=Tensor[(512), float32] */;
  %159 = sqrt(%158) /* ty=Tensor[(512), float32] */;
  %160 = divide(1f /* ty=float32 */, %159) /* ty=Tensor[(512), float32] */;
  %161 = nn.conv2d(%157, %resnet_model/conv2d_14/kernel, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO") /* resnet_model/conv2d_14/Conv2D */ /* ty=Tensor[(?, 28, 28, 512), float32] */;
  %162 = multiply(%160, %resnet_model/batch_normalization_14/gamma) /* ty=Tensor[(512), float32] */;
  %163 = negative(%resnet_model/batch_normalization_14/moving_mean) /* ty=Tensor[(512), float32] */;
  %164 = multiply(%163, %162) /* ty=Tensor[(512), float32] */;
  %165 = multiply(%161, %162) /* ty=Tensor[(?, 28, 28, 512), float32] */;
  %166 = add(%164, %resnet_model/batch_normalization_14/beta) /* ty=Tensor[(512), float32] */;
  %167 = nn.pad(%134, 0 /* ty=int32 */, pad_width=[[0, 0], [0, 0], [0, 0], [0, 0]]) /* resnet_model/Pad_1 */ /* ty=Tensor[(?, 56, 56, 256), float32] */;
  %168 = add(%resnet_model/batch_normalization_11/moving_variance, 1.001e-05f /* ty=float32 */) /* ty=Tensor[(512), float32] */;
  %169 = sqrt(%168) /* ty=Tensor[(512), float32] */;
  %170 = divide(1f /* ty=float32 */, %169) /* ty=Tensor[(512), float32] */;
  %171 = nn.conv2d(%167, %resnet_model/conv2d_11/kernel, strides=[2, 2], padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO") /* resnet_model/conv2d_11/Conv2D */ /* ty=Tensor[(?, 28, 28, 512), float32] */;
  %172 = multiply(%170, %resnet_model/batch_normalization_11/gamma) /* ty=Tensor[(512), float32] */;
  %173 = negative(%resnet_model/batch_normalization_11/moving_mean) /* ty=Tensor[(512), float32] */;
  %174 = multiply(%173, %172) /* ty=Tensor[(512), float32] */;
  %175 = multiply(%171, %172) /* ty=Tensor[(?, 28, 28, 512), float32] */;
  %176 = add(%174, %resnet_model/batch_normalization_11/beta) /* ty=Tensor[(512), float32] */;
  %177 = add(%165, %166) /* ty=Tensor[(?, 28, 28, 512), float32] */;
  %178 = add(%175, %176) /* ty=Tensor[(?, 28, 28, 512), float32] */;
  %179 = add(%177, %178) /* resnet_model/add_3 */ /* ty=Tensor[(?, 28, 28, 512), float32] */;
  %180 = nn.relu(%179) /* resnet_model/Relu_12 */ /* ty=Tensor[(?, 28, 28, 512), float32] */;
  %181 = add(%resnet_model/batch_normalization_15/moving_variance, 1.001e-05f /* ty=float32 */) /* ty=Tensor[(128), float32] */;
  %182 = sqrt(%181) /* ty=Tensor[(128), float32] */;
  %183 = divide(1f /* ty=float32 */, %182) /* ty=Tensor[(128), float32] */;
  %184 = nn.conv2d(%180, %resnet_model/conv2d_15/kernel, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO") /* resnet_model/conv2d_15/Conv2D */ /* ty=Tensor[(?, 28, 28, 128), float32] */;
  %185 = multiply(%183, %resnet_model/batch_normalization_15/gamma) /* ty=Tensor[(128), float32] */;
  %186 = negative(%resnet_model/batch_normalization_15/moving_mean) /* ty=Tensor[(128), float32] */;
  %187 = multiply(%186, %185) /* ty=Tensor[(128), float32] */;
  %188 = multiply(%184, %185) /* ty=Tensor[(?, 28, 28, 128), float32] */;
  %189 = add(%187, %resnet_model/batch_normalization_15/beta) /* ty=Tensor[(128), float32] */;
  %190 = add(%188, %189) /* ty=Tensor[(?, 28, 28, 128), float32] */;
  %191 = nn.relu(%190) /* resnet_model/Relu_13 */ /* ty=Tensor[(?, 28, 28, 128), float32] */;
  %192 = add(%resnet_model/batch_normalization_16/moving_variance, 1.001e-05f /* ty=float32 */) /* ty=Tensor[(128), float32] */;
  %193 = sqrt(%192) /* ty=Tensor[(128), float32] */;
  %194 = divide(1f /* ty=float32 */, %193) /* ty=Tensor[(128), float32] */;
  %195 = nn.conv2d(%191, %resnet_model/conv2d_16/kernel, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWIO") /* resnet_model/conv2d_16/Conv2D */ /* ty=Tensor[(?, 28, 28, 128), float32] */;
  %196 = multiply(%194, %resnet_model/batch_normalization_16/gamma) /* ty=Tensor[(128), float32] */;
  %197 = negative(%resnet_model/batch_normalization_16/moving_mean) /* ty=Tensor[(128), float32] */;
  %198 = multiply(%197, %196) /* ty=Tensor[(128), float32] */;
  %199 = multiply(%195, %196) /* ty=Tensor[(?, 28, 28, 128), float32] */;
  %200 = add(%198, %resnet_model/batch_normalization_16/beta) /* ty=Tensor[(128), float32] */;
  %201 = add(%199, %200) /* ty=Tensor[(?, 28, 28, 128), float32] */;
  %202 = nn.relu(%201) /* resnet_model/Relu_14 */ /* ty=Tensor[(?, 28, 28, 128), float32] */;
  %203 = add(%resnet_model/batch_normalization_17/moving_variance, 1.001e-05f /* ty=float32 */) /* ty=Tensor[(512), float32] */;
  %204 = sqrt(%203) /* ty=Tensor[(512), float32] */;
  %205 = divide(1f /* ty=float32 */, %204) /* ty=Tensor[(512), float32] */;
  %206 = nn.conv2d(%202, %resnet_model/conv2d_17/kernel, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO") /* resnet_model/conv2d_17/Conv2D */ /* ty=Tensor[(?, 28, 28, 512), float32] */;
  %207 = multiply(%205, %resnet_model/batch_normalization_17/gamma) /* ty=Tensor[(512), float32] */;
  %208 = negative(%resnet_model/batch_normalization_17/moving_mean) /* ty=Tensor[(512), float32] */;
  %209 = multiply(%208, %207) /* ty=Tensor[(512), float32] */;
  %210 = multiply(%206, %207) /* ty=Tensor[(?, 28, 28, 512), float32] */;
  %211 = add(%209, %resnet_model/batch_normalization_17/beta) /* ty=Tensor[(512), float32] */;
  %212 = add(%210, %211) /* ty=Tensor[(?, 28, 28, 512), float32] */;
  %213 = add(%212, %180) /* resnet_model/add_4 */ /* ty=Tensor[(?, 28, 28, 512), float32] */;
  %214 = nn.relu(%213) /* resnet_model/Relu_15 */ /* ty=Tensor[(?, 28, 28, 512), float32] */;
  %215 = add(%resnet_model/batch_normalization_18/moving_variance, 1.001e-05f /* ty=float32 */) /* ty=Tensor[(128), float32] */;
  %216 = sqrt(%215) /* ty=Tensor[(128), float32] */;
  %217 = divide(1f /* ty=float32 */, %216) /* ty=Tensor[(128), float32] */;
  %218 = nn.conv2d(%214, %resnet_model/conv2d_18/kernel, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO") /* resnet_model/conv2d_18/Conv2D */ /* ty=Tensor[(?, 28, 28, 128), float32] */;
  %219 = multiply(%217, %resnet_model/batch_normalization_18/gamma) /* ty=Tensor[(128), float32] */;
  %220 = negative(%resnet_model/batch_normalization_18/moving_mean) /* ty=Tensor[(128), float32] */;
  %221 = multiply(%220, %219) /* ty=Tensor[(128), float32] */;
  %222 = multiply(%218, %219) /* ty=Tensor[(?, 28, 28, 128), float32] */;
  %223 = add(%221, %resnet_model/batch_normalization_18/beta) /* ty=Tensor[(128), float32] */;
  %224 = add(%222, %223) /* ty=Tensor[(?, 28, 28, 128), float32] */;
  %225 = nn.relu(%224) /* resnet_model/Relu_16 */ /* ty=Tensor[(?, 28, 28, 128), float32] */;
  %226 = add(%resnet_model/batch_normalization_19/moving_variance, 1.001e-05f /* ty=float32 */) /* ty=Tensor[(128), float32] */;
  %227 = sqrt(%226) /* ty=Tensor[(128), float32] */;
  %228 = divide(1f /* ty=float32 */, %227) /* ty=Tensor[(128), float32] */;
  %229 = nn.conv2d(%225, %resnet_model/conv2d_19/kernel, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWIO") /* resnet_model/conv2d_19/Conv2D */ /* ty=Tensor[(?, 28, 28, 128), float32] */;
  %230 = multiply(%228, %resnet_model/batch_normalization_19/gamma) /* ty=Tensor[(128), float32] */;
  %231 = negative(%resnet_model/batch_normalization_19/moving_mean) /* ty=Tensor[(128), float32] */;
  %232 = multiply(%231, %230) /* ty=Tensor[(128), float32] */;
  %233 = multiply(%229, %230) /* ty=Tensor[(?, 28, 28, 128), float32] */;
  %234 = add(%232, %resnet_model/batch_normalization_19/beta) /* ty=Tensor[(128), float32] */;
  %235 = add(%233, %234) /* ty=Tensor[(?, 28, 28, 128), float32] */;
  %236 = nn.relu(%235) /* resnet_model/Relu_17 */ /* ty=Tensor[(?, 28, 28, 128), float32] */;
  %237 = add(%resnet_model/batch_normalization_20/moving_variance, 1.001e-05f /* ty=float32 */) /* ty=Tensor[(512), float32] */;
  %238 = sqrt(%237) /* ty=Tensor[(512), float32] */;
  %239 = divide(1f /* ty=float32 */, %238) /* ty=Tensor[(512), float32] */;
  %240 = nn.conv2d(%236, %resnet_model/conv2d_20/kernel, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO") /* resnet_model/conv2d_20/Conv2D */ /* ty=Tensor[(?, 28, 28, 512), float32] */;
  %241 = multiply(%239, %resnet_model/batch_normalization_20/gamma) /* ty=Tensor[(512), float32] */;
  %242 = negative(%resnet_model/batch_normalization_20/moving_mean) /* ty=Tensor[(512), float32] */;
  %243 = multiply(%242, %241) /* ty=Tensor[(512), float32] */;
  %244 = multiply(%240, %241) /* ty=Tensor[(?, 28, 28, 512), float32] */;
  %245 = add(%243, %resnet_model/batch_normalization_20/beta) /* ty=Tensor[(512), float32] */;
  %246 = add(%244, %245) /* ty=Tensor[(?, 28, 28, 512), float32] */;
  %247 = add(%246, %214) /* resnet_model/add_5 */ /* ty=Tensor[(?, 28, 28, 512), float32] */;
  %248 = nn.relu(%247) /* resnet_model/Relu_18 */ /* ty=Tensor[(?, 28, 28, 512), float32] */;
  %249 = add(%resnet_model/batch_normalization_21/moving_variance, 1.001e-05f /* ty=float32 */) /* ty=Tensor[(128), float32] */;
  %250 = sqrt(%249) /* ty=Tensor[(128), float32] */;
  %251 = divide(1f /* ty=float32 */, %250) /* ty=Tensor[(128), float32] */;
  %252 = nn.conv2d(%248, %resnet_model/conv2d_21/kernel, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO") /* resnet_model/conv2d_21/Conv2D */ /* ty=Tensor[(?, 28, 28, 128), float32] */;
  %253 = multiply(%251, %resnet_model/batch_normalization_21/gamma) /* ty=Tensor[(128), float32] */;
  %254 = negative(%resnet_model/batch_normalization_21/moving_mean) /* ty=Tensor[(128), float32] */;
  %255 = multiply(%254, %253) /* ty=Tensor[(128), float32] */;
  %256 = multiply(%252, %253) /* ty=Tensor[(?, 28, 28, 128), float32] */;
  %257 = add(%255, %resnet_model/batch_normalization_21/beta) /* ty=Tensor[(128), float32] */;
  %258 = add(%256, %257) /* ty=Tensor[(?, 28, 28, 128), float32] */;
  %259 = nn.relu(%258) /* resnet_model/Relu_19 */ /* ty=Tensor[(?, 28, 28, 128), float32] */;
  %260 = add(%resnet_model/batch_normalization_22/moving_variance, 1.001e-05f /* ty=float32 */) /* ty=Tensor[(128), float32] */;
  %261 = sqrt(%260) /* ty=Tensor[(128), float32] */;
  %262 = divide(1f /* ty=float32 */, %261) /* ty=Tensor[(128), float32] */;
  %263 = nn.conv2d(%259, %resnet_model/conv2d_22/kernel, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWIO") /* resnet_model/conv2d_22/Conv2D */ /* ty=Tensor[(?, 28, 28, 128), float32] */;
  %264 = multiply(%262, %resnet_model/batch_normalization_22/gamma) /* ty=Tensor[(128), float32] */;
  %265 = negative(%resnet_model/batch_normalization_22/moving_mean) /* ty=Tensor[(128), float32] */;
  %266 = multiply(%265, %264) /* ty=Tensor[(128), float32] */;
  %267 = multiply(%263, %264) /* ty=Tensor[(?, 28, 28, 128), float32] */;
  %268 = add(%266, %resnet_model/batch_normalization_22/beta) /* ty=Tensor[(128), float32] */;
  %269 = add(%267, %268) /* ty=Tensor[(?, 28, 28, 128), float32] */;
  %270 = nn.relu(%269) /* resnet_model/Relu_20 */ /* ty=Tensor[(?, 28, 28, 128), float32] */;
  %271 = add(%resnet_model/batch_normalization_23/moving_variance, 1.001e-05f /* ty=float32 */) /* ty=Tensor[(512), float32] */;
  %272 = sqrt(%271) /* ty=Tensor[(512), float32] */;
  %273 = divide(1f /* ty=float32 */, %272) /* ty=Tensor[(512), float32] */;
  %274 = nn.conv2d(%270, %resnet_model/conv2d_23/kernel, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO") /* resnet_model/conv2d_23/Conv2D */ /* ty=Tensor[(?, 28, 28, 512), float32] */;
  %275 = multiply(%273, %resnet_model/batch_normalization_23/gamma) /* ty=Tensor[(512), float32] */;
  %276 = negative(%resnet_model/batch_normalization_23/moving_mean) /* ty=Tensor[(512), float32] */;
  %277 = multiply(%276, %275) /* ty=Tensor[(512), float32] */;
  %278 = multiply(%274, %275) /* ty=Tensor[(?, 28, 28, 512), float32] */;
  %279 = add(%277, %resnet_model/batch_normalization_23/beta) /* ty=Tensor[(512), float32] */;
  %280 = add(%278, %279) /* ty=Tensor[(?, 28, 28, 512), float32] */;
  %281 = add(%280, %248) /* resnet_model/add_6 */ /* ty=Tensor[(?, 28, 28, 512), float32] */;
  %282 = nn.relu(%281) /* resnet_model/Relu_21 */ /* ty=Tensor[(?, 28, 28, 512), float32] */;
  %283 = add(%resnet_model/batch_normalization_25/moving_variance, 1.001e-05f /* ty=float32 */) /* ty=Tensor[(256), float32] */;
  %284 = sqrt(%283) /* ty=Tensor[(256), float32] */;
  %285 = divide(1f /* ty=float32 */, %284) /* ty=Tensor[(256), float32] */;
  %286 = nn.conv2d(%282, %resnet_model/conv2d_25/kernel, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO") /* resnet_model/conv2d_25/Conv2D */ /* ty=Tensor[(?, 28, 28, 256), float32] */;
  %287 = multiply(%285, %resnet_model/batch_normalization_25/gamma) /* ty=Tensor[(256), float32] */;
  %288 = negative(%resnet_model/batch_normalization_25/moving_mean) /* ty=Tensor[(256), float32] */;
  %289 = multiply(%288, %287) /* ty=Tensor[(256), float32] */;
  %290 = multiply(%286, %287) /* ty=Tensor[(?, 28, 28, 256), float32] */;
  %291 = add(%289, %resnet_model/batch_normalization_25/beta) /* ty=Tensor[(256), float32] */;
  %292 = add(%290, %291) /* ty=Tensor[(?, 28, 28, 256), float32] */;
  %293 = nn.relu(%292) /* resnet_model/Relu_22 */ /* ty=Tensor[(?, 28, 28, 256), float32] */;
  %294 = nn.pad(%293, 0 /* ty=int32 */, pad_width=[[0, 0], [1, 1], [1, 1], [0, 0]]) /* resnet_model/Pad_4 */ /* ty=Tensor[(?, 30, 30, 256), float32] */;
  %295 = add(%resnet_model/batch_normalization_26/moving_variance, 1.001e-05f /* ty=float32 */) /* ty=Tensor[(256), float32] */;
  %296 = sqrt(%295) /* ty=Tensor[(256), float32] */;
  %297 = divide(1f /* ty=float32 */, %296) /* ty=Tensor[(256), float32] */;
  %298 = nn.conv2d(%294, %resnet_model/conv2d_26/kernel, strides=[2, 2], padding=[0, 0, 0, 0], channels=256, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWIO") /* resnet_model/conv2d_26/Conv2D */ /* ty=Tensor[(?, 14, 14, 256), float32] */;
  %299 = multiply(%297, %resnet_model/batch_normalization_26/gamma) /* ty=Tensor[(256), float32] */;
  %300 = negative(%resnet_model/batch_normalization_26/moving_mean) /* ty=Tensor[(256), float32] */;
  %301 = multiply(%300, %299) /* ty=Tensor[(256), float32] */;
  %302 = multiply(%298, %299) /* ty=Tensor[(?, 14, 14, 256), float32] */;
  %303 = add(%301, %resnet_model/batch_normalization_26/beta) /* ty=Tensor[(256), float32] */;
  %304 = add(%302, %303) /* ty=Tensor[(?, 14, 14, 256), float32] */;
  %305 = nn.relu(%304) /* resnet_model/Relu_23 */ /* ty=Tensor[(?, 14, 14, 256), float32] */;
  %306 = add(%resnet_model/batch_normalization_27/moving_variance, 1.001e-05f /* ty=float32 */) /* ty=Tensor[(1024), float32] */;
  %307 = sqrt(%306) /* ty=Tensor[(1024), float32] */;
  %308 = divide(1f /* ty=float32 */, %307) /* ty=Tensor[(1024), float32] */;
  %309 = nn.conv2d(%305, %resnet_model/conv2d_27/kernel, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO") /* resnet_model/conv2d_27/Conv2D */ /* ty=Tensor[(?, 14, 14, 1024), float32] */;
  %310 = multiply(%308, %resnet_model/batch_normalization_27/gamma) /* ty=Tensor[(1024), float32] */;
  %311 = negative(%resnet_model/batch_normalization_27/moving_mean) /* ty=Tensor[(1024), float32] */;
  %312 = multiply(%311, %310) /* ty=Tensor[(1024), float32] */;
  %313 = multiply(%309, %310) /* ty=Tensor[(?, 14, 14, 1024), float32] */;
  %314 = add(%312, %resnet_model/batch_normalization_27/beta) /* ty=Tensor[(1024), float32] */;
  %315 = nn.pad(%282, 0 /* ty=int32 */, pad_width=[[0, 0], [0, 0], [0, 0], [0, 0]]) /* resnet_model/Pad_3 */ /* ty=Tensor[(?, 28, 28, 512), float32] */;
  %316 = add(%resnet_model/batch_normalization_24/moving_variance, 1.001e-05f /* ty=float32 */) /* ty=Tensor[(1024), float32] */;
  %317 = sqrt(%316) /* ty=Tensor[(1024), float32] */;
  %318 = divide(1f /* ty=float32 */, %317) /* ty=Tensor[(1024), float32] */;
  %319 = nn.conv2d(%315, %resnet_model/conv2d_24/kernel, strides=[2, 2], padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO") /* resnet_model/conv2d_24/Conv2D */ /* ty=Tensor[(?, 14, 14, 1024), float32] */;
  %320 = multiply(%318, %resnet_model/batch_normalization_24/gamma) /* ty=Tensor[(1024), float32] */;
  %321 = negative(%resnet_model/batch_normalization_24/moving_mean) /* ty=Tensor[(1024), float32] */;
  %322 = multiply(%321, %320) /* ty=Tensor[(1024), float32] */;
  %323 = multiply(%319, %320) /* ty=Tensor[(?, 14, 14, 1024), float32] */;
  %324 = add(%322, %resnet_model/batch_normalization_24/beta) /* ty=Tensor[(1024), float32] */;
  %325 = add(%313, %314) /* ty=Tensor[(?, 14, 14, 1024), float32] */;
  %326 = add(%323, %324) /* ty=Tensor[(?, 14, 14, 1024), float32] */;
  %327 = add(%325, %326) /* resnet_model/add_7 */ /* ty=Tensor[(?, 14, 14, 1024), float32] */;
  %328 = nn.relu(%327) /* resnet_model/Relu_24 */ /* ty=Tensor[(?, 14, 14, 1024), float32] */;
  %329 = add(%resnet_model/batch_normalization_28/moving_variance, 1.001e-05f /* ty=float32 */) /* ty=Tensor[(256), float32] */;
  %330 = sqrt(%329) /* ty=Tensor[(256), float32] */;
  %331 = divide(1f /* ty=float32 */, %330) /* ty=Tensor[(256), float32] */;
  %332 = nn.conv2d(%328, %resnet_model/conv2d_28/kernel, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO") /* resnet_model/conv2d_28/Conv2D */ /* ty=Tensor[(?, 14, 14, 256), float32] */;
  %333 = multiply(%331, %resnet_model/batch_normalization_28/gamma) /* ty=Tensor[(256), float32] */;
  %334 = negative(%resnet_model/batch_normalization_28/moving_mean) /* ty=Tensor[(256), float32] */;
  %335 = multiply(%334, %333) /* ty=Tensor[(256), float32] */;
  %336 = multiply(%332, %333) /* ty=Tensor[(?, 14, 14, 256), float32] */;
  %337 = add(%335, %resnet_model/batch_normalization_28/beta) /* ty=Tensor[(256), float32] */;
  %338 = add(%336, %337) /* ty=Tensor[(?, 14, 14, 256), float32] */;
  %339 = nn.relu(%338) /* resnet_model/Relu_25 */ /* ty=Tensor[(?, 14, 14, 256), float32] */;
  %340 = add(%resnet_model/batch_normalization_29/moving_variance, 1.001e-05f /* ty=float32 */) /* ty=Tensor[(256), float32] */;
  %341 = sqrt(%340) /* ty=Tensor[(256), float32] */;
  %342 = divide(1f /* ty=float32 */, %341) /* ty=Tensor[(256), float32] */;
  %343 = nn.conv2d(%339, %resnet_model/conv2d_29/kernel, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWIO") /* resnet_model/conv2d_29/Conv2D */ /* ty=Tensor[(?, 14, 14, 256), float32] */;
  %344 = multiply(%342, %resnet_model/batch_normalization_29/gamma) /* ty=Tensor[(256), float32] */;
  %345 = negative(%resnet_model/batch_normalization_29/moving_mean) /* ty=Tensor[(256), float32] */;
  %346 = multiply(%345, %344) /* ty=Tensor[(256), float32] */;
  %347 = multiply(%343, %344) /* ty=Tensor[(?, 14, 14, 256), float32] */;
  %348 = add(%346, %resnet_model/batch_normalization_29/beta) /* ty=Tensor[(256), float32] */;
  %349 = add(%347, %348) /* ty=Tensor[(?, 14, 14, 256), float32] */;
  %350 = nn.relu(%349) /* resnet_model/Relu_26 */ /* ty=Tensor[(?, 14, 14, 256), float32] */;
  %351 = add(%resnet_model/batch_normalization_30/moving_variance, 1.001e-05f /* ty=float32 */) /* ty=Tensor[(1024), float32] */;
  %352 = sqrt(%351) /* ty=Tensor[(1024), float32] */;
  %353 = divide(1f /* ty=float32 */, %352) /* ty=Tensor[(1024), float32] */;
  %354 = nn.conv2d(%350, %resnet_model/conv2d_30/kernel, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO") /* resnet_model/conv2d_30/Conv2D */ /* ty=Tensor[(?, 14, 14, 1024), float32] */;
  %355 = multiply(%353, %resnet_model/batch_normalization_30/gamma) /* ty=Tensor[(1024), float32] */;
  %356 = negative(%resnet_model/batch_normalization_30/moving_mean) /* ty=Tensor[(1024), float32] */;
  %357 = multiply(%356, %355) /* ty=Tensor[(1024), float32] */;
  %358 = multiply(%354, %355) /* ty=Tensor[(?, 14, 14, 1024), float32] */;
  %359 = add(%357, %resnet_model/batch_normalization_30/beta) /* ty=Tensor[(1024), float32] */;
  %360 = add(%358, %359) /* ty=Tensor[(?, 14, 14, 1024), float32] */;
  %361 = add(%360, %328) /* resnet_model/add_8 */ /* ty=Tensor[(?, 14, 14, 1024), float32] */;
  %362 = nn.relu(%361) /* resnet_model/Relu_27 */ /* ty=Tensor[(?, 14, 14, 1024), float32] */;
  %363 = add(%resnet_model/batch_normalization_31/moving_variance, 1.001e-05f /* ty=float32 */) /* ty=Tensor[(256), float32] */;
  %364 = sqrt(%363) /* ty=Tensor[(256), float32] */;
  %365 = divide(1f /* ty=float32 */, %364) /* ty=Tensor[(256), float32] */;
  %366 = nn.conv2d(%362, %resnet_model/conv2d_31/kernel, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO") /* resnet_model/conv2d_31/Conv2D */ /* ty=Tensor[(?, 14, 14, 256), float32] */;
  %367 = multiply(%365, %resnet_model/batch_normalization_31/gamma) /* ty=Tensor[(256), float32] */;
  %368 = negative(%resnet_model/batch_normalization_31/moving_mean) /* ty=Tensor[(256), float32] */;
  %369 = multiply(%368, %367) /* ty=Tensor[(256), float32] */;
  %370 = multiply(%366, %367) /* ty=Tensor[(?, 14, 14, 256), float32] */;
  %371 = add(%369, %resnet_model/batch_normalization_31/beta) /* ty=Tensor[(256), float32] */;
  %372 = add(%370, %371) /* ty=Tensor[(?, 14, 14, 256), float32] */;
  %373 = nn.relu(%372) /* resnet_model/Relu_28 */ /* ty=Tensor[(?, 14, 14, 256), float32] */;
  %374 = add(%resnet_model/batch_normalization_32/moving_variance, 1.001e-05f /* ty=float32 */) /* ty=Tensor[(256), float32] */;
  %375 = sqrt(%374) /* ty=Tensor[(256), float32] */;
  %376 = divide(1f /* ty=float32 */, %375) /* ty=Tensor[(256), float32] */;
  %377 = nn.conv2d(%373, %resnet_model/conv2d_32/kernel, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWIO") /* resnet_model/conv2d_32/Conv2D */ /* ty=Tensor[(?, 14, 14, 256), float32] */;
  %378 = multiply(%376, %resnet_model/batch_normalization_32/gamma) /* ty=Tensor[(256), float32] */;
  %379 = negative(%resnet_model/batch_normalization_32/moving_mean) /* ty=Tensor[(256), float32] */;
  %380 = multiply(%379, %378) /* ty=Tensor[(256), float32] */;
  %381 = multiply(%377, %378) /* ty=Tensor[(?, 14, 14, 256), float32] */;
  %382 = add(%380, %resnet_model/batch_normalization_32/beta) /* ty=Tensor[(256), float32] */;
  %383 = add(%381, %382) /* ty=Tensor[(?, 14, 14, 256), float32] */;
  %384 = nn.relu(%383) /* resnet_model/Relu_29 */ /* ty=Tensor[(?, 14, 14, 256), float32] */;
  %385 = add(%resnet_model/batch_normalization_33/moving_variance, 1.001e-05f /* ty=float32 */) /* ty=Tensor[(1024), float32] */;
  %386 = sqrt(%385) /* ty=Tensor[(1024), float32] */;
  %387 = divide(1f /* ty=float32 */, %386) /* ty=Tensor[(1024), float32] */;
  %388 = nn.conv2d(%384, %resnet_model/conv2d_33/kernel, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO") /* resnet_model/conv2d_33/Conv2D */ /* ty=Tensor[(?, 14, 14, 1024), float32] */;
  %389 = multiply(%387, %resnet_model/batch_normalization_33/gamma) /* ty=Tensor[(1024), float32] */;
  %390 = negative(%resnet_model/batch_normalization_33/moving_mean) /* ty=Tensor[(1024), float32] */;
  %391 = multiply(%390, %389) /* ty=Tensor[(1024), float32] */;
  %392 = multiply(%388, %389) /* ty=Tensor[(?, 14, 14, 1024), float32] */;
  %393 = add(%391, %resnet_model/batch_normalization_33/beta) /* ty=Tensor[(1024), float32] */;
  %394 = add(%392, %393) /* ty=Tensor[(?, 14, 14, 1024), float32] */;
  %395 = add(%394, %362) /* resnet_model/add_9 */ /* ty=Tensor[(?, 14, 14, 1024), float32] */;
  %396 = nn.relu(%395) /* resnet_model/Relu_30 */ /* ty=Tensor[(?, 14, 14, 1024), float32] */;
  %397 = add(%resnet_model/batch_normalization_34/moving_variance, 1.001e-05f /* ty=float32 */) /* ty=Tensor[(256), float32] */;
  %398 = sqrt(%397) /* ty=Tensor[(256), float32] */;
  %399 = divide(1f /* ty=float32 */, %398) /* ty=Tensor[(256), float32] */;
  %400 = nn.conv2d(%396, %resnet_model/conv2d_34/kernel, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO") /* resnet_model/conv2d_34/Conv2D */ /* ty=Tensor[(?, 14, 14, 256), float32] */;
  %401 = multiply(%399, %resnet_model/batch_normalization_34/gamma) /* ty=Tensor[(256), float32] */;
  %402 = negative(%resnet_model/batch_normalization_34/moving_mean) /* ty=Tensor[(256), float32] */;
  %403 = multiply(%402, %401) /* ty=Tensor[(256), float32] */;
  %404 = multiply(%400, %401) /* ty=Tensor[(?, 14, 14, 256), float32] */;
  %405 = add(%403, %resnet_model/batch_normalization_34/beta) /* ty=Tensor[(256), float32] */;
  %406 = add(%404, %405) /* ty=Tensor[(?, 14, 14, 256), float32] */;
  %407 = nn.relu(%406) /* resnet_model/Relu_31 */ /* ty=Tensor[(?, 14, 14, 256), float32] */;
  %408 = add(%resnet_model/batch_normalization_35/moving_variance, 1.001e-05f /* ty=float32 */) /* ty=Tensor[(256), float32] */;
  %409 = sqrt(%408) /* ty=Tensor[(256), float32] */;
  %410 = divide(1f /* ty=float32 */, %409) /* ty=Tensor[(256), float32] */;
  %411 = nn.conv2d(%407, %resnet_model/conv2d_35/kernel, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWIO") /* resnet_model/conv2d_35/Conv2D */ /* ty=Tensor[(?, 14, 14, 256), float32] */;
  %412 = multiply(%410, %resnet_model/batch_normalization_35/gamma) /* ty=Tensor[(256), float32] */;
  %413 = negative(%resnet_model/batch_normalization_35/moving_mean) /* ty=Tensor[(256), float32] */;
  %414 = multiply(%413, %412) /* ty=Tensor[(256), float32] */;
  %415 = multiply(%411, %412) /* ty=Tensor[(?, 14, 14, 256), float32] */;
  %416 = add(%414, %resnet_model/batch_normalization_35/beta) /* ty=Tensor[(256), float32] */;
  %417 = add(%415, %416) /* ty=Tensor[(?, 14, 14, 256), float32] */;
  %418 = nn.relu(%417) /* resnet_model/Relu_32 */ /* ty=Tensor[(?, 14, 14, 256), float32] */;
  %419 = add(%resnet_model/batch_normalization_36/moving_variance, 1.001e-05f /* ty=float32 */) /* ty=Tensor[(1024), float32] */;
  %420 = sqrt(%419) /* ty=Tensor[(1024), float32] */;
  %421 = divide(1f /* ty=float32 */, %420) /* ty=Tensor[(1024), float32] */;
  %422 = nn.conv2d(%418, %resnet_model/conv2d_36/kernel, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO") /* resnet_model/conv2d_36/Conv2D */ /* ty=Tensor[(?, 14, 14, 1024), float32] */;
  %423 = multiply(%421, %resnet_model/batch_normalization_36/gamma) /* ty=Tensor[(1024), float32] */;
  %424 = negative(%resnet_model/batch_normalization_36/moving_mean) /* ty=Tensor[(1024), float32] */;
  %425 = multiply(%424, %423) /* ty=Tensor[(1024), float32] */;
  %426 = multiply(%422, %423) /* ty=Tensor[(?, 14, 14, 1024), float32] */;
  %427 = add(%425, %resnet_model/batch_normalization_36/beta) /* ty=Tensor[(1024), float32] */;
  %428 = add(%426, %427) /* ty=Tensor[(?, 14, 14, 1024), float32] */;
  %429 = add(%428, %396) /* resnet_model/add_10 */ /* ty=Tensor[(?, 14, 14, 1024), float32] */;
  %430 = nn.relu(%429) /* resnet_model/Relu_33 */ /* ty=Tensor[(?, 14, 14, 1024), float32] */;
  %431 = add(%resnet_model/batch_normalization_37/moving_variance, 1.001e-05f /* ty=float32 */) /* ty=Tensor[(256), float32] */;
  %432 = sqrt(%431) /* ty=Tensor[(256), float32] */;
  %433 = divide(1f /* ty=float32 */, %432) /* ty=Tensor[(256), float32] */;
  %434 = nn.conv2d(%430, %resnet_model/conv2d_37/kernel, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO") /* resnet_model/conv2d_37/Conv2D */ /* ty=Tensor[(?, 14, 14, 256), float32] */;
  %435 = multiply(%433, %resnet_model/batch_normalization_37/gamma) /* ty=Tensor[(256), float32] */;
  %436 = negative(%resnet_model/batch_normalization_37/moving_mean) /* ty=Tensor[(256), float32] */;
  %437 = multiply(%436, %435) /* ty=Tensor[(256), float32] */;
  %438 = multiply(%434, %435) /* ty=Tensor[(?, 14, 14, 256), float32] */;
  %439 = add(%437, %resnet_model/batch_normalization_37/beta) /* ty=Tensor[(256), float32] */;
  %440 = add(%438, %439) /* ty=Tensor[(?, 14, 14, 256), float32] */;
  %441 = nn.relu(%440) /* resnet_model/Relu_34 */ /* ty=Tensor[(?, 14, 14, 256), float32] */;
  %442 = add(%resnet_model/batch_normalization_38/moving_variance, 1.001e-05f /* ty=float32 */) /* ty=Tensor[(256), float32] */;
  %443 = sqrt(%442) /* ty=Tensor[(256), float32] */;
  %444 = divide(1f /* ty=float32 */, %443) /* ty=Tensor[(256), float32] */;
  %445 = nn.conv2d(%441, %resnet_model/conv2d_38/kernel, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWIO") /* resnet_model/conv2d_38/Conv2D */ /* ty=Tensor[(?, 14, 14, 256), float32] */;
  %446 = multiply(%444, %resnet_model/batch_normalization_38/gamma) /* ty=Tensor[(256), float32] */;
  %447 = negative(%resnet_model/batch_normalization_38/moving_mean) /* ty=Tensor[(256), float32] */;
  %448 = multiply(%447, %446) /* ty=Tensor[(256), float32] */;
  %449 = multiply(%445, %446) /* ty=Tensor[(?, 14, 14, 256), float32] */;
  %450 = add(%448, %resnet_model/batch_normalization_38/beta) /* ty=Tensor[(256), float32] */;
  %451 = add(%449, %450) /* ty=Tensor[(?, 14, 14, 256), float32] */;
  %452 = nn.relu(%451) /* resnet_model/Relu_35 */ /* ty=Tensor[(?, 14, 14, 256), float32] */;
  %453 = add(%resnet_model/batch_normalization_39/moving_variance, 1.001e-05f /* ty=float32 */) /* ty=Tensor[(1024), float32] */;
  %454 = sqrt(%453) /* ty=Tensor[(1024), float32] */;
  %455 = divide(1f /* ty=float32 */, %454) /* ty=Tensor[(1024), float32] */;
  %456 = nn.conv2d(%452, %resnet_model/conv2d_39/kernel, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO") /* resnet_model/conv2d_39/Conv2D */ /* ty=Tensor[(?, 14, 14, 1024), float32] */;
  %457 = multiply(%455, %resnet_model/batch_normalization_39/gamma) /* ty=Tensor[(1024), float32] */;
  %458 = negative(%resnet_model/batch_normalization_39/moving_mean) /* ty=Tensor[(1024), float32] */;
  %459 = multiply(%458, %457) /* ty=Tensor[(1024), float32] */;
  %460 = multiply(%456, %457) /* ty=Tensor[(?, 14, 14, 1024), float32] */;
  %461 = add(%459, %resnet_model/batch_normalization_39/beta) /* ty=Tensor[(1024), float32] */;
  %462 = add(%460, %461) /* ty=Tensor[(?, 14, 14, 1024), float32] */;
  %463 = add(%462, %430) /* resnet_model/add_11 */ /* ty=Tensor[(?, 14, 14, 1024), float32] */;
  %464 = nn.relu(%463) /* resnet_model/Relu_36 */ /* ty=Tensor[(?, 14, 14, 1024), float32] */;
  %465 = add(%resnet_model/batch_normalization_40/moving_variance, 1.001e-05f /* ty=float32 */) /* ty=Tensor[(256), float32] */;
  %466 = sqrt(%465) /* ty=Tensor[(256), float32] */;
  %467 = divide(1f /* ty=float32 */, %466) /* ty=Tensor[(256), float32] */;
  %468 = nn.conv2d(%464, %resnet_model/conv2d_40/kernel, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO") /* resnet_model/conv2d_40/Conv2D */ /* ty=Tensor[(?, 14, 14, 256), float32] */;
  %469 = multiply(%467, %resnet_model/batch_normalization_40/gamma) /* ty=Tensor[(256), float32] */;
  %470 = negative(%resnet_model/batch_normalization_40/moving_mean) /* ty=Tensor[(256), float32] */;
  %471 = multiply(%470, %469) /* ty=Tensor[(256), float32] */;
  %472 = multiply(%468, %469) /* ty=Tensor[(?, 14, 14, 256), float32] */;
  %473 = add(%471, %resnet_model/batch_normalization_40/beta) /* ty=Tensor[(256), float32] */;
  %474 = add(%472, %473) /* ty=Tensor[(?, 14, 14, 256), float32] */;
  %475 = nn.relu(%474) /* resnet_model/Relu_37 */ /* ty=Tensor[(?, 14, 14, 256), float32] */;
  %476 = add(%resnet_model/batch_normalization_41/moving_variance, 1.001e-05f /* ty=float32 */) /* ty=Tensor[(256), float32] */;
  %477 = sqrt(%476) /* ty=Tensor[(256), float32] */;
  %478 = divide(1f /* ty=float32 */, %477) /* ty=Tensor[(256), float32] */;
  %479 = nn.conv2d(%475, %resnet_model/conv2d_41/kernel, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWIO") /* resnet_model/conv2d_41/Conv2D */ /* ty=Tensor[(?, 14, 14, 256), float32] */;
  %480 = multiply(%478, %resnet_model/batch_normalization_41/gamma) /* ty=Tensor[(256), float32] */;
  %481 = negative(%resnet_model/batch_normalization_41/moving_mean) /* ty=Tensor[(256), float32] */;
  %482 = multiply(%481, %480) /* ty=Tensor[(256), float32] */;
  %483 = multiply(%479, %480) /* ty=Tensor[(?, 14, 14, 256), float32] */;
  %484 = add(%482, %resnet_model/batch_normalization_41/beta) /* ty=Tensor[(256), float32] */;
  %485 = add(%483, %484) /* ty=Tensor[(?, 14, 14, 256), float32] */;
  %486 = nn.relu(%485) /* resnet_model/Relu_38 */ /* ty=Tensor[(?, 14, 14, 256), float32] */;
  %487 = add(%resnet_model/batch_normalization_42/moving_variance, 1.001e-05f /* ty=float32 */) /* ty=Tensor[(1024), float32] */;
  %488 = sqrt(%487) /* ty=Tensor[(1024), float32] */;
  %489 = divide(1f /* ty=float32 */, %488) /* ty=Tensor[(1024), float32] */;
  %490 = nn.conv2d(%486, %resnet_model/conv2d_42/kernel, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO") /* resnet_model/conv2d_42/Conv2D */ /* ty=Tensor[(?, 14, 14, 1024), float32] */;
  %491 = multiply(%489, %resnet_model/batch_normalization_42/gamma) /* ty=Tensor[(1024), float32] */;
  %492 = negative(%resnet_model/batch_normalization_42/moving_mean) /* ty=Tensor[(1024), float32] */;
  %493 = multiply(%492, %491) /* ty=Tensor[(1024), float32] */;
  %494 = multiply(%490, %491) /* ty=Tensor[(?, 14, 14, 1024), float32] */;
  %495 = add(%493, %resnet_model/batch_normalization_42/beta) /* ty=Tensor[(1024), float32] */;
  %496 = add(%494, %495) /* ty=Tensor[(?, 14, 14, 1024), float32] */;
  %497 = add(%496, %464) /* resnet_model/add_12 */ /* ty=Tensor[(?, 14, 14, 1024), float32] */;
  %498 = nn.relu(%497) /* resnet_model/Relu_39 */ /* ty=Tensor[(?, 14, 14, 1024), float32] */;
  %499 = add(%resnet_model/batch_normalization_44/moving_variance, 1.001e-05f /* ty=float32 */) /* ty=Tensor[(512), float32] */;
  %500 = sqrt(%499) /* ty=Tensor[(512), float32] */;
  %501 = divide(1f /* ty=float32 */, %500) /* ty=Tensor[(512), float32] */;
  %502 = nn.conv2d(%498, %resnet_model/conv2d_44/kernel, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO") /* resnet_model/conv2d_44/Conv2D */ /* ty=Tensor[(?, 14, 14, 512), float32] */;
  %503 = multiply(%501, %resnet_model/batch_normalization_44/gamma) /* ty=Tensor[(512), float32] */;
  %504 = negative(%resnet_model/batch_normalization_44/moving_mean) /* ty=Tensor[(512), float32] */;
  %505 = multiply(%504, %503) /* ty=Tensor[(512), float32] */;
  %506 = multiply(%502, %503) /* ty=Tensor[(?, 14, 14, 512), float32] */;
  %507 = add(%505, %resnet_model/batch_normalization_44/beta) /* ty=Tensor[(512), float32] */;
  %508 = add(%506, %507) /* ty=Tensor[(?, 14, 14, 512), float32] */;
  %509 = nn.relu(%508) /* resnet_model/Relu_40 */ /* ty=Tensor[(?, 14, 14, 512), float32] */;
  %510 = nn.pad(%509, 0 /* ty=int32 */, pad_width=[[0, 0], [1, 1], [1, 1], [0, 0]]) /* resnet_model/Pad_6 */ /* ty=Tensor[(?, 16, 16, 512), float32] */;
  %511 = add(%resnet_model/batch_normalization_45/moving_variance, 1.001e-05f /* ty=float32 */) /* ty=Tensor[(512), float32] */;
  %512 = sqrt(%511) /* ty=Tensor[(512), float32] */;
  %513 = divide(1f /* ty=float32 */, %512) /* ty=Tensor[(512), float32] */;
  %514 = nn.conv2d(%510, %resnet_model/conv2d_45/kernel, strides=[2, 2], padding=[0, 0, 0, 0], channels=512, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWIO") /* resnet_model/conv2d_45/Conv2D */ /* ty=Tensor[(?, 7, 7, 512), float32] */;
  %515 = multiply(%513, %resnet_model/batch_normalization_45/gamma) /* ty=Tensor[(512), float32] */;
  %516 = negative(%resnet_model/batch_normalization_45/moving_mean) /* ty=Tensor[(512), float32] */;
  %517 = multiply(%516, %515) /* ty=Tensor[(512), float32] */;
  %518 = multiply(%514, %515) /* ty=Tensor[(?, 7, 7, 512), float32] */;
  %519 = add(%517, %resnet_model/batch_normalization_45/beta) /* ty=Tensor[(512), float32] */;
  %520 = add(%518, %519) /* ty=Tensor[(?, 7, 7, 512), float32] */;
  %521 = nn.relu(%520) /* resnet_model/Relu_41 */ /* ty=Tensor[(?, 7, 7, 512), float32] */;
  %522 = add(%resnet_model/batch_normalization_46/moving_variance, 1.001e-05f /* ty=float32 */) /* ty=Tensor[(2048), float32] */;
  %523 = sqrt(%522) /* ty=Tensor[(2048), float32] */;
  %524 = divide(1f /* ty=float32 */, %523) /* ty=Tensor[(2048), float32] */;
  %525 = nn.conv2d(%521, %resnet_model/conv2d_46/kernel, padding=[0, 0, 0, 0], channels=2048, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO") /* resnet_model/conv2d_46/Conv2D */ /* ty=Tensor[(?, 7, 7, 2048), float32] */;
  %526 = multiply(%524, %resnet_model/batch_normalization_46/gamma) /* ty=Tensor[(2048), float32] */;
  %527 = negative(%resnet_model/batch_normalization_46/moving_mean) /* ty=Tensor[(2048), float32] */;
  %528 = multiply(%527, %526) /* ty=Tensor[(2048), float32] */;
  %529 = multiply(%525, %526) /* ty=Tensor[(?, 7, 7, 2048), float32] */;
  %530 = add(%528, %resnet_model/batch_normalization_46/beta) /* ty=Tensor[(2048), float32] */;
  %531 = nn.pad(%498, 0 /* ty=int32 */, pad_width=[[0, 0], [0, 0], [0, 0], [0, 0]]) /* resnet_model/Pad_5 */ /* ty=Tensor[(?, 14, 14, 1024), float32] */;
  %532 = add(%resnet_model/batch_normalization_43/moving_variance, 1.001e-05f /* ty=float32 */) /* ty=Tensor[(2048), float32] */;
  %533 = sqrt(%532) /* ty=Tensor[(2048), float32] */;
  %534 = divide(1f /* ty=float32 */, %533) /* ty=Tensor[(2048), float32] */;
  %535 = nn.conv2d(%531, %resnet_model/conv2d_43/kernel, strides=[2, 2], padding=[0, 0, 0, 0], channels=2048, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO") /* resnet_model/conv2d_43/Conv2D */ /* ty=Tensor[(?, 7, 7, 2048), float32] */;
  %536 = multiply(%534, %resnet_model/batch_normalization_43/gamma) /* ty=Tensor[(2048), float32] */;
  %537 = negative(%resnet_model/batch_normalization_43/moving_mean) /* ty=Tensor[(2048), float32] */;
  %538 = multiply(%537, %536) /* ty=Tensor[(2048), float32] */;
  %539 = multiply(%535, %536) /* ty=Tensor[(?, 7, 7, 2048), float32] */;
  %540 = add(%538, %resnet_model/batch_normalization_43/beta) /* ty=Tensor[(2048), float32] */;
  %541 = add(%529, %530) /* ty=Tensor[(?, 7, 7, 2048), float32] */;
  %542 = add(%539, %540) /* ty=Tensor[(?, 7, 7, 2048), float32] */;
  %543 = add(%541, %542) /* resnet_model/add_13 */ /* ty=Tensor[(?, 7, 7, 2048), float32] */;
  %544 = nn.relu(%543) /* resnet_model/Relu_42 */ /* ty=Tensor[(?, 7, 7, 2048), float32] */;
  %545 = add(%resnet_model/batch_normalization_47/moving_variance, 1.001e-05f /* ty=float32 */) /* ty=Tensor[(512), float32] */;
  %546 = sqrt(%545) /* ty=Tensor[(512), float32] */;
  %547 = divide(1f /* ty=float32 */, %546) /* ty=Tensor[(512), float32] */;
  %548 = nn.conv2d(%544, %resnet_model/conv2d_47/kernel, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO") /* resnet_model/conv2d_47/Conv2D */ /* ty=Tensor[(?, 7, 7, 512), float32] */;
  %549 = multiply(%547, %resnet_model/batch_normalization_47/gamma) /* ty=Tensor[(512), float32] */;
  %550 = negative(%resnet_model/batch_normalization_47/moving_mean) /* ty=Tensor[(512), float32] */;
  %551 = multiply(%550, %549) /* ty=Tensor[(512), float32] */;
  %552 = multiply(%548, %549) /* ty=Tensor[(?, 7, 7, 512), float32] */;
  %553 = add(%551, %resnet_model/batch_normalization_47/beta) /* ty=Tensor[(512), float32] */;
  %554 = add(%552, %553) /* ty=Tensor[(?, 7, 7, 512), float32] */;
  %555 = nn.relu(%554) /* resnet_model/Relu_43 */ /* ty=Tensor[(?, 7, 7, 512), float32] */;
  %556 = add(%resnet_model/batch_normalization_48/moving_variance, 1.001e-05f /* ty=float32 */) /* ty=Tensor[(512), float32] */;
  %557 = sqrt(%556) /* ty=Tensor[(512), float32] */;
  %558 = divide(1f /* ty=float32 */, %557) /* ty=Tensor[(512), float32] */;
  %559 = nn.conv2d(%555, %resnet_model/conv2d_48/kernel, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWIO") /* resnet_model/conv2d_48/Conv2D */ /* ty=Tensor[(?, 7, 7, 512), float32] */;
  %560 = multiply(%558, %resnet_model/batch_normalization_48/gamma) /* ty=Tensor[(512), float32] */;
  %561 = negative(%resnet_model/batch_normalization_48/moving_mean) /* ty=Tensor[(512), float32] */;
  %562 = multiply(%561, %560) /* ty=Tensor[(512), float32] */;
  %563 = multiply(%559, %560) /* ty=Tensor[(?, 7, 7, 512), float32] */;
  %564 = add(%562, %resnet_model/batch_normalization_48/beta) /* ty=Tensor[(512), float32] */;
  %565 = add(%563, %564) /* ty=Tensor[(?, 7, 7, 512), float32] */;
  %566 = nn.relu(%565) /* resnet_model/Relu_44 */ /* ty=Tensor[(?, 7, 7, 512), float32] */;
  %567 = add(%resnet_model/batch_normalization_49/moving_variance, 1.001e-05f /* ty=float32 */) /* ty=Tensor[(2048), float32] */;
  %568 = sqrt(%567) /* ty=Tensor[(2048), float32] */;
  %569 = divide(1f /* ty=float32 */, %568) /* ty=Tensor[(2048), float32] */;
  %570 = nn.conv2d(%566, %resnet_model/conv2d_49/kernel, padding=[0, 0, 0, 0], channels=2048, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO") /* resnet_model/conv2d_49/Conv2D */ /* ty=Tensor[(?, 7, 7, 2048), float32] */;
  %571 = multiply(%569, %resnet_model/batch_normalization_49/gamma) /* ty=Tensor[(2048), float32] */;
  %572 = negative(%resnet_model/batch_normalization_49/moving_mean) /* ty=Tensor[(2048), float32] */;
  %573 = multiply(%572, %571) /* ty=Tensor[(2048), float32] */;
  %574 = multiply(%570, %571) /* ty=Tensor[(?, 7, 7, 2048), float32] */;
  %575 = add(%573, %resnet_model/batch_normalization_49/beta) /* ty=Tensor[(2048), float32] */;
  %576 = add(%574, %575) /* ty=Tensor[(?, 7, 7, 2048), float32] */;
  %577 = add(%576, %544) /* resnet_model/add_14 */ /* ty=Tensor[(?, 7, 7, 2048), float32] */;
  %578 = nn.relu(%577) /* resnet_model/Relu_45 */ /* ty=Tensor[(?, 7, 7, 2048), float32] */;
  %579 = add(%resnet_model/batch_normalization_50/moving_variance, 1.001e-05f /* ty=float32 */) /* ty=Tensor[(512), float32] */;
  %580 = sqrt(%579) /* ty=Tensor[(512), float32] */;
  %581 = divide(1f /* ty=float32 */, %580) /* ty=Tensor[(512), float32] */;
  %582 = nn.conv2d(%578, %resnet_model/conv2d_50/kernel, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO") /* resnet_model/conv2d_50/Conv2D */ /* ty=Tensor[(?, 7, 7, 512), float32] */;
  %583 = multiply(%581, %resnet_model/batch_normalization_50/gamma) /* ty=Tensor[(512), float32] */;
  %584 = negative(%resnet_model/batch_normalization_50/moving_mean) /* ty=Tensor[(512), float32] */;
  %585 = multiply(%584, %583) /* ty=Tensor[(512), float32] */;
  %586 = multiply(%582, %583) /* ty=Tensor[(?, 7, 7, 512), float32] */;
  %587 = add(%585, %resnet_model/batch_normalization_50/beta) /* ty=Tensor[(512), float32] */;
  %588 = add(%586, %587) /* ty=Tensor[(?, 7, 7, 512), float32] */;
  %589 = nn.relu(%588) /* resnet_model/Relu_46 */ /* ty=Tensor[(?, 7, 7, 512), float32] */;
  %590 = add(%resnet_model/batch_normalization_51/moving_variance, 1.001e-05f /* ty=float32 */) /* ty=Tensor[(512), float32] */;
  %591 = sqrt(%590) /* ty=Tensor[(512), float32] */;
  %592 = divide(1f /* ty=float32 */, %591) /* ty=Tensor[(512), float32] */;
  %593 = nn.conv2d(%589, %resnet_model/conv2d_51/kernel, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWIO") /* resnet_model/conv2d_51/Conv2D */ /* ty=Tensor[(?, 7, 7, 512), float32] */;
  %594 = multiply(%592, %resnet_model/batch_normalization_51/gamma) /* ty=Tensor[(512), float32] */;
  %595 = negative(%resnet_model/batch_normalization_51/moving_mean) /* ty=Tensor[(512), float32] */;
  %596 = multiply(%595, %594) /* ty=Tensor[(512), float32] */;
  %597 = multiply(%593, %594) /* ty=Tensor[(?, 7, 7, 512), float32] */;
  %598 = add(%596, %resnet_model/batch_normalization_51/beta) /* ty=Tensor[(512), float32] */;
  %599 = add(%597, %598) /* ty=Tensor[(?, 7, 7, 512), float32] */;
  %600 = nn.relu(%599) /* resnet_model/Relu_47 */ /* ty=Tensor[(?, 7, 7, 512), float32] */;
  %601 = add(%resnet_model/batch_normalization_52/moving_variance, 1.001e-05f /* ty=float32 */) /* ty=Tensor[(2048), float32] */;
  %602 = sqrt(%601) /* ty=Tensor[(2048), float32] */;
  %603 = divide(1f /* ty=float32 */, %602) /* ty=Tensor[(2048), float32] */;
  %604 = nn.conv2d(%600, %resnet_model/conv2d_52/kernel, padding=[0, 0, 0, 0], channels=2048, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO") /* resnet_model/conv2d_52/Conv2D */ /* ty=Tensor[(?, 7, 7, 2048), float32] */;
  %605 = multiply(%603, %resnet_model/batch_normalization_52/gamma) /* ty=Tensor[(2048), float32] */;
  %606 = negative(%resnet_model/batch_normalization_52/moving_mean) /* ty=Tensor[(2048), float32] */;
  %607 = multiply(%606, %605) /* ty=Tensor[(2048), float32] */;
  %608 = multiply(%604, %605) /* ty=Tensor[(?, 7, 7, 2048), float32] */;
  %609 = add(%607, %resnet_model/batch_normalization_52/beta) /* ty=Tensor[(2048), float32] */;
  %610 = add(%608, %609) /* ty=Tensor[(?, 7, 7, 2048), float32] */;
  %611 = add(%610, %578) /* resnet_model/add_15 */ /* ty=Tensor[(?, 7, 7, 2048), float32] */;
  %612 = nn.relu(%611) /* resnet_model/Relu_48 */ /* ty=Tensor[(?, 7, 7, 2048), float32] */;
  %613 = mean(%612, axis=[1, 2], keepdims=True) /* resnet_model/Mean */ /* ty=Tensor[(?, 1, 1, 2048), float32] */;
  %614 = squeeze(%613, axis=[1, 2]) /* resnet_model/Squeeze */ /* ty=Tensor[(?, 2048), float32] */;
  %615 = transpose(%resnet_model/dense/kernel, axes=[1, 0]) /* ty=Tensor[(1001, 2048), float32] */;
  %616 = nn.dense(%614, %615, units=1001) /* resnet_model/dense/MatMul */ /* ty=Tensor[(?, 1001), float32] */;
  %617 = add(%616, %resnet_model/dense/bias) /* resnet_model/dense/BiasAdd */ /* ty=Tensor[(?, 1001), float32] */;
  nn.softmax(%617) /* softmax_tensor */ /* ty=Tensor[(?, 1001), float32] */
}

def @map[A, B](%f7: fn (A) -> B, %xs7: List[A]) -> List[B] {
  match (%xs7) {
    Cons(%x8: A, %rest5: List[A]) => {
      %618 = %f7(%x8) /* /root/tvm/python/tvm/relay/std/prelude.rly */ /* ty=B */;
      %619 = @map(%f7, %rest5) /* /root/tvm/python/tvm/relay/std/prelude.rly */ /* ty=List[B] */;
      Cons(%618, %619) /* /root/tvm/python/tvm/relay/std/prelude.rly */ /* ty=List[B] */
    },
    Nil => {
      Nil /* ty=List[B] */
    },
  }
}

def @map_accuml[A, B, C](%f8: fn (A, B) -> (A, C), %init: A, %xs8: List[B]) -> (A, List[C]) {
  let %updater: fn ((A, List[C]), B) -> (A, List[C]) = fn (%acc2: (A, List[C]), %x9: B) -> (A, List[C]) {
    %620 = %acc2.0;
    let %f_out: (A, C) = %f8(%620, %x9) /* /root/tvm/python/tvm/relay/std/prelude.rly */ /* ty=(A, C) */;
    %621 = %f_out.1;
    %622 = %acc2.1;
    %623 = %f_out.0;
    %624 = Cons(%621, %622) /* /root/tvm/python/tvm/relay/std/prelude.rly */ /* ty=List[C] */;
    (%623, %624)
  };
  %625 = Nil /* ty=List[C] */;
  %626 = (%init, %625);
  @foldl(%updater, %626, %xs8) /* /root/tvm/python/tvm/relay/std/prelude.rly */ /* ty=(A, List[C]) */
}

def @map_accumr[A, B, C](%f9: fn (A, B) -> (A, C), %init1: A, %xs9: List[B]) -> (A, List[C]) {
  let %updater1: fn (B, (A, List[C])) -> (A, List[C]) = fn (%x10: B, %acc3: (A, List[C])) -> (A, List[C]) {
    %627 = %acc3.0;
    let %f_out1: (A, C) = %f9(%627, %x10) /* /root/tvm/python/tvm/relay/std/prelude.rly */ /* ty=(A, C) */;
    %628 = %f_out1.1;
    %629 = %acc3.1;
    %630 = %f_out1.0;
    %631 = Cons(%628, %629) /* /root/tvm/python/tvm/relay/std/prelude.rly */ /* ty=List[C] */;
    (%630, %631)
  };
  %632 = Nil /* ty=List[C] */;
  %633 = (%init1, %632);
  @foldr(%updater1, %633, %xs9) /* /root/tvm/python/tvm/relay/std/prelude.rly */ /* ty=(A, List[C]) */
}

def @nth[A](%xs10: List[A], %n1: int32) -> A {
  %634 = equal(%n1, 0 /* ty=int32 */) /* /root/tvm/python/tvm/relay/std/prelude.rly */ /* ty=bool */;
  if (%634) {
    @hd(%xs10) /* /root/tvm/python/tvm/relay/std/prelude.rly */ /* ty=A */
  } else {
    %635 = @tl(%xs10) /* /root/tvm/python/tvm/relay/std/prelude.rly */ /* ty=List[A] */;
    %636 = subtract(%n1, 1 /* ty=int32 */) /* /root/tvm/python/tvm/relay/std/prelude.rly */ /* ty=int32 */;
    @nth(%635, %636) /* /root/tvm/python/tvm/relay/std/prelude.rly */ /* ty=A */
  }
}

def @rev[A](%xs11: List[A]) -> List[A] {
  %637 = fn (%h: A, %t: List[A]) -> List[A] {
    Cons(%h, %t) /* /root/tvm/python/tvm/relay/std/prelude.rly */ /* ty=List[A] */
  };
  %638 = @flip(%637) /* /root/tvm/python/tvm/relay/std/prelude.rly */ /* ty=fn (List[A], A) -> List[A] */;
  %639 = Nil /* ty=List[A] */;
  @foldl(%638, %639, %xs11) /* /root/tvm/python/tvm/relay/std/prelude.rly */ /* ty=List[A] */
}

def @size[A](%t1: Tree[A]) -> int32 {
  match (%t1) {
    Rose(_, %sub_trees: List[Tree[A]]) => {
      %640 = @map(@size, %sub_trees) /* /root/tvm/python/tvm/relay/std/prelude.rly */ /* ty=List[int32] */;
      %641 = @sum(%640) /* /root/tvm/python/tvm/relay/std/prelude.rly */ /* ty=int32 */;
      add(1 /* ty=int32 */, %641) /* /root/tvm/python/tvm/relay/std/prelude.rly */ /* ty=int32 */
    },
  }
}

def @sum(%xs12: List[int32]) -> int32 {
  let %add_f: fn (int32, int32) -> int32 = fn (%x11: int32, %y: int32) -> int32 {
    add(%x11, %y) /* /root/tvm/python/tvm/relay/std/prelude.rly */ /* ty=int32 */
  };
  @foldl(%add_f, 0 /* ty=int32 */, %xs12) /* /root/tvm/python/tvm/relay/std/prelude.rly */ /* ty=int32 */
}

def @ta_split_helper_float16(%tensor_array: List[tensor_float16_t[]], %value1: tensor_float16_t[], %offset1: int32, %current1: int32, %limit1: int32, %lengths: Tensor[(?), int32]) -> List[tensor_float16_t[]] {
  %642 = equal(%current1, %limit1) /* ty=bool */;
  if (%642) {
    %tensor_array
  } else {
    %643 = take(%lengths, %current1) /* ty=int32 */;
    %644 = add(%offset1, %643) /* ty=int32 */;
    %645 = add(%current1, 1 /* ty=int32 */) /* ty=int32 */;
    %646 = take(%lengths, %current1) /* ty=int32 */;
    %647 = add(%646, %offset1) /* ty=int32 */;
    %648 = @ta_split_helper_float16(%tensor_array, %value1, %644, %645, %limit1, %lengths) /* ty=List[tensor_float16_t[]] */;
    %649 = @tensor_take_float16(%value1, %offset1, %647) /* ty=tensor_float16_t[] */;
    @tensor_array_write_float16(%648, %current1, %649) /* ty=List[tensor_float16_t[]] */
  }
}

def @ta_split_helper_float32(%tensor_array1: List[tensor_float32_t[]], %value11: tensor_float32_t[], %offset11: int32, %current11: int32, %limit11: int32, %lengths1: Tensor[(?), int32]) -> List[tensor_float32_t[]] {
  %650 = equal(%current11, %limit11) /* ty=bool */;
  if (%650) {
    %tensor_array1
  } else {
    %651 = take(%lengths1, %current11) /* ty=int32 */;
    %652 = add(%offset11, %651) /* ty=int32 */;
    %653 = add(%current11, 1 /* ty=int32 */) /* ty=int32 */;
    %654 = take(%lengths1, %current11) /* ty=int32 */;
    %655 = add(%654, %offset11) /* ty=int32 */;
    %656 = @ta_split_helper_float32(%tensor_array1, %value11, %652, %653, %limit11, %lengths1) /* ty=List[tensor_float32_t[]] */;
    %657 = @tensor_take_float32(%value11, %offset11, %655) /* ty=tensor_float32_t[] */;
    @tensor_array_write_float32(%656, %current11, %657) /* ty=List[tensor_float32_t[]] */
  }
}

def @ta_split_helper_float64(%tensor_array2: List[tensor_float64_t[]], %value12: tensor_float64_t[], %offset12: int32, %current12: int32, %limit12: int32, %lengths2: Tensor[(?), int32]) -> List[tensor_float64_t[]] {
  %658 = equal(%current12, %limit12) /* ty=bool */;
  if (%658) {
    %tensor_array2
  } else {
    %659 = take(%lengths2, %current12) /* ty=int32 */;
    %660 = add(%offset12, %659) /* ty=int32 */;
    %661 = add(%current12, 1 /* ty=int32 */) /* ty=int32 */;
    %662 = take(%lengths2, %current12) /* ty=int32 */;
    %663 = add(%662, %offset12) /* ty=int32 */;
    %664 = @ta_split_helper_float64(%tensor_array2, %value12, %660, %661, %limit12, %lengths2) /* ty=List[tensor_float64_t[]] */;
    %665 = @tensor_take_float64(%value12, %offset12, %663) /* ty=tensor_float64_t[] */;
    @tensor_array_write_float64(%664, %current12, %665) /* ty=List[tensor_float64_t[]] */
  }
}

def @ta_split_helper_int16(%tensor_array3: List[tensor_int16_t[]], %value13: tensor_int16_t[], %offset13: int32, %current13: int32, %limit13: int32, %lengths3: Tensor[(?), int32]) -> List[tensor_int16_t[]] {
  %666 = equal(%current13, %limit13) /* ty=bool */;
  if (%666) {
    %tensor_array3
  } else {
    %667 = take(%lengths3, %current13) /* ty=int32 */;
    %668 = add(%offset13, %667) /* ty=int32 */;
    %669 = add(%current13, 1 /* ty=int32 */) /* ty=int32 */;
    %670 = take(%lengths3, %current13) /* ty=int32 */;
    %671 = add(%670, %offset13) /* ty=int32 */;
    %672 = @ta_split_helper_int16(%tensor_array3, %value13, %668, %669, %limit13, %lengths3) /* ty=List[tensor_int16_t[]] */;
    %673 = @tensor_take_int16(%value13, %offset13, %671) /* ty=tensor_int16_t[] */;
    @tensor_array_write_int16(%672, %current13, %673) /* ty=List[tensor_int16_t[]] */
  }
}

def @ta_split_helper_int32(%tensor_array4: List[tensor_int32_t[]], %value14: tensor_int32_t[], %offset14: int32, %current14: int32, %limit14: int32, %lengths4: Tensor[(?), int32]) -> List[tensor_int32_t[]] {
  %674 = equal(%current14, %limit14) /* ty=bool */;
  if (%674) {
    %tensor_array4
  } else {
    %675 = take(%lengths4, %current14) /* ty=int32 */;
    %676 = add(%offset14, %675) /* ty=int32 */;
    %677 = add(%current14, 1 /* ty=int32 */) /* ty=int32 */;
    %678 = take(%lengths4, %current14) /* ty=int32 */;
    %679 = add(%678, %offset14) /* ty=int32 */;
    %680 = @ta_split_helper_int32(%tensor_array4, %value14, %676, %677, %limit14, %lengths4) /* ty=List[tensor_int32_t[]] */;
    %681 = @tensor_take_int32(%value14, %offset14, %679) /* ty=tensor_int32_t[] */;
    @tensor_array_write_int32(%680, %current14, %681) /* ty=List[tensor_int32_t[]] */
  }
}

def @ta_split_helper_int64(%tensor_array5: List[tensor_int64_t[]], %value15: tensor_int64_t[], %offset15: int32, %current15: int32, %limit15: int32, %lengths5: Tensor[(?), int32]) -> List[tensor_int64_t[]] {
  %682 = equal(%current15, %limit15) /* ty=bool */;
  if (%682) {
    %tensor_array5
  } else {
    %683 = take(%lengths5, %current15) /* ty=int32 */;
    %684 = add(%offset15, %683) /* ty=int32 */;
    %685 = add(%current15, 1 /* ty=int32 */) /* ty=int32 */;
    %686 = take(%lengths5, %current15) /* ty=int32 */;
    %687 = add(%686, %offset15) /* ty=int32 */;
    %688 = @ta_split_helper_int64(%tensor_array5, %value15, %684, %685, %limit15, %lengths5) /* ty=List[tensor_int64_t[]] */;
    %689 = @tensor_take_int64(%value15, %offset15, %687) /* ty=tensor_int64_t[] */;
    @tensor_array_write_int64(%688, %current15, %689) /* ty=List[tensor_int64_t[]] */
  }
}

def @ta_split_helper_int8(%tensor_array6: List[tensor_int8_t[]], %value16: tensor_int8_t[], %offset16: int32, %current16: int32, %limit16: int32, %lengths6: Tensor[(?), int32]) -> List[tensor_int8_t[]] {
  %690 = equal(%current16, %limit16) /* ty=bool */;
  if (%690) {
    %tensor_array6
  } else {
    %691 = take(%lengths6, %current16) /* ty=int32 */;
    %692 = add(%offset16, %691) /* ty=int32 */;
    %693 = add(%current16, 1 /* ty=int32 */) /* ty=int32 */;
    %694 = take(%lengths6, %current16) /* ty=int32 */;
    %695 = add(%694, %offset16) /* ty=int32 */;
    %696 = @ta_split_helper_int8(%tensor_array6, %value16, %692, %693, %limit16, %lengths6) /* ty=List[tensor_int8_t[]] */;
    %697 = @tensor_take_int8(%value16, %offset16, %695) /* ty=tensor_int8_t[] */;
    @tensor_array_write_int8(%696, %current16, %697) /* ty=List[tensor_int8_t[]] */
  }
}

def @ta_split_helper_uint16(%tensor_array7: List[tensor_uint16_t[]], %value17: tensor_uint16_t[], %offset17: int32, %current17: int32, %limit17: int32, %lengths7: Tensor[(?), int32]) -> List[tensor_uint16_t[]] {
  %698 = equal(%current17, %limit17) /* ty=bool */;
  if (%698) {
    %tensor_array7
  } else {
    %699 = take(%lengths7, %current17) /* ty=int32 */;
    %700 = add(%offset17, %699) /* ty=int32 */;
    %701 = add(%current17, 1 /* ty=int32 */) /* ty=int32 */;
    %702 = take(%lengths7, %current17) /* ty=int32 */;
    %703 = add(%702, %offset17) /* ty=int32 */;
    %704 = @ta_split_helper_uint16(%tensor_array7, %value17, %700, %701, %limit17, %lengths7) /* ty=List[tensor_uint16_t[]] */;
    %705 = @tensor_take_uint16(%value17, %offset17, %703) /* ty=tensor_uint16_t[] */;
    @tensor_array_write_uint16(%704, %current17, %705) /* ty=List[tensor_uint16_t[]] */
  }
}

def @ta_split_helper_uint8(%tensor_array8: List[tensor_uint8_t[]], %value18: tensor_uint8_t[], %offset18: int32, %current18: int32, %limit18: int32, %lengths8: Tensor[(?), int32]) -> List[tensor_uint8_t[]] {
  %706 = equal(%current18, %limit18) /* ty=bool */;
  if (%706) {
    %tensor_array8
  } else {
    %707 = take(%lengths8, %current18) /* ty=int32 */;
    %708 = add(%offset18, %707) /* ty=int32 */;
    %709 = add(%current18, 1 /* ty=int32 */) /* ty=int32 */;
    %710 = take(%lengths8, %current18) /* ty=int32 */;
    %711 = add(%710, %offset18) /* ty=int32 */;
    %712 = @ta_split_helper_uint8(%tensor_array8, %value18, %708, %709, %limit18, %lengths8) /* ty=List[tensor_uint8_t[]] */;
    %713 = @tensor_take_uint8(%value18, %offset18, %711) /* ty=tensor_uint8_t[] */;
    @tensor_array_write_uint8(%712, %current18, %713) /* ty=List[tensor_uint8_t[]] */
  }
}

def @tensor_array_concat_float16(%tensor_array9: List[tensor_float16_t[]]) -> tensor_float16_t[] {
  match? (%tensor_array9) {
    Nil => {
      tensor_nil_float16 /* ty=tensor_float16_t[] */
    },
    Cons(%hd: tensor_float16_t[], %tl: List[tensor_float16_t[]]) => {
      match? (%tl) {
        Nil => {
          %hd
        },
        _ => {
          %714 = @tensor_array_concat_float16(%tl) /* ty=tensor_float16_t[] */;
          @tensor_concatenate_float16(%hd, %714) /* ty=tensor_float16_t[] */
        },
      }
    },
  }
}

def @tensor_array_concat_float32(%tensor_array10: List[tensor_float32_t[]]) -> tensor_float32_t[] {
  match? (%tensor_array10) {
    Nil => {
      tensor_nil_float32 /* ty=tensor_float32_t[] */
    },
    Cons(%hd1: tensor_float32_t[], %tl1: List[tensor_float32_t[]]) => {
      match? (%tl1) {
        Nil => {
          %hd1
        },
        _ => {
          %715 = @tensor_array_concat_float32(%tl1) /* ty=tensor_float32_t[] */;
          @tensor_concatenate_float32(%hd1, %715) /* ty=tensor_float32_t[] */
        },
      }
    },
  }
}

def @tensor_array_concat_float64(%tensor_array11: List[tensor_float64_t[]]) -> tensor_float64_t[] {
  match? (%tensor_array11) {
    Nil => {
      tensor_nil_float64 /* ty=tensor_float64_t[] */
    },
    Cons(%hd2: tensor_float64_t[], %tl2: List[tensor_float64_t[]]) => {
      match? (%tl2) {
        Nil => {
          %hd2
        },
        _ => {
          %716 = @tensor_array_concat_float64(%tl2) /* ty=tensor_float64_t[] */;
          @tensor_concatenate_float64(%hd2, %716) /* ty=tensor_float64_t[] */
        },
      }
    },
  }
}

def @tensor_array_concat_int16(%tensor_array12: List[tensor_int16_t[]]) -> tensor_int16_t[] {
  match? (%tensor_array12) {
    Nil => {
      tensor_nil_int16 /* ty=tensor_int16_t[] */
    },
    Cons(%hd3: tensor_int16_t[], %tl3: List[tensor_int16_t[]]) => {
      match? (%tl3) {
        Nil => {
          %hd3
        },
        _ => {
          %717 = @tensor_array_concat_int16(%tl3) /* ty=tensor_int16_t[] */;
          @tensor_concatenate_int16(%hd3, %717) /* ty=tensor_int16_t[] */
        },
      }
    },
  }
}

def @tensor_array_concat_int32(%tensor_array13: List[tensor_int32_t[]]) -> tensor_int32_t[] {
  match? (%tensor_array13) {
    Nil => {
      tensor_nil_int32 /* ty=tensor_int32_t[] */
    },
    Cons(%hd4: tensor_int32_t[], %tl4: List[tensor_int32_t[]]) => {
      match? (%tl4) {
        Nil => {
          %hd4
        },
        _ => {
          %718 = @tensor_array_concat_int32(%tl4) /* ty=tensor_int32_t[] */;
          @tensor_concatenate_int32(%hd4, %718) /* ty=tensor_int32_t[] */
        },
      }
    },
  }
}

def @tensor_array_concat_int64(%tensor_array14: List[tensor_int64_t[]]) -> tensor_int64_t[] {
  match? (%tensor_array14) {
    Nil => {
      tensor_nil_int64 /* ty=tensor_int64_t[] */
    },
    Cons(%hd5: tensor_int64_t[], %tl5: List[tensor_int64_t[]]) => {
      match? (%tl5) {
        Nil => {
          %hd5
        },
        _ => {
          %719 = @tensor_array_concat_int64(%tl5) /* ty=tensor_int64_t[] */;
          @tensor_concatenate_int64(%hd5, %719) /* ty=tensor_int64_t[] */
        },
      }
    },
  }
}

def @tensor_array_concat_int8(%tensor_array15: List[tensor_int8_t[]]) -> tensor_int8_t[] {
  match? (%tensor_array15) {
    Nil => {
      tensor_nil_int8 /* ty=tensor_int8_t[] */
    },
    Cons(%hd6: tensor_int8_t[], %tl6: List[tensor_int8_t[]]) => {
      match? (%tl6) {
        Nil => {
          %hd6
        },
        _ => {
          %720 = @tensor_array_concat_int8(%tl6) /* ty=tensor_int8_t[] */;
          @tensor_concatenate_int8(%hd6, %720) /* ty=tensor_int8_t[] */
        },
      }
    },
  }
}

def @tensor_array_concat_uint16(%tensor_array16: List[tensor_uint16_t[]]) -> tensor_uint16_t[] {
  match? (%tensor_array16) {
    Nil => {
      tensor_nil_uint16 /* ty=tensor_uint16_t[] */
    },
    Cons(%hd7: tensor_uint16_t[], %tl7: List[tensor_uint16_t[]]) => {
      match? (%tl7) {
        Nil => {
          %hd7
        },
        _ => {
          %721 = @tensor_array_concat_uint16(%tl7) /* ty=tensor_uint16_t[] */;
          @tensor_concatenate_uint16(%hd7, %721) /* ty=tensor_uint16_t[] */
        },
      }
    },
  }
}

def @tensor_array_concat_uint8(%tensor_array17: List[tensor_uint8_t[]]) -> tensor_uint8_t[] {
  match? (%tensor_array17) {
    Nil => {
      tensor_nil_uint8 /* ty=tensor_uint8_t[] */
    },
    Cons(%hd8: tensor_uint8_t[], %tl8: List[tensor_uint8_t[]]) => {
      match? (%tl8) {
        Nil => {
          %hd8
        },
        _ => {
          %722 = @tensor_array_concat_uint8(%tl8) /* ty=tensor_uint8_t[] */;
          @tensor_concatenate_uint8(%hd8, %722) /* ty=tensor_uint8_t[] */
        },
      }
    },
  }
}

def @tensor_array_float16(%x12: int32) -> List[tensor_float16_t[]] {
  %723 = equal(%x12, 0 /* ty=int32 */) /* ty=bool */;
  if (%723) {
    Nil /* ty=List[tensor_float16_t[]] */
  } else {
    %724 = subtract(%x12, 1 /* ty=int32 */) /* ty=int32 */;
    %725 = tensor_nil_float16 /* ty=tensor_float16_t[] */;
    %726 = @tensor_array_float16(%724) /* ty=List[tensor_float16_t[]] */;
    Cons(%725, %726) /* ty=List[tensor_float16_t[]] */
  }
}

def @tensor_array_float32(%x13: int32) -> List[tensor_float32_t[]] {
  %727 = equal(%x13, 0 /* ty=int32 */) /* ty=bool */;
  if (%727) {
    Nil /* ty=List[tensor_float32_t[]] */
  } else {
    %728 = subtract(%x13, 1 /* ty=int32 */) /* ty=int32 */;
    %729 = tensor_nil_float32 /* ty=tensor_float32_t[] */;
    %730 = @tensor_array_float32(%728) /* ty=List[tensor_float32_t[]] */;
    Cons(%729, %730) /* ty=List[tensor_float32_t[]] */
  }
}

def @tensor_array_float64(%x14: int32) -> List[tensor_float64_t[]] {
  %731 = equal(%x14, 0 /* ty=int32 */) /* ty=bool */;
  if (%731) {
    Nil /* ty=List[tensor_float64_t[]] */
  } else {
    %732 = subtract(%x14, 1 /* ty=int32 */) /* ty=int32 */;
    %733 = tensor_nil_float64 /* ty=tensor_float64_t[] */;
    %734 = @tensor_array_float64(%732) /* ty=List[tensor_float64_t[]] */;
    Cons(%733, %734) /* ty=List[tensor_float64_t[]] */
  }
}

def @tensor_array_int16(%x15: int32) -> List[tensor_int16_t[]] {
  %735 = equal(%x15, 0 /* ty=int32 */) /* ty=bool */;
  if (%735) {
    Nil /* ty=List[tensor_int16_t[]] */
  } else {
    %736 = subtract(%x15, 1 /* ty=int32 */) /* ty=int32 */;
    %737 = tensor_nil_int16 /* ty=tensor_int16_t[] */;
    %738 = @tensor_array_int16(%736) /* ty=List[tensor_int16_t[]] */;
    Cons(%737, %738) /* ty=List[tensor_int16_t[]] */
  }
}

def @tensor_array_int32(%x16: int32) -> List[tensor_int32_t[]] {
  %739 = equal(%x16, 0 /* ty=int32 */) /* ty=bool */;
  if (%739) {
    Nil /* ty=List[tensor_int32_t[]] */
  } else {
    %740 = subtract(%x16, 1 /* ty=int32 */) /* ty=int32 */;
    %741 = tensor_nil_int32 /* ty=tensor_int32_t[] */;
    %742 = @tensor_array_int32(%740) /* ty=List[tensor_int32_t[]] */;
    Cons(%741, %742) /* ty=List[tensor_int32_t[]] */
  }
}

def @tensor_array_int64(%x17: int32) -> List[tensor_int64_t[]] {
  %743 = equal(%x17, 0 /* ty=int32 */) /* ty=bool */;
  if (%743) {
    Nil /* ty=List[tensor_int64_t[]] */
  } else {
    %744 = subtract(%x17, 1 /* ty=int32 */) /* ty=int32 */;
    %745 = tensor_nil_int64 /* ty=tensor_int64_t[] */;
    %746 = @tensor_array_int64(%744) /* ty=List[tensor_int64_t[]] */;
    Cons(%745, %746) /* ty=List[tensor_int64_t[]] */
  }
}

def @tensor_array_int8(%x18: int32) -> List[tensor_int8_t[]] {
  %747 = equal(%x18, 0 /* ty=int32 */) /* ty=bool */;
  if (%747) {
    Nil /* ty=List[tensor_int8_t[]] */
  } else {
    %748 = subtract(%x18, 1 /* ty=int32 */) /* ty=int32 */;
    %749 = tensor_nil_int8 /* ty=tensor_int8_t[] */;
    %750 = @tensor_array_int8(%748) /* ty=List[tensor_int8_t[]] */;
    Cons(%749, %750) /* ty=List[tensor_int8_t[]] */
  }
}

def @tensor_array_read_float16(%tensor_array18: List[tensor_float16_t[]], %x19: int32) -> tensor_float16_t[] {
  @nth(%tensor_array18, %x19) /* ty=tensor_float16_t[] */
}

def @tensor_array_read_float32(%tensor_array19: List[tensor_float32_t[]], %x20: int32) -> tensor_float32_t[] {
  @nth(%tensor_array19, %x20) /* ty=tensor_float32_t[] */
}

def @tensor_array_read_float64(%tensor_array20: List[tensor_float64_t[]], %x21: int32) -> tensor_float64_t[] {
  @nth(%tensor_array20, %x21) /* ty=tensor_float64_t[] */
}

def @tensor_array_read_int16(%tensor_array21: List[tensor_int16_t[]], %x22: int32) -> tensor_int16_t[] {
  @nth(%tensor_array21, %x22) /* ty=tensor_int16_t[] */
}

def @tensor_array_read_int32(%tensor_array22: List[tensor_int32_t[]], %x23: int32) -> tensor_int32_t[] {
  @nth(%tensor_array22, %x23) /* ty=tensor_int32_t[] */
}

def @tensor_array_read_int64(%tensor_array23: List[tensor_int64_t[]], %x24: int32) -> tensor_int64_t[] {
  @nth(%tensor_array23, %x24) /* ty=tensor_int64_t[] */
}

def @tensor_array_read_int8(%tensor_array24: List[tensor_int8_t[]], %x25: int32) -> tensor_int8_t[] {
  @nth(%tensor_array24, %x25) /* ty=tensor_int8_t[] */
}

def @tensor_array_read_uint16(%tensor_array25: List[tensor_uint16_t[]], %x26: int32) -> tensor_uint16_t[] {
  @nth(%tensor_array25, %x26) /* ty=tensor_uint16_t[] */
}

def @tensor_array_read_uint8(%tensor_array26: List[tensor_uint8_t[]], %x27: int32) -> tensor_uint8_t[] {
  @nth(%tensor_array26, %x27) /* ty=tensor_uint8_t[] */
}

def @tensor_array_scatter_float16(%tensor_array27: List[tensor_float16_t[]], %indices: Tensor[(?), int32], %values: List[tensor_float16_t[]]) -> List[tensor_float16_t[]] {
  %751 = shape_of(%indices, dtype="int32") /* ty=Tensor[(1), int32] */;
  %752 = take(%751, 0 /* ty=int32 */) /* ty=int32 */;
  @tensor_array_scatter_helper_float16(%tensor_array27, 0 /* ty=int32 */, %752, %indices, %values) /* ty=List[tensor_float16_t[]] */
}

def @tensor_array_scatter_float32(%tensor_array28: List[tensor_float32_t[]], %indices1: Tensor[(?), int32], %values1: List[tensor_float32_t[]]) -> List[tensor_float32_t[]] {
  %753 = shape_of(%indices1, dtype="int32") /* ty=Tensor[(1), int32] */;
  %754 = take(%753, 0 /* ty=int32 */) /* ty=int32 */;
  @tensor_array_scatter_helper_float32(%tensor_array28, 0 /* ty=int32 */, %754, %indices1, %values1) /* ty=List[tensor_float32_t[]] */
}

def @tensor_array_scatter_float64(%tensor_array29: List[tensor_float64_t[]], %indices2: Tensor[(?), int32], %values2: List[tensor_float64_t[]]) -> List[tensor_float64_t[]] {
  %755 = shape_of(%indices2, dtype="int32") /* ty=Tensor[(1), int32] */;
  %756 = take(%755, 0 /* ty=int32 */) /* ty=int32 */;
  @tensor_array_scatter_helper_float64(%tensor_array29, 0 /* ty=int32 */, %756, %indices2, %values2) /* ty=List[tensor_float64_t[]] */
}

def @tensor_array_scatter_helper_float16(%ta: List[tensor_float16_t[]], %current: int32, %limit: int32, %indices_: Tensor[(?), int32], %values_: List[tensor_float16_t[]]) -> List[tensor_float16_t[]] {
  %757 = equal(%current, %limit) /* ty=bool */;
  if (%757) {
    %ta
  } else {
    %758 = take(%indices_, %current) /* ty=int32 */;
    %759 = @tensor_array_read_float16(%values_, %current) /* ty=tensor_float16_t[] */;
    %760 = @tensor_array_write_float16(%ta, %758, %759) /* ty=List[tensor_float16_t[]] */;
    %761 = add(%current, 1 /* ty=int32 */) /* ty=int32 */;
    @tensor_array_scatter_helper_float16(%760, %761, %limit, %indices_, %values_) /* ty=List[tensor_float16_t[]] */
  }
}

def @tensor_array_scatter_helper_float32(%ta1: List[tensor_float32_t[]], %current2: int32, %limit2: int32, %indices_1: Tensor[(?), int32], %values_1: List[tensor_float32_t[]]) -> List[tensor_float32_t[]] {
  %762 = equal(%current2, %limit2) /* ty=bool */;
  if (%762) {
    %ta1
  } else {
    %763 = take(%indices_1, %current2) /* ty=int32 */;
    %764 = @tensor_array_read_float32(%values_1, %current2) /* ty=tensor_float32_t[] */;
    %765 = @tensor_array_write_float32(%ta1, %763, %764) /* ty=List[tensor_float32_t[]] */;
    %766 = add(%current2, 1 /* ty=int32 */) /* ty=int32 */;
    @tensor_array_scatter_helper_float32(%765, %766, %limit2, %indices_1, %values_1) /* ty=List[tensor_float32_t[]] */
  }
}

def @tensor_array_scatter_helper_float64(%ta2: List[tensor_float64_t[]], %current3: int32, %limit3: int32, %indices_2: Tensor[(?), int32], %values_2: List[tensor_float64_t[]]) -> List[tensor_float64_t[]] {
  %767 = equal(%current3, %limit3) /* ty=bool */;
  if (%767) {
    %ta2
  } else {
    %768 = take(%indices_2, %current3) /* ty=int32 */;
    %769 = @tensor_array_read_float64(%values_2, %current3) /* ty=tensor_float64_t[] */;
    %770 = @tensor_array_write_float64(%ta2, %768, %769) /* ty=List[tensor_float64_t[]] */;
    %771 = add(%current3, 1 /* ty=int32 */) /* ty=int32 */;
    @tensor_array_scatter_helper_float64(%770, %771, %limit3, %indices_2, %values_2) /* ty=List[tensor_float64_t[]] */
  }
}

def @tensor_array_scatter_helper_int16(%ta3: List[tensor_int16_t[]], %current4: int32, %limit4: int32, %indices_3: Tensor[(?), int32], %values_3: List[tensor_int16_t[]]) -> List[tensor_int16_t[]] {
  %772 = equal(%current4, %limit4) /* ty=bool */;
  if (%772) {
    %ta3
  } else {
    %773 = take(%indices_3, %current4) /* ty=int32 */;
    %774 = @tensor_array_read_int16(%values_3, %current4) /* ty=tensor_int16_t[] */;
    %775 = @tensor_array_write_int16(%ta3, %773, %774) /* ty=List[tensor_int16_t[]] */;
    %776 = add(%current4, 1 /* ty=int32 */) /* ty=int32 */;
    @tensor_array_scatter_helper_int16(%775, %776, %limit4, %indices_3, %values_3) /* ty=List[tensor_int16_t[]] */
  }
}

def @tensor_array_scatter_helper_int32(%ta4: List[tensor_int32_t[]], %current5: int32, %limit5: int32, %indices_4: Tensor[(?), int32], %values_4: List[tensor_int32_t[]]) -> List[tensor_int32_t[]] {
  %777 = equal(%current5, %limit5) /* ty=bool */;
  if (%777) {
    %ta4
  } else {
    %778 = take(%indices_4, %current5) /* ty=int32 */;
    %779 = @tensor_array_read_int32(%values_4, %current5) /* ty=tensor_int32_t[] */;
    %780 = @tensor_array_write_int32(%ta4, %778, %779) /* ty=List[tensor_int32_t[]] */;
    %781 = add(%current5, 1 /* ty=int32 */) /* ty=int32 */;
    @tensor_array_scatter_helper_int32(%780, %781, %limit5, %indices_4, %values_4) /* ty=List[tensor_int32_t[]] */
  }
}

def @tensor_array_scatter_helper_int64(%ta5: List[tensor_int64_t[]], %current6: int32, %limit6: int32, %indices_5: Tensor[(?), int32], %values_5: List[tensor_int64_t[]]) -> List[tensor_int64_t[]] {
  %782 = equal(%current6, %limit6) /* ty=bool */;
  if (%782) {
    %ta5
  } else {
    %783 = take(%indices_5, %current6) /* ty=int32 */;
    %784 = @tensor_array_read_int64(%values_5, %current6) /* ty=tensor_int64_t[] */;
    %785 = @tensor_array_write_int64(%ta5, %783, %784) /* ty=List[tensor_int64_t[]] */;
    %786 = add(%current6, 1 /* ty=int32 */) /* ty=int32 */;
    @tensor_array_scatter_helper_int64(%785, %786, %limit6, %indices_5, %values_5) /* ty=List[tensor_int64_t[]] */
  }
}

def @tensor_array_scatter_helper_int8(%ta6: List[tensor_int8_t[]], %current7: int32, %limit7: int32, %indices_6: Tensor[(?), int32], %values_6: List[tensor_int8_t[]]) -> List[tensor_int8_t[]] {
  %787 = equal(%current7, %limit7) /* ty=bool */;
  if (%787) {
    %ta6
  } else {
    %788 = take(%indices_6, %current7) /* ty=int32 */;
    %789 = @tensor_array_read_int8(%values_6, %current7) /* ty=tensor_int8_t[] */;
    %790 = @tensor_array_write_int8(%ta6, %788, %789) /* ty=List[tensor_int8_t[]] */;
    %791 = add(%current7, 1 /* ty=int32 */) /* ty=int32 */;
    @tensor_array_scatter_helper_int8(%790, %791, %limit7, %indices_6, %values_6) /* ty=List[tensor_int8_t[]] */
  }
}

def @tensor_array_scatter_helper_uint16(%ta7: List[tensor_uint16_t[]], %current8: int32, %limit8: int32, %indices_7: Tensor[(?), int32], %values_7: List[tensor_uint16_t[]]) -> List[tensor_uint16_t[]] {
  %792 = equal(%current8, %limit8) /* ty=bool */;
  if (%792) {
    %ta7
  } else {
    %793 = take(%indices_7, %current8) /* ty=int32 */;
    %794 = @tensor_array_read_uint16(%values_7, %current8) /* ty=tensor_uint16_t[] */;
    %795 = @tensor_array_write_uint16(%ta7, %793, %794) /* ty=List[tensor_uint16_t[]] */;
    %796 = add(%current8, 1 /* ty=int32 */) /* ty=int32 */;
    @tensor_array_scatter_helper_uint16(%795, %796, %limit8, %indices_7, %values_7) /* ty=List[tensor_uint16_t[]] */
  }
}

def @tensor_array_scatter_helper_uint8(%ta8: List[tensor_uint8_t[]], %current9: int32, %limit9: int32, %indices_8: Tensor[(?), int32], %values_8: List[tensor_uint8_t[]]) -> List[tensor_uint8_t[]] {
  %797 = equal(%current9, %limit9) /* ty=bool */;
  if (%797) {
    %ta8
  } else {
    %798 = take(%indices_8, %current9) /* ty=int32 */;
    %799 = @tensor_array_read_uint8(%values_8, %current9) /* ty=tensor_uint8_t[] */;
    %800 = @tensor_array_write_uint8(%ta8, %798, %799) /* ty=List[tensor_uint8_t[]] */;
    %801 = add(%current9, 1 /* ty=int32 */) /* ty=int32 */;
    @tensor_array_scatter_helper_uint8(%800, %801, %limit9, %indices_8, %values_8) /* ty=List[tensor_uint8_t[]] */
  }
}

def @tensor_array_scatter_int16(%tensor_array30: List[tensor_int16_t[]], %indices3: Tensor[(?), int32], %values3: List[tensor_int16_t[]]) -> List[tensor_int16_t[]] {
  %802 = shape_of(%indices3, dtype="int32") /* ty=Tensor[(1), int32] */;
  %803 = take(%802, 0 /* ty=int32 */) /* ty=int32 */;
  @tensor_array_scatter_helper_int16(%tensor_array30, 0 /* ty=int32 */, %803, %indices3, %values3) /* ty=List[tensor_int16_t[]] */
}

def @tensor_array_scatter_int32(%tensor_array31: List[tensor_int32_t[]], %indices4: Tensor[(?), int32], %values4: List[tensor_int32_t[]]) -> List[tensor_int32_t[]] {
  %804 = shape_of(%indices4, dtype="int32") /* ty=Tensor[(1), int32] */;
  %805 = take(%804, 0 /* ty=int32 */) /* ty=int32 */;
  @tensor_array_scatter_helper_int32(%tensor_array31, 0 /* ty=int32 */, %805, %indices4, %values4) /* ty=List[tensor_int32_t[]] */
}

def @tensor_array_scatter_int64(%tensor_array32: List[tensor_int64_t[]], %indices5: Tensor[(?), int32], %values5: List[tensor_int64_t[]]) -> List[tensor_int64_t[]] {
  %806 = shape_of(%indices5, dtype="int32") /* ty=Tensor[(1), int32] */;
  %807 = take(%806, 0 /* ty=int32 */) /* ty=int32 */;
  @tensor_array_scatter_helper_int64(%tensor_array32, 0 /* ty=int32 */, %807, %indices5, %values5) /* ty=List[tensor_int64_t[]] */
}

def @tensor_array_scatter_int8(%tensor_array33: List[tensor_int8_t[]], %indices6: Tensor[(?), int32], %values6: List[tensor_int8_t[]]) -> List[tensor_int8_t[]] {
  %808 = shape_of(%indices6, dtype="int32") /* ty=Tensor[(1), int32] */;
  %809 = take(%808, 0 /* ty=int32 */) /* ty=int32 */;
  @tensor_array_scatter_helper_int8(%tensor_array33, 0 /* ty=int32 */, %809, %indices6, %values6) /* ty=List[tensor_int8_t[]] */
}

def @tensor_array_scatter_uint16(%tensor_array34: List[tensor_uint16_t[]], %indices7: Tensor[(?), int32], %values7: List[tensor_uint16_t[]]) -> List[tensor_uint16_t[]] {
  %810 = shape_of(%indices7, dtype="int32") /* ty=Tensor[(1), int32] */;
  %811 = take(%810, 0 /* ty=int32 */) /* ty=int32 */;
  @tensor_array_scatter_helper_uint16(%tensor_array34, 0 /* ty=int32 */, %811, %indices7, %values7) /* ty=List[tensor_uint16_t[]] */
}

def @tensor_array_scatter_uint8(%tensor_array35: List[tensor_uint8_t[]], %indices8: Tensor[(?), int32], %values8: List[tensor_uint8_t[]]) -> List[tensor_uint8_t[]] {
  %812 = shape_of(%indices8, dtype="int32") /* ty=Tensor[(1), int32] */;
  %813 = take(%812, 0 /* ty=int32 */) /* ty=int32 */;
  @tensor_array_scatter_helper_uint8(%tensor_array35, 0 /* ty=int32 */, %813, %indices8, %values8) /* ty=List[tensor_uint8_t[]] */
}

def @tensor_array_split_float16(%tensor_array36: List[tensor_float16_t[]], %value: tensor_float16_t[], %lengths9: Tensor[(?), int32]) -> List[tensor_float16_t[]] {
  %814 = shape_of(%lengths9, dtype="int32") /* ty=Tensor[(1), int32] */;
  %815 = take(%814, 0 /* ty=int32 */) /* ty=int32 */;
  @ta_split_helper_float16(%tensor_array36, %value, 0 /* ty=int32 */, 0 /* ty=int32 */, %815, %lengths9) /* ty=List[tensor_float16_t[]] */
}

def @tensor_array_split_float32(%tensor_array37: List[tensor_float32_t[]], %value2: tensor_float32_t[], %lengths10: Tensor[(?), int32]) -> List[tensor_float32_t[]] {
  %816 = shape_of(%lengths10, dtype="int32") /* ty=Tensor[(1), int32] */;
  %817 = take(%816, 0 /* ty=int32 */) /* ty=int32 */;
  @ta_split_helper_float32(%tensor_array37, %value2, 0 /* ty=int32 */, 0 /* ty=int32 */, %817, %lengths10) /* ty=List[tensor_float32_t[]] */
}

def @tensor_array_split_float64(%tensor_array38: List[tensor_float64_t[]], %value3: tensor_float64_t[], %lengths11: Tensor[(?), int32]) -> List[tensor_float64_t[]] {
  %818 = shape_of(%lengths11, dtype="int32") /* ty=Tensor[(1), int32] */;
  %819 = take(%818, 0 /* ty=int32 */) /* ty=int32 */;
  @ta_split_helper_float64(%tensor_array38, %value3, 0 /* ty=int32 */, 0 /* ty=int32 */, %819, %lengths11) /* ty=List[tensor_float64_t[]] */
}

def @tensor_array_split_int16(%tensor_array39: List[tensor_int16_t[]], %value4: tensor_int16_t[], %lengths12: Tensor[(?), int32]) -> List[tensor_int16_t[]] {
  %820 = shape_of(%lengths12, dtype="int32") /* ty=Tensor[(1), int32] */;
  %821 = take(%820, 0 /* ty=int32 */) /* ty=int32 */;
  @ta_split_helper_int16(%tensor_array39, %value4, 0 /* ty=int32 */, 0 /* ty=int32 */, %821, %lengths12) /* ty=List[tensor_int16_t[]] */
}

def @tensor_array_split_int32(%tensor_array40: List[tensor_int32_t[]], %value5: tensor_int32_t[], %lengths13: Tensor[(?), int32]) -> List[tensor_int32_t[]] {
  %822 = shape_of(%lengths13, dtype="int32") /* ty=Tensor[(1), int32] */;
  %823 = take(%822, 0 /* ty=int32 */) /* ty=int32 */;
  @ta_split_helper_int32(%tensor_array40, %value5, 0 /* ty=int32 */, 0 /* ty=int32 */, %823, %lengths13) /* ty=List[tensor_int32_t[]] */
}

def @tensor_array_split_int64(%tensor_array41: List[tensor_int64_t[]], %value6: tensor_int64_t[], %lengths14: Tensor[(?), int32]) -> List[tensor_int64_t[]] {
  %824 = shape_of(%lengths14, dtype="int32") /* ty=Tensor[(1), int32] */;
  %825 = take(%824, 0 /* ty=int32 */) /* ty=int32 */;
  @ta_split_helper_int64(%tensor_array41, %value6, 0 /* ty=int32 */, 0 /* ty=int32 */, %825, %lengths14) /* ty=List[tensor_int64_t[]] */
}

def @tensor_array_split_int8(%tensor_array42: List[tensor_int8_t[]], %value7: tensor_int8_t[], %lengths15: Tensor[(?), int32]) -> List[tensor_int8_t[]] {
  %826 = shape_of(%lengths15, dtype="int32") /* ty=Tensor[(1), int32] */;
  %827 = take(%826, 0 /* ty=int32 */) /* ty=int32 */;
  @ta_split_helper_int8(%tensor_array42, %value7, 0 /* ty=int32 */, 0 /* ty=int32 */, %827, %lengths15) /* ty=List[tensor_int8_t[]] */
}

def @tensor_array_split_uint16(%tensor_array43: List[tensor_uint16_t[]], %value8: tensor_uint16_t[], %lengths16: Tensor[(?), int32]) -> List[tensor_uint16_t[]] {
  %828 = shape_of(%lengths16, dtype="int32") /* ty=Tensor[(1), int32] */;
  %829 = take(%828, 0 /* ty=int32 */) /* ty=int32 */;
  @ta_split_helper_uint16(%tensor_array43, %value8, 0 /* ty=int32 */, 0 /* ty=int32 */, %829, %lengths16) /* ty=List[tensor_uint16_t[]] */
}

def @tensor_array_split_uint8(%tensor_array44: List[tensor_uint8_t[]], %value9: tensor_uint8_t[], %lengths17: Tensor[(?), int32]) -> List[tensor_uint8_t[]] {
  %830 = shape_of(%lengths17, dtype="int32") /* ty=Tensor[(1), int32] */;
  %831 = take(%830, 0 /* ty=int32 */) /* ty=int32 */;
  @ta_split_helper_uint8(%tensor_array44, %value9, 0 /* ty=int32 */, 0 /* ty=int32 */, %831, %lengths17) /* ty=List[tensor_uint8_t[]] */
}

def @tensor_array_stack_float16(%tensor_array45: List[tensor_float16_t[]]) -> tensor_float16_t[] {
  let %x_40: List[tensor_float16_t[]] = @map(@tensor_expand_dims_float16, %tensor_array45) /* ty=List[tensor_float16_t[]] */;
  let %x_41: tensor_float16_t[] = @hd(%x_40) /* ty=tensor_float16_t[] */;
  let %x_42: List[tensor_float16_t[]] = @tl(%x_40) /* ty=List[tensor_float16_t[]] */;
  let %x_43: tensor_float16_t[] = @foldl(@tensor_concatenate_float16, %x_41, %x_42) /* ty=tensor_float16_t[] */;
  %x_43
}

def @tensor_array_stack_float32(%tensor_array46: List[tensor_float32_t[]]) -> tensor_float32_t[] {
  let %x_36: List[tensor_float32_t[]] = @map(@tensor_expand_dims_float32, %tensor_array46) /* ty=List[tensor_float32_t[]] */;
  let %x_37: tensor_float32_t[] = @hd(%x_36) /* ty=tensor_float32_t[] */;
  let %x_38: List[tensor_float32_t[]] = @tl(%x_36) /* ty=List[tensor_float32_t[]] */;
  let %x_39: tensor_float32_t[] = @foldl(@tensor_concatenate_float32, %x_37, %x_38) /* ty=tensor_float32_t[] */;
  %x_39
}

def @tensor_array_stack_float64(%tensor_array47: List[tensor_float64_t[]]) -> tensor_float64_t[] {
  let %x_44: List[tensor_float64_t[]] = @map(@tensor_expand_dims_float64, %tensor_array47) /* ty=List[tensor_float64_t[]] */;
  let %x_45: tensor_float64_t[] = @hd(%x_44) /* ty=tensor_float64_t[] */;
  let %x_46: List[tensor_float64_t[]] = @tl(%x_44) /* ty=List[tensor_float64_t[]] */;
  let %x_47: tensor_float64_t[] = @foldl(@tensor_concatenate_float64, %x_45, %x_46) /* ty=tensor_float64_t[] */;
  %x_47
}

def @tensor_array_stack_int16(%tensor_array48: List[tensor_int16_t[]]) -> tensor_int16_t[] {
  let %x_60: List[tensor_int16_t[]] = @map(@tensor_expand_dims_int16, %tensor_array48) /* ty=List[tensor_int16_t[]] */;
  let %x_61: tensor_int16_t[] = @hd(%x_60) /* ty=tensor_int16_t[] */;
  let %x_62: List[tensor_int16_t[]] = @tl(%x_60) /* ty=List[tensor_int16_t[]] */;
  let %x_63: tensor_int16_t[] = @foldl(@tensor_concatenate_int16, %x_61, %x_62) /* ty=tensor_int16_t[] */;
  %x_63
}

def @tensor_array_stack_int32(%tensor_array49: List[tensor_int32_t[]]) -> tensor_int32_t[] {
  let %x_48: List[tensor_int32_t[]] = @map(@tensor_expand_dims_int32, %tensor_array49) /* ty=List[tensor_int32_t[]] */;
  let %x_49: tensor_int32_t[] = @hd(%x_48) /* ty=tensor_int32_t[] */;
  let %x_50: List[tensor_int32_t[]] = @tl(%x_48) /* ty=List[tensor_int32_t[]] */;
  let %x_51: tensor_int32_t[] = @foldl(@tensor_concatenate_int32, %x_49, %x_50) /* ty=tensor_int32_t[] */;
  %x_51
}

def @tensor_array_stack_int64(%tensor_array50: List[tensor_int64_t[]]) -> tensor_int64_t[] {
  let %x_68: List[tensor_int64_t[]] = @map(@tensor_expand_dims_int64, %tensor_array50) /* ty=List[tensor_int64_t[]] */;
  let %x_69: tensor_int64_t[] = @hd(%x_68) /* ty=tensor_int64_t[] */;
  let %x_70: List[tensor_int64_t[]] = @tl(%x_68) /* ty=List[tensor_int64_t[]] */;
  let %x_71: tensor_int64_t[] = @foldl(@tensor_concatenate_int64, %x_69, %x_70) /* ty=tensor_int64_t[] */;
  %x_71
}

def @tensor_array_stack_int8(%tensor_array51: List[tensor_int8_t[]]) -> tensor_int8_t[] {
  let %x_56: List[tensor_int8_t[]] = @map(@tensor_expand_dims_int8, %tensor_array51) /* ty=List[tensor_int8_t[]] */;
  let %x_57: tensor_int8_t[] = @hd(%x_56) /* ty=tensor_int8_t[] */;
  let %x_58: List[tensor_int8_t[]] = @tl(%x_56) /* ty=List[tensor_int8_t[]] */;
  let %x_59: tensor_int8_t[] = @foldl(@tensor_concatenate_int8, %x_57, %x_58) /* ty=tensor_int8_t[] */;
  %x_59
}

def @tensor_array_stack_uint16(%tensor_array52: List[tensor_uint16_t[]]) -> tensor_uint16_t[] {
  let %x_64: List[tensor_uint16_t[]] = @map(@tensor_expand_dims_uint16, %tensor_array52) /* ty=List[tensor_uint16_t[]] */;
  let %x_65: tensor_uint16_t[] = @hd(%x_64) /* ty=tensor_uint16_t[] */;
  let %x_66: List[tensor_uint16_t[]] = @tl(%x_64) /* ty=List[tensor_uint16_t[]] */;
  let %x_67: tensor_uint16_t[] = @foldl(@tensor_concatenate_uint16, %x_65, %x_66) /* ty=tensor_uint16_t[] */;
  %x_67
}

def @tensor_array_stack_uint8(%tensor_array53: List[tensor_uint8_t[]]) -> tensor_uint8_t[] {
  let %x_52: List[tensor_uint8_t[]] = @map(@tensor_expand_dims_uint8, %tensor_array53) /* ty=List[tensor_uint8_t[]] */;
  let %x_53: tensor_uint8_t[] = @hd(%x_52) /* ty=tensor_uint8_t[] */;
  let %x_54: List[tensor_uint8_t[]] = @tl(%x_52) /* ty=List[tensor_uint8_t[]] */;
  let %x_55: tensor_uint8_t[] = @foldl(@tensor_concatenate_uint8, %x_53, %x_54) /* ty=tensor_uint8_t[] */;
  %x_55
}

def @tensor_array_uint16(%x28: int32) -> List[tensor_uint16_t[]] {
  %832 = equal(%x28, 0 /* ty=int32 */) /* ty=bool */;
  if (%832) {
    Nil /* ty=List[tensor_uint16_t[]] */
  } else {
    %833 = subtract(%x28, 1 /* ty=int32 */) /* ty=int32 */;
    %834 = tensor_nil_uint16 /* ty=tensor_uint16_t[] */;
    %835 = @tensor_array_uint16(%833) /* ty=List[tensor_uint16_t[]] */;
    Cons(%834, %835) /* ty=List[tensor_uint16_t[]] */
  }
}

def @tensor_array_uint8(%x29: int32) -> List[tensor_uint8_t[]] {
  %836 = equal(%x29, 0 /* ty=int32 */) /* ty=bool */;
  if (%836) {
    Nil /* ty=List[tensor_uint8_t[]] */
  } else {
    %837 = subtract(%x29, 1 /* ty=int32 */) /* ty=int32 */;
    %838 = tensor_nil_uint8 /* ty=tensor_uint8_t[] */;
    %839 = @tensor_array_uint8(%837) /* ty=List[tensor_uint8_t[]] */;
    Cons(%838, %839) /* ty=List[tensor_uint8_t[]] */
  }
}

def @tensor_array_unstack_tensor1_float16(%tensor: Tensor[(?), float16]) -> List[tensor_float16_t[]] {
  %840 = shape_of(%tensor, dtype="int32") /* ty=Tensor[(1), int32] */;
  %841 = take(%840, 0 /* ty=int32 */) /* ty=int32 */;
  @tensor_array_unstack_tensor1_helper_float16(0 /* ty=int32 */, %841, %tensor) /* ty=List[tensor_float16_t[]] */
}

def @tensor_array_unstack_tensor1_float32(%tensor1: Tensor[(?), float32]) -> List[tensor_float32_t[]] {
  %842 = shape_of(%tensor1, dtype="int32") /* ty=Tensor[(1), int32] */;
  %843 = take(%842, 0 /* ty=int32 */) /* ty=int32 */;
  @tensor_array_unstack_tensor1_helper_float32(0 /* ty=int32 */, %843, %tensor1) /* ty=List[tensor_float32_t[]] */
}

def @tensor_array_unstack_tensor1_float64(%tensor2: Tensor[(?), float64]) -> List[tensor_float64_t[]] {
  %844 = shape_of(%tensor2, dtype="int32") /* ty=Tensor[(1), int32] */;
  %845 = take(%844, 0 /* ty=int32 */) /* ty=int32 */;
  @tensor_array_unstack_tensor1_helper_float64(0 /* ty=int32 */, %845, %tensor2) /* ty=List[tensor_float64_t[]] */
}

def @tensor_array_unstack_tensor1_helper_float16(%i: int32, %up: int32, %t2: Tensor[(?), float16]) -> List[tensor_float16_t[]] {
  %846 = equal(%i, %up) /* ty=bool */;
  if (%846) {
    Nil /* ty=List[tensor_float16_t[]] */
  } else {
    %847 = take(%t2, %i) /* ty=float16 */;
    %848 = add(%i, 1 /* ty=int32 */) /* ty=int32 */;
    %849 = tensor0_float16(%847) /* ty=tensor_float16_t[] */;
    %850 = @tensor_array_unstack_tensor1_helper_float16(%848, %up, %t2) /* ty=List[tensor_float16_t[]] */;
    Cons(%849, %850) /* ty=List[tensor_float16_t[]] */
  }
}

def @tensor_array_unstack_tensor1_helper_float32(%i1: int32, %up1: int32, %t3: Tensor[(?), float32]) -> List[tensor_float32_t[]] {
  %851 = equal(%i1, %up1) /* ty=bool */;
  if (%851) {
    Nil /* ty=List[tensor_float32_t[]] */
  } else {
    %852 = take(%t3, %i1) /* ty=float32 */;
    %853 = add(%i1, 1 /* ty=int32 */) /* ty=int32 */;
    %854 = tensor0_float32(%852) /* ty=tensor_float32_t[] */;
    %855 = @tensor_array_unstack_tensor1_helper_float32(%853, %up1, %t3) /* ty=List[tensor_float32_t[]] */;
    Cons(%854, %855) /* ty=List[tensor_float32_t[]] */
  }
}

def @tensor_array_unstack_tensor1_helper_float64(%i2: int32, %up2: int32, %t4: Tensor[(?), float64]) -> List[tensor_float64_t[]] {
  %856 = equal(%i2, %up2) /* ty=bool */;
  if (%856) {
    Nil /* ty=List[tensor_float64_t[]] */
  } else {
    %857 = take(%t4, %i2) /* ty=float64 */;
    %858 = add(%i2, 1 /* ty=int32 */) /* ty=int32 */;
    %859 = tensor0_float64(%857) /* ty=tensor_float64_t[] */;
    %860 = @tensor_array_unstack_tensor1_helper_float64(%858, %up2, %t4) /* ty=List[tensor_float64_t[]] */;
    Cons(%859, %860) /* ty=List[tensor_float64_t[]] */
  }
}

def @tensor_array_unstack_tensor1_helper_int16(%i3: int32, %up3: int32, %t5: Tensor[(?), int16]) -> List[tensor_int16_t[]] {
  %861 = equal(%i3, %up3) /* ty=bool */;
  if (%861) {
    Nil /* ty=List[tensor_int16_t[]] */
  } else {
    %862 = take(%t5, %i3) /* ty=int16 */;
    %863 = add(%i3, 1 /* ty=int32 */) /* ty=int32 */;
    %864 = tensor0_int16(%862) /* ty=tensor_int16_t[] */;
    %865 = @tensor_array_unstack_tensor1_helper_int16(%863, %up3, %t5) /* ty=List[tensor_int16_t[]] */;
    Cons(%864, %865) /* ty=List[tensor_int16_t[]] */
  }
}

def @tensor_array_unstack_tensor1_helper_int32(%i4: int32, %up4: int32, %t6: Tensor[(?), int32]) -> List[tensor_int32_t[]] {
  %866 = equal(%i4, %up4) /* ty=bool */;
  if (%866) {
    Nil /* ty=List[tensor_int32_t[]] */
  } else {
    %867 = take(%t6, %i4) /* ty=int32 */;
    %868 = add(%i4, 1 /* ty=int32 */) /* ty=int32 */;
    %869 = tensor0_int32(%867) /* ty=tensor_int32_t[] */;
    %870 = @tensor_array_unstack_tensor1_helper_int32(%868, %up4, %t6) /* ty=List[tensor_int32_t[]] */;
    Cons(%869, %870) /* ty=List[tensor_int32_t[]] */
  }
}

def @tensor_array_unstack_tensor1_helper_int64(%i5: int32, %up5: int32, %t7: Tensor[(?), int64]) -> List[tensor_int64_t[]] {
  %871 = equal(%i5, %up5) /* ty=bool */;
  if (%871) {
    Nil /* ty=List[tensor_int64_t[]] */
  } else {
    %872 = take(%t7, %i5) /* ty=int64 */;
    %873 = add(%i5, 1 /* ty=int32 */) /* ty=int32 */;
    %874 = tensor0_int64(%872) /* ty=tensor_int64_t[] */;
    %875 = @tensor_array_unstack_tensor1_helper_int64(%873, %up5, %t7) /* ty=List[tensor_int64_t[]] */;
    Cons(%874, %875) /* ty=List[tensor_int64_t[]] */
  }
}

def @tensor_array_unstack_tensor1_helper_int8(%i6: int32, %up6: int32, %t8: Tensor[(?), int8]) -> List[tensor_int8_t[]] {
  %876 = equal(%i6, %up6) /* ty=bool */;
  if (%876) {
    Nil /* ty=List[tensor_int8_t[]] */
  } else {
    %877 = take(%t8, %i6) /* ty=int8 */;
    %878 = add(%i6, 1 /* ty=int32 */) /* ty=int32 */;
    %879 = tensor0_int8(%877) /* ty=tensor_int8_t[] */;
    %880 = @tensor_array_unstack_tensor1_helper_int8(%878, %up6, %t8) /* ty=List[tensor_int8_t[]] */;
    Cons(%879, %880) /* ty=List[tensor_int8_t[]] */
  }
}

def @tensor_array_unstack_tensor1_helper_uint16(%i7: int32, %up7: int32, %t9: Tensor[(?), uint16]) -> List[tensor_uint16_t[]] {
  %881 = equal(%i7, %up7) /* ty=bool */;
  if (%881) {
    Nil /* ty=List[tensor_uint16_t[]] */
  } else {
    %882 = take(%t9, %i7) /* ty=uint16 */;
    %883 = add(%i7, 1 /* ty=int32 */) /* ty=int32 */;
    %884 = tensor0_uint16(%882) /* ty=tensor_uint16_t[] */;
    %885 = @tensor_array_unstack_tensor1_helper_uint16(%883, %up7, %t9) /* ty=List[tensor_uint16_t[]] */;
    Cons(%884, %885) /* ty=List[tensor_uint16_t[]] */
  }
}

def @tensor_array_unstack_tensor1_helper_uint8(%i8: int32, %up8: int32, %t10: Tensor[(?), uint8]) -> List[tensor_uint8_t[]] {
  %886 = equal(%i8, %up8) /* ty=bool */;
  if (%886) {
    Nil /* ty=List[tensor_uint8_t[]] */
  } else {
    %887 = take(%t10, %i8) /* ty=uint8 */;
    %888 = add(%i8, 1 /* ty=int32 */) /* ty=int32 */;
    %889 = tensor0_uint8(%887) /* ty=tensor_uint8_t[] */;
    %890 = @tensor_array_unstack_tensor1_helper_uint8(%888, %up8, %t10) /* ty=List[tensor_uint8_t[]] */;
    Cons(%889, %890) /* ty=List[tensor_uint8_t[]] */
  }
}

def @tensor_array_unstack_tensor1_int16(%tensor3: Tensor[(?), int16]) -> List[tensor_int16_t[]] {
  %891 = shape_of(%tensor3, dtype="int32") /* ty=Tensor[(1), int32] */;
  %892 = take(%891, 0 /* ty=int32 */) /* ty=int32 */;
  @tensor_array_unstack_tensor1_helper_int16(0 /* ty=int32 */, %892, %tensor3) /* ty=List[tensor_int16_t[]] */
}

def @tensor_array_unstack_tensor1_int32(%tensor4: Tensor[(?), int32]) -> List[tensor_int32_t[]] {
  %893 = shape_of(%tensor4, dtype="int32") /* ty=Tensor[(1), int32] */;
  %894 = take(%893, 0 /* ty=int32 */) /* ty=int32 */;
  @tensor_array_unstack_tensor1_helper_int32(0 /* ty=int32 */, %894, %tensor4) /* ty=List[tensor_int32_t[]] */
}

def @tensor_array_unstack_tensor1_int64(%tensor5: Tensor[(?), int64]) -> List[tensor_int64_t[]] {
  %895 = shape_of(%tensor5, dtype="int32") /* ty=Tensor[(1), int32] */;
  %896 = take(%895, 0 /* ty=int32 */) /* ty=int32 */;
  @tensor_array_unstack_tensor1_helper_int64(0 /* ty=int32 */, %896, %tensor5) /* ty=List[tensor_int64_t[]] */
}

def @tensor_array_unstack_tensor1_int8(%tensor6: Tensor[(?), int8]) -> List[tensor_int8_t[]] {
  %897 = shape_of(%tensor6, dtype="int32") /* ty=Tensor[(1), int32] */;
  %898 = take(%897, 0 /* ty=int32 */) /* ty=int32 */;
  @tensor_array_unstack_tensor1_helper_int8(0 /* ty=int32 */, %898, %tensor6) /* ty=List[tensor_int8_t[]] */
}

def @tensor_array_unstack_tensor1_uint16(%tensor7: Tensor[(?), uint16]) -> List[tensor_uint16_t[]] {
  %899 = shape_of(%tensor7, dtype="int32") /* ty=Tensor[(1), int32] */;
  %900 = take(%899, 0 /* ty=int32 */) /* ty=int32 */;
  @tensor_array_unstack_tensor1_helper_uint16(0 /* ty=int32 */, %900, %tensor7) /* ty=List[tensor_uint16_t[]] */
}

def @tensor_array_unstack_tensor1_uint8(%tensor8: Tensor[(?), uint8]) -> List[tensor_uint8_t[]] {
  %901 = shape_of(%tensor8, dtype="int32") /* ty=Tensor[(1), int32] */;
  %902 = take(%901, 0 /* ty=int32 */) /* ty=int32 */;
  @tensor_array_unstack_tensor1_helper_uint8(0 /* ty=int32 */, %902, %tensor8) /* ty=List[tensor_uint8_t[]] */
}

def @tensor_array_unstack_tensor2_float16(%tensor9: Tensor[(?, ?), float16]) -> List[tensor_float16_t[]] {
  %903 = shape_of(%tensor9, dtype="int32") /* ty=Tensor[(2), int32] */;
  %904 = take(%903, 0 /* ty=int32 */) /* ty=int32 */;
  @tensor_array_unstack_tensor2_helper_float16(0 /* ty=int32 */, %904, %tensor9) /* ty=List[tensor_float16_t[]] */
}

def @tensor_array_unstack_tensor2_float32(%tensor10: Tensor[(?, ?), float32]) -> List[tensor_float32_t[]] {
  %905 = shape_of(%tensor10, dtype="int32") /* ty=Tensor[(2), int32] */;
  %906 = take(%905, 0 /* ty=int32 */) /* ty=int32 */;
  @tensor_array_unstack_tensor2_helper_float32(0 /* ty=int32 */, %906, %tensor10) /* ty=List[tensor_float32_t[]] */
}

def @tensor_array_unstack_tensor2_float64(%tensor11: Tensor[(?, ?), float64]) -> List[tensor_float64_t[]] {
  %907 = shape_of(%tensor11, dtype="int32") /* ty=Tensor[(2), int32] */;
  %908 = take(%907, 0 /* ty=int32 */) /* ty=int32 */;
  @tensor_array_unstack_tensor2_helper_float64(0 /* ty=int32 */, %908, %tensor11) /* ty=List[tensor_float64_t[]] */
}

def @tensor_array_unstack_tensor2_helper_float16(%i9: int32, %up9: int32, %t11: Tensor[(?, ?), float16]) -> List[tensor_float16_t[]] {
  %909 = equal(%i9, %up9) /* ty=bool */;
  if (%909) {
    Nil /* ty=List[tensor_float16_t[]] */
  } else {
    %910 = take(%t11, %i9, axis=0) /* ty=Tensor[(?), float16] */;
    %911 = add(%i9, 1 /* ty=int32 */) /* ty=int32 */;
    %912 = tensor1_float16(%910) /* ty=tensor_float16_t[] */;
    %913 = @tensor_array_unstack_tensor2_helper_float16(%911, %up9, %t11) /* ty=List[tensor_float16_t[]] */;
    Cons(%912, %913) /* ty=List[tensor_float16_t[]] */
  }
}

def @tensor_array_unstack_tensor2_helper_float32(%i10: int32, %up10: int32, %t12: Tensor[(?, ?), float32]) -> List[tensor_float32_t[]] {
  %914 = equal(%i10, %up10) /* ty=bool */;
  if (%914) {
    Nil /* ty=List[tensor_float32_t[]] */
  } else {
    %915 = take(%t12, %i10, axis=0) /* ty=Tensor[(?), float32] */;
    %916 = add(%i10, 1 /* ty=int32 */) /* ty=int32 */;
    %917 = tensor1_float32(%915) /* ty=tensor_float32_t[] */;
    %918 = @tensor_array_unstack_tensor2_helper_float32(%916, %up10, %t12) /* ty=List[tensor_float32_t[]] */;
    Cons(%917, %918) /* ty=List[tensor_float32_t[]] */
  }
}

def @tensor_array_unstack_tensor2_helper_float64(%i11: int32, %up11: int32, %t13: Tensor[(?, ?), float64]) -> List[tensor_float64_t[]] {
  %919 = equal(%i11, %up11) /* ty=bool */;
  if (%919) {
    Nil /* ty=List[tensor_float64_t[]] */
  } else {
    %920 = take(%t13, %i11, axis=0) /* ty=Tensor[(?), float64] */;
    %921 = add(%i11, 1 /* ty=int32 */) /* ty=int32 */;
    %922 = tensor1_float64(%920) /* ty=tensor_float64_t[] */;
    %923 = @tensor_array_unstack_tensor2_helper_float64(%921, %up11, %t13) /* ty=List[tensor_float64_t[]] */;
    Cons(%922, %923) /* ty=List[tensor_float64_t[]] */
  }
}

def @tensor_array_unstack_tensor2_helper_int16(%i12: int32, %up12: int32, %t14: Tensor[(?, ?), int16]) -> List[tensor_int16_t[]] {
  %924 = equal(%i12, %up12) /* ty=bool */;
  if (%924) {
    Nil /* ty=List[tensor_int16_t[]] */
  } else {
    %925 = take(%t14, %i12, axis=0) /* ty=Tensor[(?), int16] */;
    %926 = add(%i12, 1 /* ty=int32 */) /* ty=int32 */;
    %927 = tensor1_int16(%925) /* ty=tensor_int16_t[] */;
    %928 = @tensor_array_unstack_tensor2_helper_int16(%926, %up12, %t14) /* ty=List[tensor_int16_t[]] */;
    Cons(%927, %928) /* ty=List[tensor_int16_t[]] */
  }
}

def @tensor_array_unstack_tensor2_helper_int32(%i13: int32, %up13: int32, %t15: Tensor[(?, ?), int32]) -> List[tensor_int32_t[]] {
  %929 = equal(%i13, %up13) /* ty=bool */;
  if (%929) {
    Nil /* ty=List[tensor_int32_t[]] */
  } else {
    %930 = take(%t15, %i13, axis=0) /* ty=Tensor[(?), int32] */;
    %931 = add(%i13, 1 /* ty=int32 */) /* ty=int32 */;
    %932 = tensor1_int32(%930) /* ty=tensor_int32_t[] */;
    %933 = @tensor_array_unstack_tensor2_helper_int32(%931, %up13, %t15) /* ty=List[tensor_int32_t[]] */;
    Cons(%932, %933) /* ty=List[tensor_int32_t[]] */
  }
}

def @tensor_array_unstack_tensor2_helper_int64(%i14: int32, %up14: int32, %t16: Tensor[(?, ?), int64]) -> List[tensor_int64_t[]] {
  %934 = equal(%i14, %up14) /* ty=bool */;
  if (%934) {
    Nil /* ty=List[tensor_int64_t[]] */
  } else {
    %935 = take(%t16, %i14, axis=0) /* ty=Tensor[(?), int64] */;
    %936 = add(%i14, 1 /* ty=int32 */) /* ty=int32 */;
    %937 = tensor1_int64(%935) /* ty=tensor_int64_t[] */;
    %938 = @tensor_array_unstack_tensor2_helper_int64(%936, %up14, %t16) /* ty=List[tensor_int64_t[]] */;
    Cons(%937, %938) /* ty=List[tensor_int64_t[]] */
  }
}

def @tensor_array_unstack_tensor2_helper_int8(%i15: int32, %up15: int32, %t17: Tensor[(?, ?), int8]) -> List[tensor_int8_t[]] {
  %939 = equal(%i15, %up15) /* ty=bool */;
  if (%939) {
    Nil /* ty=List[tensor_int8_t[]] */
  } else {
    %940 = take(%t17, %i15, axis=0) /* ty=Tensor[(?), int8] */;
    %941 = add(%i15, 1 /* ty=int32 */) /* ty=int32 */;
    %942 = tensor1_int8(%940) /* ty=tensor_int8_t[] */;
    %943 = @tensor_array_unstack_tensor2_helper_int8(%941, %up15, %t17) /* ty=List[tensor_int8_t[]] */;
    Cons(%942, %943) /* ty=List[tensor_int8_t[]] */
  }
}

def @tensor_array_unstack_tensor2_helper_uint16(%i16: int32, %up16: int32, %t18: Tensor[(?, ?), uint16]) -> List[tensor_uint16_t[]] {
  %944 = equal(%i16, %up16) /* ty=bool */;
  if (%944) {
    Nil /* ty=List[tensor_uint16_t[]] */
  } else {
    %945 = take(%t18, %i16, axis=0) /* ty=Tensor[(?), uint16] */;
    %946 = add(%i16, 1 /* ty=int32 */) /* ty=int32 */;
    %947 = tensor1_uint16(%945) /* ty=tensor_uint16_t[] */;
    %948 = @tensor_array_unstack_tensor2_helper_uint16(%946, %up16, %t18) /* ty=List[tensor_uint16_t[]] */;
    Cons(%947, %948) /* ty=List[tensor_uint16_t[]] */
  }
}

def @tensor_array_unstack_tensor2_helper_uint8(%i17: int32, %up17: int32, %t19: Tensor[(?, ?), uint8]) -> List[tensor_uint8_t[]] {
  %949 = equal(%i17, %up17) /* ty=bool */;
  if (%949) {
    Nil /* ty=List[tensor_uint8_t[]] */
  } else {
    %950 = take(%t19, %i17, axis=0) /* ty=Tensor[(?), uint8] */;
    %951 = add(%i17, 1 /* ty=int32 */) /* ty=int32 */;
    %952 = tensor1_uint8(%950) /* ty=tensor_uint8_t[] */;
    %953 = @tensor_array_unstack_tensor2_helper_uint8(%951, %up17, %t19) /* ty=List[tensor_uint8_t[]] */;
    Cons(%952, %953) /* ty=List[tensor_uint8_t[]] */
  }
}

def @tensor_array_unstack_tensor2_int16(%tensor12: Tensor[(?, ?), int16]) -> List[tensor_int16_t[]] {
  %954 = shape_of(%tensor12, dtype="int32") /* ty=Tensor[(2), int32] */;
  %955 = take(%954, 0 /* ty=int32 */) /* ty=int32 */;
  @tensor_array_unstack_tensor2_helper_int16(0 /* ty=int32 */, %955, %tensor12) /* ty=List[tensor_int16_t[]] */
}

def @tensor_array_unstack_tensor2_int32(%tensor13: Tensor[(?, ?), int32]) -> List[tensor_int32_t[]] {
  %956 = shape_of(%tensor13, dtype="int32") /* ty=Tensor[(2), int32] */;
  %957 = take(%956, 0 /* ty=int32 */) /* ty=int32 */;
  @tensor_array_unstack_tensor2_helper_int32(0 /* ty=int32 */, %957, %tensor13) /* ty=List[tensor_int32_t[]] */
}

def @tensor_array_unstack_tensor2_int64(%tensor14: Tensor[(?, ?), int64]) -> List[tensor_int64_t[]] {
  %958 = shape_of(%tensor14, dtype="int32") /* ty=Tensor[(2), int32] */;
  %959 = take(%958, 0 /* ty=int32 */) /* ty=int32 */;
  @tensor_array_unstack_tensor2_helper_int64(0 /* ty=int32 */, %959, %tensor14) /* ty=List[tensor_int64_t[]] */
}

def @tensor_array_unstack_tensor2_int8(%tensor15: Tensor[(?, ?), int8]) -> List[tensor_int8_t[]] {
  %960 = shape_of(%tensor15, dtype="int32") /* ty=Tensor[(2), int32] */;
  %961 = take(%960, 0 /* ty=int32 */) /* ty=int32 */;
  @tensor_array_unstack_tensor2_helper_int8(0 /* ty=int32 */, %961, %tensor15) /* ty=List[tensor_int8_t[]] */
}

def @tensor_array_unstack_tensor2_uint16(%tensor16: Tensor[(?, ?), uint16]) -> List[tensor_uint16_t[]] {
  %962 = shape_of(%tensor16, dtype="int32") /* ty=Tensor[(2), int32] */;
  %963 = take(%962, 0 /* ty=int32 */) /* ty=int32 */;
  @tensor_array_unstack_tensor2_helper_uint16(0 /* ty=int32 */, %963, %tensor16) /* ty=List[tensor_uint16_t[]] */
}

def @tensor_array_unstack_tensor2_uint8(%tensor17: Tensor[(?, ?), uint8]) -> List[tensor_uint8_t[]] {
  %964 = shape_of(%tensor17, dtype="int32") /* ty=Tensor[(2), int32] */;
  %965 = take(%964, 0 /* ty=int32 */) /* ty=int32 */;
  @tensor_array_unstack_tensor2_helper_uint8(0 /* ty=int32 */, %965, %tensor17) /* ty=List[tensor_uint8_t[]] */
}

def @tensor_array_unstack_tensor3_float16(%tensor18: Tensor[(?, ?, ?), float16]) -> List[tensor_float16_t[]] {
  %966 = shape_of(%tensor18, dtype="int32") /* ty=Tensor[(3), int32] */;
  %967 = take(%966, 0 /* ty=int32 */) /* ty=int32 */;
  @tensor_array_unstack_tensor3_helper_float16(0 /* ty=int32 */, %967, %tensor18) /* ty=List[tensor_float16_t[]] */
}

def @tensor_array_unstack_tensor3_float32(%tensor19: Tensor[(?, ?, ?), float32]) -> List[tensor_float32_t[]] {
  %968 = shape_of(%tensor19, dtype="int32") /* ty=Tensor[(3), int32] */;
  %969 = take(%968, 0 /* ty=int32 */) /* ty=int32 */;
  @tensor_array_unstack_tensor3_helper_float32(0 /* ty=int32 */, %969, %tensor19) /* ty=List[tensor_float32_t[]] */
}

def @tensor_array_unstack_tensor3_float64(%tensor20: Tensor[(?, ?, ?), float64]) -> List[tensor_float64_t[]] {
  %970 = shape_of(%tensor20, dtype="int32") /* ty=Tensor[(3), int32] */;
  %971 = take(%970, 0 /* ty=int32 */) /* ty=int32 */;
  @tensor_array_unstack_tensor3_helper_float64(0 /* ty=int32 */, %971, %tensor20) /* ty=List[tensor_float64_t[]] */
}

def @tensor_array_unstack_tensor3_helper_float16(%i18: int32, %up18: int32, %t20: Tensor[(?, ?, ?), float16]) -> List[tensor_float16_t[]] {
  %972 = equal(%i18, %up18) /* ty=bool */;
  if (%972) {
    Nil /* ty=List[tensor_float16_t[]] */
  } else {
    %973 = take(%t20, %i18, axis=0) /* ty=Tensor[(?, ?), float16] */;
    %974 = add(%i18, 1 /* ty=int32 */) /* ty=int32 */;
    %975 = tensor2_float16(%973) /* ty=tensor_float16_t[] */;
    %976 = @tensor_array_unstack_tensor3_helper_float16(%974, %up18, %t20) /* ty=List[tensor_float16_t[]] */;
    Cons(%975, %976) /* ty=List[tensor_float16_t[]] */
  }
}

def @tensor_array_unstack_tensor3_helper_float32(%i19: int32, %up19: int32, %t21: Tensor[(?, ?, ?), float32]) -> List[tensor_float32_t[]] {
  %977 = equal(%i19, %up19) /* ty=bool */;
  if (%977) {
    Nil /* ty=List[tensor_float32_t[]] */
  } else {
    %978 = take(%t21, %i19, axis=0) /* ty=Tensor[(?, ?), float32] */;
    %979 = add(%i19, 1 /* ty=int32 */) /* ty=int32 */;
    %980 = tensor2_float32(%978) /* ty=tensor_float32_t[] */;
    %981 = @tensor_array_unstack_tensor3_helper_float32(%979, %up19, %t21) /* ty=List[tensor_float32_t[]] */;
    Cons(%980, %981) /* ty=List[tensor_float32_t[]] */
  }
}

def @tensor_array_unstack_tensor3_helper_float64(%i20: int32, %up20: int32, %t22: Tensor[(?, ?, ?), float64]) -> List[tensor_float64_t[]] {
  %982 = equal(%i20, %up20) /* ty=bool */;
  if (%982) {
    Nil /* ty=List[tensor_float64_t[]] */
  } else {
    %983 = take(%t22, %i20, axis=0) /* ty=Tensor[(?, ?), float64] */;
    %984 = add(%i20, 1 /* ty=int32 */) /* ty=int32 */;
    %985 = tensor2_float64(%983) /* ty=tensor_float64_t[] */;
    %986 = @tensor_array_unstack_tensor3_helper_float64(%984, %up20, %t22) /* ty=List[tensor_float64_t[]] */;
    Cons(%985, %986) /* ty=List[tensor_float64_t[]] */
  }
}

def @tensor_array_unstack_tensor3_helper_int16(%i21: int32, %up21: int32, %t23: Tensor[(?, ?, ?), int16]) -> List[tensor_int16_t[]] {
  %987 = equal(%i21, %up21) /* ty=bool */;
  if (%987) {
    Nil /* ty=List[tensor_int16_t[]] */
  } else {
    %988 = take(%t23, %i21, axis=0) /* ty=Tensor[(?, ?), int16] */;
    %989 = add(%i21, 1 /* ty=int32 */) /* ty=int32 */;
    %990 = tensor2_int16(%988) /* ty=tensor_int16_t[] */;
    %991 = @tensor_array_unstack_tensor3_helper_int16(%989, %up21, %t23) /* ty=List[tensor_int16_t[]] */;
    Cons(%990, %991) /* ty=List[tensor_int16_t[]] */
  }
}

def @tensor_array_unstack_tensor3_helper_int32(%i22: int32, %up22: int32, %t24: Tensor[(?, ?, ?), int32]) -> List[tensor_int32_t[]] {
  %992 = equal(%i22, %up22) /* ty=bool */;
  if (%992) {
    Nil /* ty=List[tensor_int32_t[]] */
  } else {
    %993 = take(%t24, %i22, axis=0) /* ty=Tensor[(?, ?), int32] */;
    %994 = add(%i22, 1 /* ty=int32 */) /* ty=int32 */;
    %995 = tensor2_int32(%993) /* ty=tensor_int32_t[] */;
    %996 = @tensor_array_unstack_tensor3_helper_int32(%994, %up22, %t24) /* ty=List[tensor_int32_t[]] */;
    Cons(%995, %996) /* ty=List[tensor_int32_t[]] */
  }
}

def @tensor_array_unstack_tensor3_helper_int64(%i23: int32, %up23: int32, %t25: Tensor[(?, ?, ?), int64]) -> List[tensor_int64_t[]] {
  %997 = equal(%i23, %up23) /* ty=bool */;
  if (%997) {
    Nil /* ty=List[tensor_int64_t[]] */
  } else {
    %998 = take(%t25, %i23, axis=0) /* ty=Tensor[(?, ?), int64] */;
    %999 = add(%i23, 1 /* ty=int32 */) /* ty=int32 */;
    %1000 = tensor2_int64(%998) /* ty=tensor_int64_t[] */;
    %1001 = @tensor_array_unstack_tensor3_helper_int64(%999, %up23, %t25) /* ty=List[tensor_int64_t[]] */;
    Cons(%1000, %1001) /* ty=List[tensor_int64_t[]] */
  }
}

def @tensor_array_unstack_tensor3_helper_int8(%i24: int32, %up24: int32, %t26: Tensor[(?, ?, ?), int8]) -> List[tensor_int8_t[]] {
  %1002 = equal(%i24, %up24) /* ty=bool */;
  if (%1002) {
    Nil /* ty=List[tensor_int8_t[]] */
  } else {
    %1003 = take(%t26, %i24, axis=0) /* ty=Tensor[(?, ?), int8] */;
    %1004 = add(%i24, 1 /* ty=int32 */) /* ty=int32 */;
    %1005 = tensor2_int8(%1003) /* ty=tensor_int8_t[] */;
    %1006 = @tensor_array_unstack_tensor3_helper_int8(%1004, %up24, %t26) /* ty=List[tensor_int8_t[]] */;
    Cons(%1005, %1006) /* ty=List[tensor_int8_t[]] */
  }
}

def @tensor_array_unstack_tensor3_helper_uint16(%i25: int32, %up25: int32, %t27: Tensor[(?, ?, ?), uint16]) -> List[tensor_uint16_t[]] {
  %1007 = equal(%i25, %up25) /* ty=bool */;
  if (%1007) {
    Nil /* ty=List[tensor_uint16_t[]] */
  } else {
    %1008 = take(%t27, %i25, axis=0) /* ty=Tensor[(?, ?), uint16] */;
    %1009 = add(%i25, 1 /* ty=int32 */) /* ty=int32 */;
    %1010 = tensor2_uint16(%1008) /* ty=tensor_uint16_t[] */;
    %1011 = @tensor_array_unstack_tensor3_helper_uint16(%1009, %up25, %t27) /* ty=List[tensor_uint16_t[]] */;
    Cons(%1010, %1011) /* ty=List[tensor_uint16_t[]] */
  }
}

def @tensor_array_unstack_tensor3_helper_uint8(%i26: int32, %up26: int32, %t28: Tensor[(?, ?, ?), uint8]) -> List[tensor_uint8_t[]] {
  %1012 = equal(%i26, %up26) /* ty=bool */;
  if (%1012) {
    Nil /* ty=List[tensor_uint8_t[]] */
  } else {
    %1013 = take(%t28, %i26, axis=0) /* ty=Tensor[(?, ?), uint8] */;
    %1014 = add(%i26, 1 /* ty=int32 */) /* ty=int32 */;
    %1015 = tensor2_uint8(%1013) /* ty=tensor_uint8_t[] */;
    %1016 = @tensor_array_unstack_tensor3_helper_uint8(%1014, %up26, %t28) /* ty=List[tensor_uint8_t[]] */;
    Cons(%1015, %1016) /* ty=List[tensor_uint8_t[]] */
  }
}

def @tensor_array_unstack_tensor3_int16(%tensor21: Tensor[(?, ?, ?), int16]) -> List[tensor_int16_t[]] {
  %1017 = shape_of(%tensor21, dtype="int32") /* ty=Tensor[(3), int32] */;
  %1018 = take(%1017, 0 /* ty=int32 */) /* ty=int32 */;
  @tensor_array_unstack_tensor3_helper_int16(0 /* ty=int32 */, %1018, %tensor21) /* ty=List[tensor_int16_t[]] */
}

def @tensor_array_unstack_tensor3_int32(%tensor22: Tensor[(?, ?, ?), int32]) -> List[tensor_int32_t[]] {
  %1019 = shape_of(%tensor22, dtype="int32") /* ty=Tensor[(3), int32] */;
  %1020 = take(%1019, 0 /* ty=int32 */) /* ty=int32 */;
  @tensor_array_unstack_tensor3_helper_int32(0 /* ty=int32 */, %1020, %tensor22) /* ty=List[tensor_int32_t[]] */
}

def @tensor_array_unstack_tensor3_int64(%tensor23: Tensor[(?, ?, ?), int64]) -> List[tensor_int64_t[]] {
  %1021 = shape_of(%tensor23, dtype="int32") /* ty=Tensor[(3), int32] */;
  %1022 = take(%1021, 0 /* ty=int32 */) /* ty=int32 */;
  @tensor_array_unstack_tensor3_helper_int64(0 /* ty=int32 */, %1022, %tensor23) /* ty=List[tensor_int64_t[]] */
}

def @tensor_array_unstack_tensor3_int8(%tensor24: Tensor[(?, ?, ?), int8]) -> List[tensor_int8_t[]] {
  %1023 = shape_of(%tensor24, dtype="int32") /* ty=Tensor[(3), int32] */;
  %1024 = take(%1023, 0 /* ty=int32 */) /* ty=int32 */;
  @tensor_array_unstack_tensor3_helper_int8(0 /* ty=int32 */, %1024, %tensor24) /* ty=List[tensor_int8_t[]] */
}

def @tensor_array_unstack_tensor3_uint16(%tensor25: Tensor[(?, ?, ?), uint16]) -> List[tensor_uint16_t[]] {
  %1025 = shape_of(%tensor25, dtype="int32") /* ty=Tensor[(3), int32] */;
  %1026 = take(%1025, 0 /* ty=int32 */) /* ty=int32 */;
  @tensor_array_unstack_tensor3_helper_uint16(0 /* ty=int32 */, %1026, %tensor25) /* ty=List[tensor_uint16_t[]] */
}

def @tensor_array_unstack_tensor3_uint8(%tensor26: Tensor[(?, ?, ?), uint8]) -> List[tensor_uint8_t[]] {
  %1027 = shape_of(%tensor26, dtype="int32") /* ty=Tensor[(3), int32] */;
  %1028 = take(%1027, 0 /* ty=int32 */) /* ty=int32 */;
  @tensor_array_unstack_tensor3_helper_uint8(0 /* ty=int32 */, %1028, %tensor26) /* ty=List[tensor_uint8_t[]] */
}

def @tensor_array_unstack_tensor4_float16(%tensor27: Tensor[(?, ?, ?, ?), float16]) -> List[tensor_float16_t[]] {
  %1029 = shape_of(%tensor27, dtype="int32") /* ty=Tensor[(4), int32] */;
  %1030 = take(%1029, 0 /* ty=int32 */) /* ty=int32 */;
  @tensor_array_unstack_tensor4_helper_float16(0 /* ty=int32 */, %1030, %tensor27) /* ty=List[tensor_float16_t[]] */
}

def @tensor_array_unstack_tensor4_float32(%tensor28: Tensor[(?, ?, ?, ?), float32]) -> List[tensor_float32_t[]] {
  %1031 = shape_of(%tensor28, dtype="int32") /* ty=Tensor[(4), int32] */;
  %1032 = take(%1031, 0 /* ty=int32 */) /* ty=int32 */;
  @tensor_array_unstack_tensor4_helper_float32(0 /* ty=int32 */, %1032, %tensor28) /* ty=List[tensor_float32_t[]] */
}

def @tensor_array_unstack_tensor4_float64(%tensor29: Tensor[(?, ?, ?, ?), float64]) -> List[tensor_float64_t[]] {
  %1033 = shape_of(%tensor29, dtype="int32") /* ty=Tensor[(4), int32] */;
  %1034 = take(%1033, 0 /* ty=int32 */) /* ty=int32 */;
  @tensor_array_unstack_tensor4_helper_float64(0 /* ty=int32 */, %1034, %tensor29) /* ty=List[tensor_float64_t[]] */
}

def @tensor_array_unstack_tensor4_helper_float16(%i27: int32, %up27: int32, %t29: Tensor[(?, ?, ?, ?), float16]) -> List[tensor_float16_t[]] {
  %1035 = equal(%i27, %up27) /* ty=bool */;
  if (%1035) {
    Nil /* ty=List[tensor_float16_t[]] */
  } else {
    %1036 = take(%t29, %i27, axis=0) /* ty=Tensor[(?, ?, ?), float16] */;
    %1037 = add(%i27, 1 /* ty=int32 */) /* ty=int32 */;
    %1038 = tensor3_float16(%1036) /* ty=tensor_float16_t[] */;
    %1039 = @tensor_array_unstack_tensor4_helper_float16(%1037, %up27, %t29) /* ty=List[tensor_float16_t[]] */;
    Cons(%1038, %1039) /* ty=List[tensor_float16_t[]] */
  }
}

def @tensor_array_unstack_tensor4_helper_float32(%i28: int32, %up28: int32, %t30: Tensor[(?, ?, ?, ?), float32]) -> List[tensor_float32_t[]] {
  %1040 = equal(%i28, %up28) /* ty=bool */;
  if (%1040) {
    Nil /* ty=List[tensor_float32_t[]] */
  } else {
    %1041 = take(%t30, %i28, axis=0) /* ty=Tensor[(?, ?, ?), float32] */;
    %1042 = add(%i28, 1 /* ty=int32 */) /* ty=int32 */;
    %1043 = tensor3_float32(%1041) /* ty=tensor_float32_t[] */;
    %1044 = @tensor_array_unstack_tensor4_helper_float32(%1042, %up28, %t30) /* ty=List[tensor_float32_t[]] */;
    Cons(%1043, %1044) /* ty=List[tensor_float32_t[]] */
  }
}

def @tensor_array_unstack_tensor4_helper_float64(%i29: int32, %up29: int32, %t31: Tensor[(?, ?, ?, ?), float64]) -> List[tensor_float64_t[]] {
  %1045 = equal(%i29, %up29) /* ty=bool */;
  if (%1045) {
    Nil /* ty=List[tensor_float64_t[]] */
  } else {
    %1046 = take(%t31, %i29, axis=0) /* ty=Tensor[(?, ?, ?), float64] */;
    %1047 = add(%i29, 1 /* ty=int32 */) /* ty=int32 */;
    %1048 = tensor3_float64(%1046) /* ty=tensor_float64_t[] */;
    %1049 = @tensor_array_unstack_tensor4_helper_float64(%1047, %up29, %t31) /* ty=List[tensor_float64_t[]] */;
    Cons(%1048, %1049) /* ty=List[tensor_float64_t[]] */
  }
}

def @tensor_array_unstack_tensor4_helper_int16(%i30: int32, %up30: int32, %t32: Tensor[(?, ?, ?, ?), int16]) -> List[tensor_int16_t[]] {
  %1050 = equal(%i30, %up30) /* ty=bool */;
  if (%1050) {
    Nil /* ty=List[tensor_int16_t[]] */
  } else {
    %1051 = take(%t32, %i30, axis=0) /* ty=Tensor[(?, ?, ?), int16] */;
    %1052 = add(%i30, 1 /* ty=int32 */) /* ty=int32 */;
    %1053 = tensor3_int16(%1051) /* ty=tensor_int16_t[] */;
    %1054 = @tensor_array_unstack_tensor4_helper_int16(%1052, %up30, %t32) /* ty=List[tensor_int16_t[]] */;
    Cons(%1053, %1054) /* ty=List[tensor_int16_t[]] */
  }
}

def @tensor_array_unstack_tensor4_helper_int32(%i31: int32, %up31: int32, %t33: Tensor[(?, ?, ?, ?), int32]) -> List[tensor_int32_t[]] {
  %1055 = equal(%i31, %up31) /* ty=bool */;
  if (%1055) {
    Nil /* ty=List[tensor_int32_t[]] */
  } else {
    %1056 = take(%t33, %i31, axis=0) /* ty=Tensor[(?, ?, ?), int32] */;
    %1057 = add(%i31, 1 /* ty=int32 */) /* ty=int32 */;
    %1058 = tensor3_int32(%1056) /* ty=tensor_int32_t[] */;
    %1059 = @tensor_array_unstack_tensor4_helper_int32(%1057, %up31, %t33) /* ty=List[tensor_int32_t[]] */;
    Cons(%1058, %1059) /* ty=List[tensor_int32_t[]] */
  }
}

def @tensor_array_unstack_tensor4_helper_int64(%i32: int32, %up32: int32, %t34: Tensor[(?, ?, ?, ?), int64]) -> List[tensor_int64_t[]] {
  %1060 = equal(%i32, %up32) /* ty=bool */;
  if (%1060) {
    Nil /* ty=List[tensor_int64_t[]] */
  } else {
    %1061 = take(%t34, %i32, axis=0) /* ty=Tensor[(?, ?, ?), int64] */;
    %1062 = add(%i32, 1 /* ty=int32 */) /* ty=int32 */;
    %1063 = tensor3_int64(%1061) /* ty=tensor_int64_t[] */;
    %1064 = @tensor_array_unstack_tensor4_helper_int64(%1062, %up32, %t34) /* ty=List[tensor_int64_t[]] */;
    Cons(%1063, %1064) /* ty=List[tensor_int64_t[]] */
  }
}

def @tensor_array_unstack_tensor4_helper_int8(%i33: int32, %up33: int32, %t35: Tensor[(?, ?, ?, ?), int8]) -> List[tensor_int8_t[]] {
  %1065 = equal(%i33, %up33) /* ty=bool */;
  if (%1065) {
    Nil /* ty=List[tensor_int8_t[]] */
  } else {
    %1066 = take(%t35, %i33, axis=0) /* ty=Tensor[(?, ?, ?), int8] */;
    %1067 = add(%i33, 1 /* ty=int32 */) /* ty=int32 */;
    %1068 = tensor3_int8(%1066) /* ty=tensor_int8_t[] */;
    %1069 = @tensor_array_unstack_tensor4_helper_int8(%1067, %up33, %t35) /* ty=List[tensor_int8_t[]] */;
    Cons(%1068, %1069) /* ty=List[tensor_int8_t[]] */
  }
}

def @tensor_array_unstack_tensor4_helper_uint16(%i34: int32, %up34: int32, %t36: Tensor[(?, ?, ?, ?), uint16]) -> List[tensor_uint16_t[]] {
  %1070 = equal(%i34, %up34) /* ty=bool */;
  if (%1070) {
    Nil /* ty=List[tensor_uint16_t[]] */
  } else {
    %1071 = take(%t36, %i34, axis=0) /* ty=Tensor[(?, ?, ?), uint16] */;
    %1072 = add(%i34, 1 /* ty=int32 */) /* ty=int32 */;
    %1073 = tensor3_uint16(%1071) /* ty=tensor_uint16_t[] */;
    %1074 = @tensor_array_unstack_tensor4_helper_uint16(%1072, %up34, %t36) /* ty=List[tensor_uint16_t[]] */;
    Cons(%1073, %1074) /* ty=List[tensor_uint16_t[]] */
  }
}

def @tensor_array_unstack_tensor4_helper_uint8(%i35: int32, %up35: int32, %t37: Tensor[(?, ?, ?, ?), uint8]) -> List[tensor_uint8_t[]] {
  %1075 = equal(%i35, %up35) /* ty=bool */;
  if (%1075) {
    Nil /* ty=List[tensor_uint8_t[]] */
  } else {
    %1076 = take(%t37, %i35, axis=0) /* ty=Tensor[(?, ?, ?), uint8] */;
    %1077 = add(%i35, 1 /* ty=int32 */) /* ty=int32 */;
    %1078 = tensor3_uint8(%1076) /* ty=tensor_uint8_t[] */;
    %1079 = @tensor_array_unstack_tensor4_helper_uint8(%1077, %up35, %t37) /* ty=List[tensor_uint8_t[]] */;
    Cons(%1078, %1079) /* ty=List[tensor_uint8_t[]] */
  }
}

def @tensor_array_unstack_tensor4_int16(%tensor30: Tensor[(?, ?, ?, ?), int16]) -> List[tensor_int16_t[]] {
  %1080 = shape_of(%tensor30, dtype="int32") /* ty=Tensor[(4), int32] */;
  %1081 = take(%1080, 0 /* ty=int32 */) /* ty=int32 */;
  @tensor_array_unstack_tensor4_helper_int16(0 /* ty=int32 */, %1081, %tensor30) /* ty=List[tensor_int16_t[]] */
}

def @tensor_array_unstack_tensor4_int32(%tensor31: Tensor[(?, ?, ?, ?), int32]) -> List[tensor_int32_t[]] {
  %1082 = shape_of(%tensor31, dtype="int32") /* ty=Tensor[(4), int32] */;
  %1083 = take(%1082, 0 /* ty=int32 */) /* ty=int32 */;
  @tensor_array_unstack_tensor4_helper_int32(0 /* ty=int32 */, %1083, %tensor31) /* ty=List[tensor_int32_t[]] */
}

def @tensor_array_unstack_tensor4_int64(%tensor32: Tensor[(?, ?, ?, ?), int64]) -> List[tensor_int64_t[]] {
  %1084 = shape_of(%tensor32, dtype="int32") /* ty=Tensor[(4), int32] */;
  %1085 = take(%1084, 0 /* ty=int32 */) /* ty=int32 */;
  @tensor_array_unstack_tensor4_helper_int64(0 /* ty=int32 */, %1085, %tensor32) /* ty=List[tensor_int64_t[]] */
}

def @tensor_array_unstack_tensor4_int8(%tensor33: Tensor[(?, ?, ?, ?), int8]) -> List[tensor_int8_t[]] {
  %1086 = shape_of(%tensor33, dtype="int32") /* ty=Tensor[(4), int32] */;
  %1087 = take(%1086, 0 /* ty=int32 */) /* ty=int32 */;
  @tensor_array_unstack_tensor4_helper_int8(0 /* ty=int32 */, %1087, %tensor33) /* ty=List[tensor_int8_t[]] */
}

def @tensor_array_unstack_tensor4_uint16(%tensor34: Tensor[(?, ?, ?, ?), uint16]) -> List[tensor_uint16_t[]] {
  %1088 = shape_of(%tensor34, dtype="int32") /* ty=Tensor[(4), int32] */;
  %1089 = take(%1088, 0 /* ty=int32 */) /* ty=int32 */;
  @tensor_array_unstack_tensor4_helper_uint16(0 /* ty=int32 */, %1089, %tensor34) /* ty=List[tensor_uint16_t[]] */
}

def @tensor_array_unstack_tensor4_uint8(%tensor35: Tensor[(?, ?, ?, ?), uint8]) -> List[tensor_uint8_t[]] {
  %1090 = shape_of(%tensor35, dtype="int32") /* ty=Tensor[(4), int32] */;
  %1091 = take(%1090, 0 /* ty=int32 */) /* ty=int32 */;
  @tensor_array_unstack_tensor4_helper_uint8(0 /* ty=int32 */, %1091, %tensor35) /* ty=List[tensor_uint8_t[]] */
}

def @tensor_array_unstack_tensor5_float16(%tensor36: Tensor[(?, ?, ?, ?, ?), float16]) -> List[tensor_float16_t[]] {
  %1092 = shape_of(%tensor36, dtype="int32") /* ty=Tensor[(5), int32] */;
  %1093 = take(%1092, 0 /* ty=int32 */) /* ty=int32 */;
  @tensor_array_unstack_tensor5_helper_float16(0 /* ty=int32 */, %1093, %tensor36) /* ty=List[tensor_float16_t[]] */
}

def @tensor_array_unstack_tensor5_float32(%tensor37: Tensor[(?, ?, ?, ?, ?), float32]) -> List[tensor_float32_t[]] {
  %1094 = shape_of(%tensor37, dtype="int32") /* ty=Tensor[(5), int32] */;
  %1095 = take(%1094, 0 /* ty=int32 */) /* ty=int32 */;
  @tensor_array_unstack_tensor5_helper_float32(0 /* ty=int32 */, %1095, %tensor37) /* ty=List[tensor_float32_t[]] */
}

def @tensor_array_unstack_tensor5_float64(%tensor38: Tensor[(?, ?, ?, ?, ?), float64]) -> List[tensor_float64_t[]] {
  %1096 = shape_of(%tensor38, dtype="int32") /* ty=Tensor[(5), int32] */;
  %1097 = take(%1096, 0 /* ty=int32 */) /* ty=int32 */;
  @tensor_array_unstack_tensor5_helper_float64(0 /* ty=int32 */, %1097, %tensor38) /* ty=List[tensor_float64_t[]] */
}

def @tensor_array_unstack_tensor5_helper_float16(%i36: int32, %up36: int32, %t38: Tensor[(?, ?, ?, ?, ?), float16]) -> List[tensor_float16_t[]] {
  %1098 = equal(%i36, %up36) /* ty=bool */;
  if (%1098) {
    Nil /* ty=List[tensor_float16_t[]] */
  } else {
    %1099 = take(%t38, %i36, axis=0) /* ty=Tensor[(?, ?, ?, ?), float16] */;
    %1100 = add(%i36, 1 /* ty=int32 */) /* ty=int32 */;
    %1101 = tensor4_float16(%1099) /* ty=tensor_float16_t[] */;
    %1102 = @tensor_array_unstack_tensor5_helper_float16(%1100, %up36, %t38) /* ty=List[tensor_float16_t[]] */;
    Cons(%1101, %1102) /* ty=List[tensor_float16_t[]] */
  }
}

def @tensor_array_unstack_tensor5_helper_float32(%i37: int32, %up37: int32, %t39: Tensor[(?, ?, ?, ?, ?), float32]) -> List[tensor_float32_t[]] {
  %1103 = equal(%i37, %up37) /* ty=bool */;
  if (%1103) {
    Nil /* ty=List[tensor_float32_t[]] */
  } else {
    %1104 = take(%t39, %i37, axis=0) /* ty=Tensor[(?, ?, ?, ?), float32] */;
    %1105 = add(%i37, 1 /* ty=int32 */) /* ty=int32 */;
    %1106 = tensor4_float32(%1104) /* ty=tensor_float32_t[] */;
    %1107 = @tensor_array_unstack_tensor5_helper_float32(%1105, %up37, %t39) /* ty=List[tensor_float32_t[]] */;
    Cons(%1106, %1107) /* ty=List[tensor_float32_t[]] */
  }
}

def @tensor_array_unstack_tensor5_helper_float64(%i38: int32, %up38: int32, %t40: Tensor[(?, ?, ?, ?, ?), float64]) -> List[tensor_float64_t[]] {
  %1108 = equal(%i38, %up38) /* ty=bool */;
  if (%1108) {
    Nil /* ty=List[tensor_float64_t[]] */
  } else {
    %1109 = take(%t40, %i38, axis=0) /* ty=Tensor[(?, ?, ?, ?), float64] */;
    %1110 = add(%i38, 1 /* ty=int32 */) /* ty=int32 */;
    %1111 = tensor4_float64(%1109) /* ty=tensor_float64_t[] */;
    %1112 = @tensor_array_unstack_tensor5_helper_float64(%1110, %up38, %t40) /* ty=List[tensor_float64_t[]] */;
    Cons(%1111, %1112) /* ty=List[tensor_float64_t[]] */
  }
}

def @tensor_array_unstack_tensor5_helper_int16(%i39: int32, %up39: int32, %t41: Tensor[(?, ?, ?, ?, ?), int16]) -> List[tensor_int16_t[]] {
  %1113 = equal(%i39, %up39) /* ty=bool */;
  if (%1113) {
    Nil /* ty=List[tensor_int16_t[]] */
  } else {
    %1114 = take(%t41, %i39, axis=0) /* ty=Tensor[(?, ?, ?, ?), int16] */;
    %1115 = add(%i39, 1 /* ty=int32 */) /* ty=int32 */;
    %1116 = tensor4_int16(%1114) /* ty=tensor_int16_t[] */;
    %1117 = @tensor_array_unstack_tensor5_helper_int16(%1115, %up39, %t41) /* ty=List[tensor_int16_t[]] */;
    Cons(%1116, %1117) /* ty=List[tensor_int16_t[]] */
  }
}

def @tensor_array_unstack_tensor5_helper_int32(%i40: int32, %up40: int32, %t42: Tensor[(?, ?, ?, ?, ?), int32]) -> List[tensor_int32_t[]] {
  %1118 = equal(%i40, %up40) /* ty=bool */;
  if (%1118) {
    Nil /* ty=List[tensor_int32_t[]] */
  } else {
    %1119 = take(%t42, %i40, axis=0) /* ty=Tensor[(?, ?, ?, ?), int32] */;
    %1120 = add(%i40, 1 /* ty=int32 */) /* ty=int32 */;
    %1121 = tensor4_int32(%1119) /* ty=tensor_int32_t[] */;
    %1122 = @tensor_array_unstack_tensor5_helper_int32(%1120, %up40, %t42) /* ty=List[tensor_int32_t[]] */;
    Cons(%1121, %1122) /* ty=List[tensor_int32_t[]] */
  }
}

def @tensor_array_unstack_tensor5_helper_int64(%i41: int32, %up41: int32, %t43: Tensor[(?, ?, ?, ?, ?), int64]) -> List[tensor_int64_t[]] {
  %1123 = equal(%i41, %up41) /* ty=bool */;
  if (%1123) {
    Nil /* ty=List[tensor_int64_t[]] */
  } else {
    %1124 = take(%t43, %i41, axis=0) /* ty=Tensor[(?, ?, ?, ?), int64] */;
    %1125 = add(%i41, 1 /* ty=int32 */) /* ty=int32 */;
    %1126 = tensor4_int64(%1124) /* ty=tensor_int64_t[] */;
    %1127 = @tensor_array_unstack_tensor5_helper_int64(%1125, %up41, %t43) /* ty=List[tensor_int64_t[]] */;
    Cons(%1126, %1127) /* ty=List[tensor_int64_t[]] */
  }
}

def @tensor_array_unstack_tensor5_helper_int8(%i42: int32, %up42: int32, %t44: Tensor[(?, ?, ?, ?, ?), int8]) -> List[tensor_int8_t[]] {
  %1128 = equal(%i42, %up42) /* ty=bool */;
  if (%1128) {
    Nil /* ty=List[tensor_int8_t[]] */
  } else {
    %1129 = take(%t44, %i42, axis=0) /* ty=Tensor[(?, ?, ?, ?), int8] */;
    %1130 = add(%i42, 1 /* ty=int32 */) /* ty=int32 */;
    %1131 = tensor4_int8(%1129) /* ty=tensor_int8_t[] */;
    %1132 = @tensor_array_unstack_tensor5_helper_int8(%1130, %up42, %t44) /* ty=List[tensor_int8_t[]] */;
    Cons(%1131, %1132) /* ty=List[tensor_int8_t[]] */
  }
}

def @tensor_array_unstack_tensor5_helper_uint16(%i43: int32, %up43: int32, %t45: Tensor[(?, ?, ?, ?, ?), uint16]) -> List[tensor_uint16_t[]] {
  %1133 = equal(%i43, %up43) /* ty=bool */;
  if (%1133) {
    Nil /* ty=List[tensor_uint16_t[]] */
  } else {
    %1134 = take(%t45, %i43, axis=0) /* ty=Tensor[(?, ?, ?, ?), uint16] */;
    %1135 = add(%i43, 1 /* ty=int32 */) /* ty=int32 */;
    %1136 = tensor4_uint16(%1134) /* ty=tensor_uint16_t[] */;
    %1137 = @tensor_array_unstack_tensor5_helper_uint16(%1135, %up43, %t45) /* ty=List[tensor_uint16_t[]] */;
    Cons(%1136, %1137) /* ty=List[tensor_uint16_t[]] */
  }
}

def @tensor_array_unstack_tensor5_helper_uint8(%i44: int32, %up44: int32, %t46: Tensor[(?, ?, ?, ?, ?), uint8]) -> List[tensor_uint8_t[]] {
  %1138 = equal(%i44, %up44) /* ty=bool */;
  if (%1138) {
    Nil /* ty=List[tensor_uint8_t[]] */
  } else {
    %1139 = take(%t46, %i44, axis=0) /* ty=Tensor[(?, ?, ?, ?), uint8] */;
    %1140 = add(%i44, 1 /* ty=int32 */) /* ty=int32 */;
    %1141 = tensor4_uint8(%1139) /* ty=tensor_uint8_t[] */;
    %1142 = @tensor_array_unstack_tensor5_helper_uint8(%1140, %up44, %t46) /* ty=List[tensor_uint8_t[]] */;
    Cons(%1141, %1142) /* ty=List[tensor_uint8_t[]] */
  }
}

def @tensor_array_unstack_tensor5_int16(%tensor39: Tensor[(?, ?, ?, ?, ?), int16]) -> List[tensor_int16_t[]] {
  %1143 = shape_of(%tensor39, dtype="int32") /* ty=Tensor[(5), int32] */;
  %1144 = take(%1143, 0 /* ty=int32 */) /* ty=int32 */;
  @tensor_array_unstack_tensor5_helper_int16(0 /* ty=int32 */, %1144, %tensor39) /* ty=List[tensor_int16_t[]] */
}

def @tensor_array_unstack_tensor5_int32(%tensor40: Tensor[(?, ?, ?, ?, ?), int32]) -> List[tensor_int32_t[]] {
  %1145 = shape_of(%tensor40, dtype="int32") /* ty=Tensor[(5), int32] */;
  %1146 = take(%1145, 0 /* ty=int32 */) /* ty=int32 */;
  @tensor_array_unstack_tensor5_helper_int32(0 /* ty=int32 */, %1146, %tensor40) /* ty=List[tensor_int32_t[]] */
}

def @tensor_array_unstack_tensor5_int64(%tensor41: Tensor[(?, ?, ?, ?, ?), int64]) -> List[tensor_int64_t[]] {
  %1147 = shape_of(%tensor41, dtype="int32") /* ty=Tensor[(5), int32] */;
  %1148 = take(%1147, 0 /* ty=int32 */) /* ty=int32 */;
  @tensor_array_unstack_tensor5_helper_int64(0 /* ty=int32 */, %1148, %tensor41) /* ty=List[tensor_int64_t[]] */
}

def @tensor_array_unstack_tensor5_int8(%tensor42: Tensor[(?, ?, ?, ?, ?), int8]) -> List[tensor_int8_t[]] {
  %1149 = shape_of(%tensor42, dtype="int32") /* ty=Tensor[(5), int32] */;
  %1150 = take(%1149, 0 /* ty=int32 */) /* ty=int32 */;
  @tensor_array_unstack_tensor5_helper_int8(0 /* ty=int32 */, %1150, %tensor42) /* ty=List[tensor_int8_t[]] */
}

def @tensor_array_unstack_tensor5_uint16(%tensor43: Tensor[(?, ?, ?, ?, ?), uint16]) -> List[tensor_uint16_t[]] {
  %1151 = shape_of(%tensor43, dtype="int32") /* ty=Tensor[(5), int32] */;
  %1152 = take(%1151, 0 /* ty=int32 */) /* ty=int32 */;
  @tensor_array_unstack_tensor5_helper_uint16(0 /* ty=int32 */, %1152, %tensor43) /* ty=List[tensor_uint16_t[]] */
}

def @tensor_array_unstack_tensor5_uint8(%tensor44: Tensor[(?, ?, ?, ?, ?), uint8]) -> List[tensor_uint8_t[]] {
  %1153 = shape_of(%tensor44, dtype="int32") /* ty=Tensor[(5), int32] */;
  %1154 = take(%1153, 0 /* ty=int32 */) /* ty=int32 */;
  @tensor_array_unstack_tensor5_helper_uint8(0 /* ty=int32 */, %1154, %tensor44) /* ty=List[tensor_uint8_t[]] */
}

def @tensor_array_unstack_tensor6_float16(%tensor45: Tensor[(?, ?, ?, ?, ?, ?), float16]) -> List[tensor_float16_t[]] {
  %1155 = shape_of(%tensor45, dtype="int32") /* ty=Tensor[(6), int32] */;
  %1156 = take(%1155, 0 /* ty=int32 */) /* ty=int32 */;
  @tensor_array_unstack_tensor6_helper_float16(0 /* ty=int32 */, %1156, %tensor45) /* ty=List[tensor_float16_t[]] */
}

def @tensor_array_unstack_tensor6_float32(%tensor46: Tensor[(?, ?, ?, ?, ?, ?), float32]) -> List[tensor_float32_t[]] {
  %1157 = shape_of(%tensor46, dtype="int32") /* ty=Tensor[(6), int32] */;
  %1158 = take(%1157, 0 /* ty=int32 */) /* ty=int32 */;
  @tensor_array_unstack_tensor6_helper_float32(0 /* ty=int32 */, %1158, %tensor46) /* ty=List[tensor_float32_t[]] */
}

def @tensor_array_unstack_tensor6_float64(%tensor47: Tensor[(?, ?, ?, ?, ?, ?), float64]) -> List[tensor_float64_t[]] {
  %1159 = shape_of(%tensor47, dtype="int32") /* ty=Tensor[(6), int32] */;
  %1160 = take(%1159, 0 /* ty=int32 */) /* ty=int32 */;
  @tensor_array_unstack_tensor6_helper_float64(0 /* ty=int32 */, %1160, %tensor47) /* ty=List[tensor_float64_t[]] */
}

def @tensor_array_unstack_tensor6_helper_float16(%i45: int32, %up45: int32, %t47: Tensor[(?, ?, ?, ?, ?, ?), float16]) -> List[tensor_float16_t[]] {
  %1161 = equal(%i45, %up45) /* ty=bool */;
  if (%1161) {
    Nil /* ty=List[tensor_float16_t[]] */
  } else {
    %1162 = take(%t47, %i45, axis=0) /* ty=Tensor[(?, ?, ?, ?, ?), float16] */;
    %1163 = add(%i45, 1 /* ty=int32 */) /* ty=int32 */;
    %1164 = tensor5_float16(%1162) /* ty=tensor_float16_t[] */;
    %1165 = @tensor_array_unstack_tensor6_helper_float16(%1163, %up45, %t47) /* ty=List[tensor_float16_t[]] */;
    Cons(%1164, %1165) /* ty=List[tensor_float16_t[]] */
  }
}

def @tensor_array_unstack_tensor6_helper_float32(%i46: int32, %up46: int32, %t48: Tensor[(?, ?, ?, ?, ?, ?), float32]) -> List[tensor_float32_t[]] {
  %1166 = equal(%i46, %up46) /* ty=bool */;
  if (%1166) {
    Nil /* ty=List[tensor_float32_t[]] */
  } else {
    %1167 = take(%t48, %i46, axis=0) /* ty=Tensor[(?, ?, ?, ?, ?), float32] */;
    %1168 = add(%i46, 1 /* ty=int32 */) /* ty=int32 */;
    %1169 = tensor5_float32(%1167) /* ty=tensor_float32_t[] */;
    %1170 = @tensor_array_unstack_tensor6_helper_float32(%1168, %up46, %t48) /* ty=List[tensor_float32_t[]] */;
    Cons(%1169, %1170) /* ty=List[tensor_float32_t[]] */
  }
}

def @tensor_array_unstack_tensor6_helper_float64(%i47: int32, %up47: int32, %t49: Tensor[(?, ?, ?, ?, ?, ?), float64]) -> List[tensor_float64_t[]] {
  %1171 = equal(%i47, %up47) /* ty=bool */;
  if (%1171) {
    Nil /* ty=List[tensor_float64_t[]] */
  } else {
    %1172 = take(%t49, %i47, axis=0) /* ty=Tensor[(?, ?, ?, ?, ?), float64] */;
    %1173 = add(%i47, 1 /* ty=int32 */) /* ty=int32 */;
    %1174 = tensor5_float64(%1172) /* ty=tensor_float64_t[] */;
    %1175 = @tensor_array_unstack_tensor6_helper_float64(%1173, %up47, %t49) /* ty=List[tensor_float64_t[]] */;
    Cons(%1174, %1175) /* ty=List[tensor_float64_t[]] */
  }
}

def @tensor_array_unstack_tensor6_helper_int16(%i48: int32, %up48: int32, %t50: Tensor[(?, ?, ?, ?, ?, ?), int16]) -> List[tensor_int16_t[]] {
  %1176 = equal(%i48, %up48) /* ty=bool */;
  if (%1176) {
    Nil /* ty=List[tensor_int16_t[]] */
  } else {
    %1177 = take(%t50, %i48, axis=0) /* ty=Tensor[(?, ?, ?, ?, ?), int16] */;
    %1178 = add(%i48, 1 /* ty=int32 */) /* ty=int32 */;
    %1179 = tensor5_int16(%1177) /* ty=tensor_int16_t[] */;
    %1180 = @tensor_array_unstack_tensor6_helper_int16(%1178, %up48, %t50) /* ty=List[tensor_int16_t[]] */;
    Cons(%1179, %1180) /* ty=List[tensor_int16_t[]] */
  }
}

def @tensor_array_unstack_tensor6_helper_int32(%i49: int32, %up49: int32, %t51: Tensor[(?, ?, ?, ?, ?, ?), int32]) -> List[tensor_int32_t[]] {
  %1181 = equal(%i49, %up49) /* ty=bool */;
  if (%1181) {
    Nil /* ty=List[tensor_int32_t[]] */
  } else {
    %1182 = take(%t51, %i49, axis=0) /* ty=Tensor[(?, ?, ?, ?, ?), int32] */;
    %1183 = add(%i49, 1 /* ty=int32 */) /* ty=int32 */;
    %1184 = tensor5_int32(%1182) /* ty=tensor_int32_t[] */;
    %1185 = @tensor_array_unstack_tensor6_helper_int32(%1183, %up49, %t51) /* ty=List[tensor_int32_t[]] */;
    Cons(%1184, %1185) /* ty=List[tensor_int32_t[]] */
  }
}

def @tensor_array_unstack_tensor6_helper_int64(%i50: int32, %up50: int32, %t52: Tensor[(?, ?, ?, ?, ?, ?), int64]) -> List[tensor_int64_t[]] {
  %1186 = equal(%i50, %up50) /* ty=bool */;
  if (%1186) {
    Nil /* ty=List[tensor_int64_t[]] */
  } else {
    %1187 = take(%t52, %i50, axis=0) /* ty=Tensor[(?, ?, ?, ?, ?), int64] */;
    %1188 = add(%i50, 1 /* ty=int32 */) /* ty=int32 */;
    %1189 = tensor5_int64(%1187) /* ty=tensor_int64_t[] */;
    %1190 = @tensor_array_unstack_tensor6_helper_int64(%1188, %up50, %t52) /* ty=List[tensor_int64_t[]] */;
    Cons(%1189, %1190) /* ty=List[tensor_int64_t[]] */
  }
}

def @tensor_array_unstack_tensor6_helper_int8(%i51: int32, %up51: int32, %t53: Tensor[(?, ?, ?, ?, ?, ?), int8]) -> List[tensor_int8_t[]] {
  %1191 = equal(%i51, %up51) /* ty=bool */;
  if (%1191) {
    Nil /* ty=List[tensor_int8_t[]] */
  } else {
    %1192 = take(%t53, %i51, axis=0) /* ty=Tensor[(?, ?, ?, ?, ?), int8] */;
    %1193 = add(%i51, 1 /* ty=int32 */) /* ty=int32 */;
    %1194 = tensor5_int8(%1192) /* ty=tensor_int8_t[] */;
    %1195 = @tensor_array_unstack_tensor6_helper_int8(%1193, %up51, %t53) /* ty=List[tensor_int8_t[]] */;
    Cons(%1194, %1195) /* ty=List[tensor_int8_t[]] */
  }
}

def @tensor_array_unstack_tensor6_helper_uint16(%i52: int32, %up52: int32, %t54: Tensor[(?, ?, ?, ?, ?, ?), uint16]) -> List[tensor_uint16_t[]] {
  %1196 = equal(%i52, %up52) /* ty=bool */;
  if (%1196) {
    Nil /* ty=List[tensor_uint16_t[]] */
  } else {
    %1197 = take(%t54, %i52, axis=0) /* ty=Tensor[(?, ?, ?, ?, ?), uint16] */;
    %1198 = add(%i52, 1 /* ty=int32 */) /* ty=int32 */;
    %1199 = tensor5_uint16(%1197) /* ty=tensor_uint16_t[] */;
    %1200 = @tensor_array_unstack_tensor6_helper_uint16(%1198, %up52, %t54) /* ty=List[tensor_uint16_t[]] */;
    Cons(%1199, %1200) /* ty=List[tensor_uint16_t[]] */
  }
}

def @tensor_array_unstack_tensor6_helper_uint8(%i53: int32, %up53: int32, %t55: Tensor[(?, ?, ?, ?, ?, ?), uint8]) -> List[tensor_uint8_t[]] {
  %1201 = equal(%i53, %up53) /* ty=bool */;
  if (%1201) {
    Nil /* ty=List[tensor_uint8_t[]] */
  } else {
    %1202 = take(%t55, %i53, axis=0) /* ty=Tensor[(?, ?, ?, ?, ?), uint8] */;
    %1203 = add(%i53, 1 /* ty=int32 */) /* ty=int32 */;
    %1204 = tensor5_uint8(%1202) /* ty=tensor_uint8_t[] */;
    %1205 = @tensor_array_unstack_tensor6_helper_uint8(%1203, %up53, %t55) /* ty=List[tensor_uint8_t[]] */;
    Cons(%1204, %1205) /* ty=List[tensor_uint8_t[]] */
  }
}

def @tensor_array_unstack_tensor6_int16(%tensor48: Tensor[(?, ?, ?, ?, ?, ?), int16]) -> List[tensor_int16_t[]] {
  %1206 = shape_of(%tensor48, dtype="int32") /* ty=Tensor[(6), int32] */;
  %1207 = take(%1206, 0 /* ty=int32 */) /* ty=int32 */;
  @tensor_array_unstack_tensor6_helper_int16(0 /* ty=int32 */, %1207, %tensor48) /* ty=List[tensor_int16_t[]] */
}

def @tensor_array_unstack_tensor6_int32(%tensor49: Tensor[(?, ?, ?, ?, ?, ?), int32]) -> List[tensor_int32_t[]] {
  %1208 = shape_of(%tensor49, dtype="int32") /* ty=Tensor[(6), int32] */;
  %1209 = take(%1208, 0 /* ty=int32 */) /* ty=int32 */;
  @tensor_array_unstack_tensor6_helper_int32(0 /* ty=int32 */, %1209, %tensor49) /* ty=List[tensor_int32_t[]] */
}

def @tensor_array_unstack_tensor6_int64(%tensor50: Tensor[(?, ?, ?, ?, ?, ?), int64]) -> List[tensor_int64_t[]] {
  %1210 = shape_of(%tensor50, dtype="int32") /* ty=Tensor[(6), int32] */;
  %1211 = take(%1210, 0 /* ty=int32 */) /* ty=int32 */;
  @tensor_array_unstack_tensor6_helper_int64(0 /* ty=int32 */, %1211, %tensor50) /* ty=List[tensor_int64_t[]] */
}

def @tensor_array_unstack_tensor6_int8(%tensor51: Tensor[(?, ?, ?, ?, ?, ?), int8]) -> List[tensor_int8_t[]] {
  %1212 = shape_of(%tensor51, dtype="int32") /* ty=Tensor[(6), int32] */;
  %1213 = take(%1212, 0 /* ty=int32 */) /* ty=int32 */;
  @tensor_array_unstack_tensor6_helper_int8(0 /* ty=int32 */, %1213, %tensor51) /* ty=List[tensor_int8_t[]] */
}

def @tensor_array_unstack_tensor6_uint16(%tensor52: Tensor[(?, ?, ?, ?, ?, ?), uint16]) -> List[tensor_uint16_t[]] {
  %1214 = shape_of(%tensor52, dtype="int32") /* ty=Tensor[(6), int32] */;
  %1215 = take(%1214, 0 /* ty=int32 */) /* ty=int32 */;
  @tensor_array_unstack_tensor6_helper_uint16(0 /* ty=int32 */, %1215, %tensor52) /* ty=List[tensor_uint16_t[]] */
}

def @tensor_array_unstack_tensor6_uint8(%tensor53: Tensor[(?, ?, ?, ?, ?, ?), uint8]) -> List[tensor_uint8_t[]] {
  %1216 = shape_of(%tensor53, dtype="int32") /* ty=Tensor[(6), int32] */;
  %1217 = take(%1216, 0 /* ty=int32 */) /* ty=int32 */;
  @tensor_array_unstack_tensor6_helper_uint8(0 /* ty=int32 */, %1217, %tensor53) /* ty=List[tensor_uint8_t[]] */
}

def @tensor_array_write_float16(%tensor_array54: List[tensor_float16_t[]], %x30: int32, %v: tensor_float16_t[]) -> List[tensor_float16_t[]] {
  @update(%tensor_array54, %x30, %v) /* ty=List[tensor_float16_t[]] */
}

def @tensor_array_write_float32(%tensor_array55: List[tensor_float32_t[]], %x31: int32, %v1: tensor_float32_t[]) -> List[tensor_float32_t[]] {
  @update(%tensor_array55, %x31, %v1) /* ty=List[tensor_float32_t[]] */
}

def @tensor_array_write_float64(%tensor_array56: List[tensor_float64_t[]], %x32: int32, %v2: tensor_float64_t[]) -> List[tensor_float64_t[]] {
  @update(%tensor_array56, %x32, %v2) /* ty=List[tensor_float64_t[]] */
}

def @tensor_array_write_int16(%tensor_array57: List[tensor_int16_t[]], %x33: int32, %v3: tensor_int16_t[]) -> List[tensor_int16_t[]] {
  @update(%tensor_array57, %x33, %v3) /* ty=List[tensor_int16_t[]] */
}

def @tensor_array_write_int32(%tensor_array58: List[tensor_int32_t[]], %x34: int32, %v4: tensor_int32_t[]) -> List[tensor_int32_t[]] {
  @update(%tensor_array58, %x34, %v4) /* ty=List[tensor_int32_t[]] */
}

def @tensor_array_write_int64(%tensor_array59: List[tensor_int64_t[]], %x35: int32, %v5: tensor_int64_t[]) -> List[tensor_int64_t[]] {
  @update(%tensor_array59, %x35, %v5) /* ty=List[tensor_int64_t[]] */
}

def @tensor_array_write_int8(%tensor_array60: List[tensor_int8_t[]], %x36: int32, %v6: tensor_int8_t[]) -> List[tensor_int8_t[]] {
  @update(%tensor_array60, %x36, %v6) /* ty=List[tensor_int8_t[]] */
}

def @tensor_array_write_uint16(%tensor_array61: List[tensor_uint16_t[]], %x37: int32, %v7: tensor_uint16_t[]) -> List[tensor_uint16_t[]] {
  @update(%tensor_array61, %x37, %v7) /* ty=List[tensor_uint16_t[]] */
}

def @tensor_array_write_uint8(%tensor_array62: List[tensor_uint8_t[]], %x38: int32, %v8: tensor_uint8_t[]) -> List[tensor_uint8_t[]] {
  @update(%tensor_array62, %x38, %v8) /* ty=List[tensor_uint8_t[]] */
}

def @tensor_concatenate_float16(%x39: tensor_float16_t[], %y1: tensor_float16_t[]) -> tensor_float16_t[] {
  match? (%x39) {
    tensor1_float16(%t111: Tensor[(?), float16]) => {
      match? (%y1) {
        tensor1_float16(%t121: Tensor[(?), float16]) => {
          %1218 = (%t111, %t121);
          %1219 = concatenate(%1218) /* ty=Tensor[(?), float16] */;
          tensor1_float16(%1219) /* ty=tensor_float16_t[] */
        },
      }
    },
    tensor2_float16(%t211: Tensor[(?, ?), float16]) => {
      match? (%y1) {
        tensor2_float16(%t221: Tensor[(?, ?), float16]) => {
          %1220 = (%t211, %t221);
          %1221 = concatenate(%1220) /* ty=Tensor[(?, ?), float16] */;
          tensor2_float16(%1221) /* ty=tensor_float16_t[] */
        },
      }
    },
    tensor3_float16(%t311: Tensor[(?, ?, ?), float16]) => {
      match? (%y1) {
        tensor3_float16(%t321: Tensor[(?, ?, ?), float16]) => {
          %1222 = (%t311, %t321);
          %1223 = concatenate(%1222) /* ty=Tensor[(?, ?, ?), float16] */;
          tensor3_float16(%1223) /* ty=tensor_float16_t[] */
        },
      }
    },
    tensor4_float16(%t411: Tensor[(?, ?, ?, ?), float16]) => {
      match? (%y1) {
        tensor4_float16(%t421: Tensor[(?, ?, ?, ?), float16]) => {
          %1224 = (%t411, %t421);
          %1225 = concatenate(%1224) /* ty=Tensor[(?, ?, ?, ?), float16] */;
          tensor4_float16(%1225) /* ty=tensor_float16_t[] */
        },
      }
    },
  }
}

def @tensor_concatenate_float32(%x40: tensor_float32_t[], %y2: tensor_float32_t[]) -> tensor_float32_t[] {
  match? (%x40) {
    tensor1_float32(%t112: Tensor[(?), float32]) => {
      match? (%y2) {
        tensor1_float32(%t122: Tensor[(?), float32]) => {
          %1226 = (%t112, %t122);
          %1227 = concatenate(%1226) /* ty=Tensor[(?), float32] */;
          tensor1_float32(%1227) /* ty=tensor_float32_t[] */
        },
      }
    },
    tensor2_float32(%t212: Tensor[(?, ?), float32]) => {
      match? (%y2) {
        tensor2_float32(%t222: Tensor[(?, ?), float32]) => {
          %1228 = (%t212, %t222);
          %1229 = concatenate(%1228) /* ty=Tensor[(?, ?), float32] */;
          tensor2_float32(%1229) /* ty=tensor_float32_t[] */
        },
      }
    },
    tensor3_float32(%t312: Tensor[(?, ?, ?), float32]) => {
      match? (%y2) {
        tensor3_float32(%t322: Tensor[(?, ?, ?), float32]) => {
          %1230 = (%t312, %t322);
          %1231 = concatenate(%1230) /* ty=Tensor[(?, ?, ?), float32] */;
          tensor3_float32(%1231) /* ty=tensor_float32_t[] */
        },
      }
    },
    tensor4_float32(%t412: Tensor[(?, ?, ?, ?), float32]) => {
      match? (%y2) {
        tensor4_float32(%t422: Tensor[(?, ?, ?, ?), float32]) => {
          %1232 = (%t412, %t422);
          %1233 = concatenate(%1232) /* ty=Tensor[(?, ?, ?, ?), float32] */;
          tensor4_float32(%1233) /* ty=tensor_float32_t[] */
        },
      }
    },
  }
}

def @tensor_concatenate_float64(%x41: tensor_float64_t[], %y3: tensor_float64_t[]) -> tensor_float64_t[] {
  match? (%x41) {
    tensor1_float64(%t113: Tensor[(?), float64]) => {
      match? (%y3) {
        tensor1_float64(%t123: Tensor[(?), float64]) => {
          %1234 = (%t113, %t123);
          %1235 = concatenate(%1234) /* ty=Tensor[(?), float64] */;
          tensor1_float64(%1235) /* ty=tensor_float64_t[] */
        },
      }
    },
    tensor2_float64(%t213: Tensor[(?, ?), float64]) => {
      match? (%y3) {
        tensor2_float64(%t223: Tensor[(?, ?), float64]) => {
          %1236 = (%t213, %t223);
          %1237 = concatenate(%1236) /* ty=Tensor[(?, ?), float64] */;
          tensor2_float64(%1237) /* ty=tensor_float64_t[] */
        },
      }
    },
    tensor3_float64(%t313: Tensor[(?, ?, ?), float64]) => {
      match? (%y3) {
        tensor3_float64(%t323: Tensor[(?, ?, ?), float64]) => {
          %1238 = (%t313, %t323);
          %1239 = concatenate(%1238) /* ty=Tensor[(?, ?, ?), float64] */;
          tensor3_float64(%1239) /* ty=tensor_float64_t[] */
        },
      }
    },
    tensor4_float64(%t413: Tensor[(?, ?, ?, ?), float64]) => {
      match? (%y3) {
        tensor4_float64(%t423: Tensor[(?, ?, ?, ?), float64]) => {
          %1240 = (%t413, %t423);
          %1241 = concatenate(%1240) /* ty=Tensor[(?, ?, ?, ?), float64] */;
          tensor4_float64(%1241) /* ty=tensor_float64_t[] */
        },
      }
    },
  }
}

def @tensor_concatenate_int16(%x42: tensor_int16_t[], %y4: tensor_int16_t[]) -> tensor_int16_t[] {
  match? (%x42) {
    tensor1_int16(%t114: Tensor[(?), int16]) => {
      match? (%y4) {
        tensor1_int16(%t124: Tensor[(?), int16]) => {
          %1242 = (%t114, %t124);
          %1243 = concatenate(%1242) /* ty=Tensor[(?), int16] */;
          tensor1_int16(%1243) /* ty=tensor_int16_t[] */
        },
      }
    },
    tensor2_int16(%t214: Tensor[(?, ?), int16]) => {
      match? (%y4) {
        tensor2_int16(%t224: Tensor[(?, ?), int16]) => {
          %1244 = (%t214, %t224);
          %1245 = concatenate(%1244) /* ty=Tensor[(?, ?), int16] */;
          tensor2_int16(%1245) /* ty=tensor_int16_t[] */
        },
      }
    },
    tensor3_int16(%t314: Tensor[(?, ?, ?), int16]) => {
      match? (%y4) {
        tensor3_int16(%t324: Tensor[(?, ?, ?), int16]) => {
          %1246 = (%t314, %t324);
          %1247 = concatenate(%1246) /* ty=Tensor[(?, ?, ?), int16] */;
          tensor3_int16(%1247) /* ty=tensor_int16_t[] */
        },
      }
    },
    tensor4_int16(%t414: Tensor[(?, ?, ?, ?), int16]) => {
      match? (%y4) {
        tensor4_int16(%t424: Tensor[(?, ?, ?, ?), int16]) => {
          %1248 = (%t414, %t424);
          %1249 = concatenate(%1248) /* ty=Tensor[(?, ?, ?, ?), int16] */;
          tensor4_int16(%1249) /* ty=tensor_int16_t[] */
        },
      }
    },
  }
}

def @tensor_concatenate_int32(%x43: tensor_int32_t[], %y5: tensor_int32_t[]) -> tensor_int32_t[] {
  match? (%x43) {
    tensor1_int32(%t115: Tensor[(?), int32]) => {
      match? (%y5) {
        tensor1_int32(%t125: Tensor[(?), int32]) => {
          %1250 = (%t115, %t125);
          %1251 = concatenate(%1250) /* ty=Tensor[(?), int32] */;
          tensor1_int32(%1251) /* ty=tensor_int32_t[] */
        },
      }
    },
    tensor2_int32(%t215: Tensor[(?, ?), int32]) => {
      match? (%y5) {
        tensor2_int32(%t225: Tensor[(?, ?), int32]) => {
          %1252 = (%t215, %t225);
          %1253 = concatenate(%1252) /* ty=Tensor[(?, ?), int32] */;
          tensor2_int32(%1253) /* ty=tensor_int32_t[] */
        },
      }
    },
    tensor3_int32(%t315: Tensor[(?, ?, ?), int32]) => {
      match? (%y5) {
        tensor3_int32(%t325: Tensor[(?, ?, ?), int32]) => {
          %1254 = (%t315, %t325);
          %1255 = concatenate(%1254) /* ty=Tensor[(?, ?, ?), int32] */;
          tensor3_int32(%1255) /* ty=tensor_int32_t[] */
        },
      }
    },
    tensor4_int32(%t415: Tensor[(?, ?, ?, ?), int32]) => {
      match? (%y5) {
        tensor4_int32(%t425: Tensor[(?, ?, ?, ?), int32]) => {
          %1256 = (%t415, %t425);
          %1257 = concatenate(%1256) /* ty=Tensor[(?, ?, ?, ?), int32] */;
          tensor4_int32(%1257) /* ty=tensor_int32_t[] */
        },
      }
    },
  }
}

def @tensor_concatenate_int64(%x44: tensor_int64_t[], %y6: tensor_int64_t[]) -> tensor_int64_t[] {
  match? (%x44) {
    tensor1_int64(%t116: Tensor[(?), int64]) => {
      match? (%y6) {
        tensor1_int64(%t126: Tensor[(?), int64]) => {
          %1258 = (%t116, %t126);
          %1259 = concatenate(%1258) /* ty=Tensor[(?), int64] */;
          tensor1_int64(%1259) /* ty=tensor_int64_t[] */
        },
      }
    },
    tensor2_int64(%t216: Tensor[(?, ?), int64]) => {
      match? (%y6) {
        tensor2_int64(%t226: Tensor[(?, ?), int64]) => {
          %1260 = (%t216, %t226);
          %1261 = concatenate(%1260) /* ty=Tensor[(?, ?), int64] */;
          tensor2_int64(%1261) /* ty=tensor_int64_t[] */
        },
      }
    },
    tensor3_int64(%t316: Tensor[(?, ?, ?), int64]) => {
      match? (%y6) {
        tensor3_int64(%t326: Tensor[(?, ?, ?), int64]) => {
          %1262 = (%t316, %t326);
          %1263 = concatenate(%1262) /* ty=Tensor[(?, ?, ?), int64] */;
          tensor3_int64(%1263) /* ty=tensor_int64_t[] */
        },
      }
    },
    tensor4_int64(%t416: Tensor[(?, ?, ?, ?), int64]) => {
      match? (%y6) {
        tensor4_int64(%t426: Tensor[(?, ?, ?, ?), int64]) => {
          %1264 = (%t416, %t426);
          %1265 = concatenate(%1264) /* ty=Tensor[(?, ?, ?, ?), int64] */;
          tensor4_int64(%1265) /* ty=tensor_int64_t[] */
        },
      }
    },
  }
}

def @tensor_concatenate_int8(%x45: tensor_int8_t[], %y7: tensor_int8_t[]) -> tensor_int8_t[] {
  match? (%x45) {
    tensor1_int8(%t117: Tensor[(?), int8]) => {
      match? (%y7) {
        tensor1_int8(%t127: Tensor[(?), int8]) => {
          %1266 = (%t117, %t127);
          %1267 = concatenate(%1266) /* ty=Tensor[(?), int8] */;
          tensor1_int8(%1267) /* ty=tensor_int8_t[] */
        },
      }
    },
    tensor2_int8(%t217: Tensor[(?, ?), int8]) => {
      match? (%y7) {
        tensor2_int8(%t227: Tensor[(?, ?), int8]) => {
          %1268 = (%t217, %t227);
          %1269 = concatenate(%1268) /* ty=Tensor[(?, ?), int8] */;
          tensor2_int8(%1269) /* ty=tensor_int8_t[] */
        },
      }
    },
    tensor3_int8(%t317: Tensor[(?, ?, ?), int8]) => {
      match? (%y7) {
        tensor3_int8(%t327: Tensor[(?, ?, ?), int8]) => {
          %1270 = (%t317, %t327);
          %1271 = concatenate(%1270) /* ty=Tensor[(?, ?, ?), int8] */;
          tensor3_int8(%1271) /* ty=tensor_int8_t[] */
        },
      }
    },
    tensor4_int8(%t417: Tensor[(?, ?, ?, ?), int8]) => {
      match? (%y7) {
        tensor4_int8(%t427: Tensor[(?, ?, ?, ?), int8]) => {
          %1272 = (%t417, %t427);
          %1273 = concatenate(%1272) /* ty=Tensor[(?, ?, ?, ?), int8] */;
          tensor4_int8(%1273) /* ty=tensor_int8_t[] */
        },
      }
    },
  }
}

def @tensor_concatenate_uint16(%x46: tensor_uint16_t[], %y8: tensor_uint16_t[]) -> tensor_uint16_t[] {
  match? (%x46) {
    tensor1_uint16(%t118: Tensor[(?), uint16]) => {
      match? (%y8) {
        tensor1_uint16(%t128: Tensor[(?), uint16]) => {
          %1274 = (%t118, %t128);
          %1275 = concatenate(%1274) /* ty=Tensor[(?), uint16] */;
          tensor1_uint16(%1275) /* ty=tensor_uint16_t[] */
        },
      }
    },
    tensor2_uint16(%t218: Tensor[(?, ?), uint16]) => {
      match? (%y8) {
        tensor2_uint16(%t228: Tensor[(?, ?), uint16]) => {
          %1276 = (%t218, %t228);
          %1277 = concatenate(%1276) /* ty=Tensor[(?, ?), uint16] */;
          tensor2_uint16(%1277) /* ty=tensor_uint16_t[] */
        },
      }
    },
    tensor3_uint16(%t318: Tensor[(?, ?, ?), uint16]) => {
      match? (%y8) {
        tensor3_uint16(%t328: Tensor[(?, ?, ?), uint16]) => {
          %1278 = (%t318, %t328);
          %1279 = concatenate(%1278) /* ty=Tensor[(?, ?, ?), uint16] */;
          tensor3_uint16(%1279) /* ty=tensor_uint16_t[] */
        },
      }
    },
    tensor4_uint16(%t418: Tensor[(?, ?, ?, ?), uint16]) => {
      match? (%y8) {
        tensor4_uint16(%t428: Tensor[(?, ?, ?, ?), uint16]) => {
          %1280 = (%t418, %t428);
          %1281 = concatenate(%1280) /* ty=Tensor[(?, ?, ?, ?), uint16] */;
          tensor4_uint16(%1281) /* ty=tensor_uint16_t[] */
        },
      }
    },
  }
}

def @tensor_concatenate_uint8(%x47: tensor_uint8_t[], %y9: tensor_uint8_t[]) -> tensor_uint8_t[] {
  match? (%x47) {
    tensor1_uint8(%t119: Tensor[(?), uint8]) => {
      match? (%y9) {
        tensor1_uint8(%t129: Tensor[(?), uint8]) => {
          %1282 = (%t119, %t129);
          %1283 = concatenate(%1282) /* ty=Tensor[(?), uint8] */;
          tensor1_uint8(%1283) /* ty=tensor_uint8_t[] */
        },
      }
    },
    tensor2_uint8(%t219: Tensor[(?, ?), uint8]) => {
      match? (%y9) {
        tensor2_uint8(%t229: Tensor[(?, ?), uint8]) => {
          %1284 = (%t219, %t229);
          %1285 = concatenate(%1284) /* ty=Tensor[(?, ?), uint8] */;
          tensor2_uint8(%1285) /* ty=tensor_uint8_t[] */
        },
      }
    },
    tensor3_uint8(%t319: Tensor[(?, ?, ?), uint8]) => {
      match? (%y9) {
        tensor3_uint8(%t329: Tensor[(?, ?, ?), uint8]) => {
          %1286 = (%t319, %t329);
          %1287 = concatenate(%1286) /* ty=Tensor[(?, ?, ?), uint8] */;
          tensor3_uint8(%1287) /* ty=tensor_uint8_t[] */
        },
      }
    },
    tensor4_uint8(%t419: Tensor[(?, ?, ?, ?), uint8]) => {
      match? (%y9) {
        tensor4_uint8(%t429: Tensor[(?, ?, ?, ?), uint8]) => {
          %1288 = (%t419, %t429);
          %1289 = concatenate(%1288) /* ty=Tensor[(?, ?, ?, ?), uint8] */;
          tensor4_uint8(%1289) /* ty=tensor_uint8_t[] */
        },
      }
    },
  }
}

def @tensor_expand_dims_float16(%x48: tensor_float16_t[]) -> tensor_float16_t[] {
  match? (%x48) {
    tensor0_float16(%t0: float16) => {
      %1290 = expand_dims(%t0, axis=0) /* ty=Tensor[(1), float16] */;
      tensor1_float16(%1290) /* ty=tensor_float16_t[] */
    },
    tensor1_float16(%t110: Tensor[(?), float16]) => {
      %1291 = expand_dims(%t110, axis=0) /* ty=Tensor[(1, ?), float16] */;
      tensor2_float16(%1291) /* ty=tensor_float16_t[] */
    },
    tensor2_float16(%t210: Tensor[(?, ?), float16]) => {
      %1292 = expand_dims(%t210, axis=0) /* ty=Tensor[(1, ?, ?), float16] */;
      tensor3_float16(%1292) /* ty=tensor_float16_t[] */
    },
    tensor3_float16(%t310: Tensor[(?, ?, ?), float16]) => {
      %1293 = expand_dims(%t310, axis=0) /* ty=Tensor[(1, ?, ?, ?), float16] */;
      tensor4_float16(%1293) /* ty=tensor_float16_t[] */
    },
    tensor4_float16(%t410: Tensor[(?, ?, ?, ?), float16]) => {
      %1294 = expand_dims(%t410, axis=0) /* ty=Tensor[(1, ?, ?, ?, ?), float16] */;
      tensor5_float16(%1294) /* ty=tensor_float16_t[] */
    },
    tensor5_float16(%t56: Tensor[(?, ?, ?, ?, ?), float16]) => {
      %1295 = expand_dims(%t56, axis=0) /* ty=Tensor[(1, ?, ?, ?, ?, ?), float16] */;
      tensor6_float16(%1295) /* ty=tensor_float16_t[] */
    },
  }
}

def @tensor_expand_dims_float32(%x49: tensor_float32_t[]) -> tensor_float32_t[] {
  match? (%x49) {
    tensor0_float32(%t01: float32) => {
      %1296 = expand_dims(%t01, axis=0) /* ty=Tensor[(1), float32] */;
      tensor1_float32(%1296) /* ty=tensor_float32_t[] */
    },
    tensor1_float32(%t120: Tensor[(?), float32]) => {
      %1297 = expand_dims(%t120, axis=0) /* ty=Tensor[(1, ?), float32] */;
      tensor2_float32(%1297) /* ty=tensor_float32_t[] */
    },
    tensor2_float32(%t220: Tensor[(?, ?), float32]) => {
      %1298 = expand_dims(%t220, axis=0) /* ty=Tensor[(1, ?, ?), float32] */;
      tensor3_float32(%1298) /* ty=tensor_float32_t[] */
    },
    tensor3_float32(%t320: Tensor[(?, ?, ?), float32]) => {
      %1299 = expand_dims(%t320, axis=0) /* ty=Tensor[(1, ?, ?, ?), float32] */;
      tensor4_float32(%1299) /* ty=tensor_float32_t[] */
    },
    tensor4_float32(%t420: Tensor[(?, ?, ?, ?), float32]) => {
      %1300 = expand_dims(%t420, axis=0) /* ty=Tensor[(1, ?, ?, ?, ?), float32] */;
      tensor5_float32(%1300) /* ty=tensor_float32_t[] */
    },
    tensor5_float32(%t57: Tensor[(?, ?, ?, ?, ?), float32]) => {
      %1301 = expand_dims(%t57, axis=0) /* ty=Tensor[(1, ?, ?, ?, ?, ?), float32] */;
      tensor6_float32(%1301) /* ty=tensor_float32_t[] */
    },
  }
}

def @tensor_expand_dims_float64(%x50: tensor_float64_t[]) -> tensor_float64_t[] {
  match? (%x50) {
    tensor0_float64(%t02: float64) => {
      %1302 = expand_dims(%t02, axis=0) /* ty=Tensor[(1), float64] */;
      tensor1_float64(%1302) /* ty=tensor_float64_t[] */
    },
    tensor1_float64(%t130: Tensor[(?), float64]) => {
      %1303 = expand_dims(%t130, axis=0) /* ty=Tensor[(1, ?), float64] */;
      tensor2_float64(%1303) /* ty=tensor_float64_t[] */
    },
    tensor2_float64(%t230: Tensor[(?, ?), float64]) => {
      %1304 = expand_dims(%t230, axis=0) /* ty=Tensor[(1, ?, ?), float64] */;
      tensor3_float64(%1304) /* ty=tensor_float64_t[] */
    },
    tensor3_float64(%t330: Tensor[(?, ?, ?), float64]) => {
      %1305 = expand_dims(%t330, axis=0) /* ty=Tensor[(1, ?, ?, ?), float64] */;
      tensor4_float64(%1305) /* ty=tensor_float64_t[] */
    },
    tensor4_float64(%t430: Tensor[(?, ?, ?, ?), float64]) => {
      %1306 = expand_dims(%t430, axis=0) /* ty=Tensor[(1, ?, ?, ?, ?), float64] */;
      tensor5_float64(%1306) /* ty=tensor_float64_t[] */
    },
    tensor5_float64(%t58: Tensor[(?, ?, ?, ?, ?), float64]) => {
      %1307 = expand_dims(%t58, axis=0) /* ty=Tensor[(1, ?, ?, ?, ?, ?), float64] */;
      tensor6_float64(%1307) /* ty=tensor_float64_t[] */
    },
  }
}

def @tensor_expand_dims_int16(%x51: tensor_int16_t[]) -> tensor_int16_t[] {
  match? (%x51) {
    tensor0_int16(%t03: int16) => {
      %1308 = expand_dims(%t03, axis=0) /* ty=Tensor[(1), int16] */;
      tensor1_int16(%1308) /* ty=tensor_int16_t[] */
    },
    tensor1_int16(%t131: Tensor[(?), int16]) => {
      %1309 = expand_dims(%t131, axis=0) /* ty=Tensor[(1, ?), int16] */;
      tensor2_int16(%1309) /* ty=tensor_int16_t[] */
    },
    tensor2_int16(%t231: Tensor[(?, ?), int16]) => {
      %1310 = expand_dims(%t231, axis=0) /* ty=Tensor[(1, ?, ?), int16] */;
      tensor3_int16(%1310) /* ty=tensor_int16_t[] */
    },
    tensor3_int16(%t331: Tensor[(?, ?, ?), int16]) => {
      %1311 = expand_dims(%t331, axis=0) /* ty=Tensor[(1, ?, ?, ?), int16] */;
      tensor4_int16(%1311) /* ty=tensor_int16_t[] */
    },
    tensor4_int16(%t431: Tensor[(?, ?, ?, ?), int16]) => {
      %1312 = expand_dims(%t431, axis=0) /* ty=Tensor[(1, ?, ?, ?, ?), int16] */;
      tensor5_int16(%1312) /* ty=tensor_int16_t[] */
    },
    tensor5_int16(%t59: Tensor[(?, ?, ?, ?, ?), int16]) => {
      %1313 = expand_dims(%t59, axis=0) /* ty=Tensor[(1, ?, ?, ?, ?, ?), int16] */;
      tensor6_int16(%1313) /* ty=tensor_int16_t[] */
    },
  }
}

def @tensor_expand_dims_int32(%x52: tensor_int32_t[]) -> tensor_int32_t[] {
  match? (%x52) {
    tensor0_int32(%t04: int32) => {
      %1314 = expand_dims(%t04, axis=0) /* ty=Tensor[(1), int32] */;
      tensor1_int32(%1314) /* ty=tensor_int32_t[] */
    },
    tensor1_int32(%t132: Tensor[(?), int32]) => {
      %1315 = expand_dims(%t132, axis=0) /* ty=Tensor[(1, ?), int32] */;
      tensor2_int32(%1315) /* ty=tensor_int32_t[] */
    },
    tensor2_int32(%t232: Tensor[(?, ?), int32]) => {
      %1316 = expand_dims(%t232, axis=0) /* ty=Tensor[(1, ?, ?), int32] */;
      tensor3_int32(%1316) /* ty=tensor_int32_t[] */
    },
    tensor3_int32(%t332: Tensor[(?, ?, ?), int32]) => {
      %1317 = expand_dims(%t332, axis=0) /* ty=Tensor[(1, ?, ?, ?), int32] */;
      tensor4_int32(%1317) /* ty=tensor_int32_t[] */
    },
    tensor4_int32(%t432: Tensor[(?, ?, ?, ?), int32]) => {
      %1318 = expand_dims(%t432, axis=0) /* ty=Tensor[(1, ?, ?, ?, ?), int32] */;
      tensor5_int32(%1318) /* ty=tensor_int32_t[] */
    },
    tensor5_int32(%t510: Tensor[(?, ?, ?, ?, ?), int32]) => {
      %1319 = expand_dims(%t510, axis=0) /* ty=Tensor[(1, ?, ?, ?, ?, ?), int32] */;
      tensor6_int32(%1319) /* ty=tensor_int32_t[] */
    },
  }
}

def @tensor_expand_dims_int64(%x53: tensor_int64_t[]) -> tensor_int64_t[] {
  match? (%x53) {
    tensor0_int64(%t05: int64) => {
      %1320 = expand_dims(%t05, axis=0) /* ty=Tensor[(1), int64] */;
      tensor1_int64(%1320) /* ty=tensor_int64_t[] */
    },
    tensor1_int64(%t133: Tensor[(?), int64]) => {
      %1321 = expand_dims(%t133, axis=0) /* ty=Tensor[(1, ?), int64] */;
      tensor2_int64(%1321) /* ty=tensor_int64_t[] */
    },
    tensor2_int64(%t233: Tensor[(?, ?), int64]) => {
      %1322 = expand_dims(%t233, axis=0) /* ty=Tensor[(1, ?, ?), int64] */;
      tensor3_int64(%1322) /* ty=tensor_int64_t[] */
    },
    tensor3_int64(%t333: Tensor[(?, ?, ?), int64]) => {
      %1323 = expand_dims(%t333, axis=0) /* ty=Tensor[(1, ?, ?, ?), int64] */;
      tensor4_int64(%1323) /* ty=tensor_int64_t[] */
    },
    tensor4_int64(%t433: Tensor[(?, ?, ?, ?), int64]) => {
      %1324 = expand_dims(%t433, axis=0) /* ty=Tensor[(1, ?, ?, ?, ?), int64] */;
      tensor5_int64(%1324) /* ty=tensor_int64_t[] */
    },
    tensor5_int64(%t511: Tensor[(?, ?, ?, ?, ?), int64]) => {
      %1325 = expand_dims(%t511, axis=0) /* ty=Tensor[(1, ?, ?, ?, ?, ?), int64] */;
      tensor6_int64(%1325) /* ty=tensor_int64_t[] */
    },
  }
}

def @tensor_expand_dims_int8(%x54: tensor_int8_t[]) -> tensor_int8_t[] {
  match? (%x54) {
    tensor0_int8(%t06: int8) => {
      %1326 = expand_dims(%t06, axis=0) /* ty=Tensor[(1), int8] */;
      tensor1_int8(%1326) /* ty=tensor_int8_t[] */
    },
    tensor1_int8(%t134: Tensor[(?), int8]) => {
      %1327 = expand_dims(%t134, axis=0) /* ty=Tensor[(1, ?), int8] */;
      tensor2_int8(%1327) /* ty=tensor_int8_t[] */
    },
    tensor2_int8(%t234: Tensor[(?, ?), int8]) => {
      %1328 = expand_dims(%t234, axis=0) /* ty=Tensor[(1, ?, ?), int8] */;
      tensor3_int8(%1328) /* ty=tensor_int8_t[] */
    },
    tensor3_int8(%t334: Tensor[(?, ?, ?), int8]) => {
      %1329 = expand_dims(%t334, axis=0) /* ty=Tensor[(1, ?, ?, ?), int8] */;
      tensor4_int8(%1329) /* ty=tensor_int8_t[] */
    },
    tensor4_int8(%t434: Tensor[(?, ?, ?, ?), int8]) => {
      %1330 = expand_dims(%t434, axis=0) /* ty=Tensor[(1, ?, ?, ?, ?), int8] */;
      tensor5_int8(%1330) /* ty=tensor_int8_t[] */
    },
    tensor5_int8(%t512: Tensor[(?, ?, ?, ?, ?), int8]) => {
      %1331 = expand_dims(%t512, axis=0) /* ty=Tensor[(1, ?, ?, ?, ?, ?), int8] */;
      tensor6_int8(%1331) /* ty=tensor_int8_t[] */
    },
  }
}

def @tensor_expand_dims_uint16(%x55: tensor_uint16_t[]) -> tensor_uint16_t[] {
  match? (%x55) {
    tensor0_uint16(%t07: uint16) => {
      %1332 = expand_dims(%t07, axis=0) /* ty=Tensor[(1), uint16] */;
      tensor1_uint16(%1332) /* ty=tensor_uint16_t[] */
    },
    tensor1_uint16(%t135: Tensor[(?), uint16]) => {
      %1333 = expand_dims(%t135, axis=0) /* ty=Tensor[(1, ?), uint16] */;
      tensor2_uint16(%1333) /* ty=tensor_uint16_t[] */
    },
    tensor2_uint16(%t235: Tensor[(?, ?), uint16]) => {
      %1334 = expand_dims(%t235, axis=0) /* ty=Tensor[(1, ?, ?), uint16] */;
      tensor3_uint16(%1334) /* ty=tensor_uint16_t[] */
    },
    tensor3_uint16(%t335: Tensor[(?, ?, ?), uint16]) => {
      %1335 = expand_dims(%t335, axis=0) /* ty=Tensor[(1, ?, ?, ?), uint16] */;
      tensor4_uint16(%1335) /* ty=tensor_uint16_t[] */
    },
    tensor4_uint16(%t435: Tensor[(?, ?, ?, ?), uint16]) => {
      %1336 = expand_dims(%t435, axis=0) /* ty=Tensor[(1, ?, ?, ?, ?), uint16] */;
      tensor5_uint16(%1336) /* ty=tensor_uint16_t[] */
    },
    tensor5_uint16(%t513: Tensor[(?, ?, ?, ?, ?), uint16]) => {
      %1337 = expand_dims(%t513, axis=0) /* ty=Tensor[(1, ?, ?, ?, ?, ?), uint16] */;
      tensor6_uint16(%1337) /* ty=tensor_uint16_t[] */
    },
  }
}

def @tensor_expand_dims_uint8(%x56: tensor_uint8_t[]) -> tensor_uint8_t[] {
  match? (%x56) {
    tensor0_uint8(%t08: uint8) => {
      %1338 = expand_dims(%t08, axis=0) /* ty=Tensor[(1), uint8] */;
      tensor1_uint8(%1338) /* ty=tensor_uint8_t[] */
    },
    tensor1_uint8(%t136: Tensor[(?), uint8]) => {
      %1339 = expand_dims(%t136, axis=0) /* ty=Tensor[(1, ?), uint8] */;
      tensor2_uint8(%1339) /* ty=tensor_uint8_t[] */
    },
    tensor2_uint8(%t236: Tensor[(?, ?), uint8]) => {
      %1340 = expand_dims(%t236, axis=0) /* ty=Tensor[(1, ?, ?), uint8] */;
      tensor3_uint8(%1340) /* ty=tensor_uint8_t[] */
    },
    tensor3_uint8(%t336: Tensor[(?, ?, ?), uint8]) => {
      %1341 = expand_dims(%t336, axis=0) /* ty=Tensor[(1, ?, ?, ?), uint8] */;
      tensor4_uint8(%1341) /* ty=tensor_uint8_t[] */
    },
    tensor4_uint8(%t436: Tensor[(?, ?, ?, ?), uint8]) => {
      %1342 = expand_dims(%t436, axis=0) /* ty=Tensor[(1, ?, ?, ?, ?), uint8] */;
      tensor5_uint8(%1342) /* ty=tensor_uint8_t[] */
    },
    tensor5_uint8(%t514: Tensor[(?, ?, ?, ?, ?), uint8]) => {
      %1343 = expand_dims(%t514, axis=0) /* ty=Tensor[(1, ?, ?, ?, ?, ?), uint8] */;
      tensor6_uint8(%1343) /* ty=tensor_uint8_t[] */
    },
  }
}

def @tensor_take_float16(%tensor54: tensor_float16_t[], %lower: int32, %upper: int32) -> tensor_float16_t[] {
  match? (%tensor54) {
    tensor1_float16(%t137: Tensor[(?), float16]) => {
      %1344 = arange(%lower, %upper, 1 /* ty=int32 */, start=meta[relay.Var][0], stop=meta[relay.Var][1], step=meta[relay.Constant][0], dtype="int32") /* ty=Tensor[(?), int32] */;
      %1345 = take(%t137, %1344) /* ty=Tensor[(?), float16] */;
      tensor1_float16(%1345) /* ty=tensor_float16_t[] */
    },
    tensor2_float16(%t237: Tensor[(?, ?), float16]) => {
      %1346 = arange(%lower, %upper, 1 /* ty=int32 */, start=meta[relay.Var][0], stop=meta[relay.Var][1], step=meta[relay.Constant][1], dtype="int32") /* ty=Tensor[(?), int32] */;
      %1347 = take(%t237, %1346, axis=0) /* ty=Tensor[(?, ?), float16] */;
      tensor2_float16(%1347) /* ty=tensor_float16_t[] */
    },
    tensor3_float16(%t337: Tensor[(?, ?, ?), float16]) => {
      %1348 = arange(%lower, %upper, 1 /* ty=int32 */, start=meta[relay.Var][0], stop=meta[relay.Var][1], step=meta[relay.Constant][2], dtype="int32") /* ty=Tensor[(?), int32] */;
      %1349 = take(%t337, %1348, axis=0) /* ty=Tensor[(?, ?, ?), float16] */;
      tensor3_float16(%1349) /* ty=tensor_float16_t[] */
    },
    tensor4_float16(%t437: Tensor[(?, ?, ?, ?), float16]) => {
      %1350 = arange(%lower, %upper, 1 /* ty=int32 */, start=meta[relay.Var][0], stop=meta[relay.Var][1], step=meta[relay.Constant][3], dtype="int32") /* ty=Tensor[(?), int32] */;
      %1351 = take(%t437, %1350, axis=0) /* ty=Tensor[(?, ?, ?, ?), float16] */;
      tensor4_float16(%1351) /* ty=tensor_float16_t[] */
    },
    tensor5_float16(%t515: Tensor[(?, ?, ?, ?, ?), float16]) => {
      %1352 = arange(%lower, %upper, 1 /* ty=int32 */, start=meta[relay.Var][0], stop=meta[relay.Var][1], step=meta[relay.Constant][4], dtype="int32") /* ty=Tensor[(?), int32] */;
      %1353 = take(%t515, %1352, axis=0) /* ty=Tensor[(?, ?, ?, ?, ?), float16] */;
      tensor5_float16(%1353) /* ty=tensor_float16_t[] */
    },
    tensor6_float16(%t61: Tensor[(?, ?, ?, ?, ?, ?), float16]) => {
      %1354 = arange(%lower, %upper, 1 /* ty=int32 */, start=meta[relay.Var][0], stop=meta[relay.Var][1], step=meta[relay.Constant][5], dtype="int32") /* ty=Tensor[(?), int32] */;
      %1355 = take(%t61, %1354, axis=0) /* ty=Tensor[(?, ?, ?, ?, ?, ?), float16] */;
      tensor6_float16(%1355) /* ty=tensor_float16_t[] */
    },
  }
}

def @tensor_take_float32(%tensor55: tensor_float32_t[], %lower1: int32, %upper1: int32) -> tensor_float32_t[] {
  match? (%tensor55) {
    tensor1_float32(%t138: Tensor[(?), float32]) => {
      %1356 = arange(%lower1, %upper1, 1 /* ty=int32 */, start=meta[relay.Var][2], stop=meta[relay.Var][3], step=meta[relay.Constant][6], dtype="int32") /* ty=Tensor[(?), int32] */;
      %1357 = take(%t138, %1356) /* ty=Tensor[(?), float32] */;
      tensor1_float32(%1357) /* ty=tensor_float32_t[] */
    },
    tensor2_float32(%t238: Tensor[(?, ?), float32]) => {
      %1358 = arange(%lower1, %upper1, 1 /* ty=int32 */, start=meta[relay.Var][2], stop=meta[relay.Var][3], step=meta[relay.Constant][7], dtype="int32") /* ty=Tensor[(?), int32] */;
      %1359 = take(%t238, %1358, axis=0) /* ty=Tensor[(?, ?), float32] */;
      tensor2_float32(%1359) /* ty=tensor_float32_t[] */
    },
    tensor3_float32(%t338: Tensor[(?, ?, ?), float32]) => {
      %1360 = arange(%lower1, %upper1, 1 /* ty=int32 */, start=meta[relay.Var][2], stop=meta[relay.Var][3], step=meta[relay.Constant][8], dtype="int32") /* ty=Tensor[(?), int32] */;
      %1361 = take(%t338, %1360, axis=0) /* ty=Tensor[(?, ?, ?), float32] */;
      tensor3_float32(%1361) /* ty=tensor_float32_t[] */
    },
    tensor4_float32(%t438: Tensor[(?, ?, ?, ?), float32]) => {
      %1362 = arange(%lower1, %upper1, 1 /* ty=int32 */, start=meta[relay.Var][2], stop=meta[relay.Var][3], step=meta[relay.Constant][9], dtype="int32") /* ty=Tensor[(?), int32] */;
      %1363 = take(%t438, %1362, axis=0) /* ty=Tensor[(?, ?, ?, ?), float32] */;
      tensor4_float32(%1363) /* ty=tensor_float32_t[] */
    },
    tensor5_float32(%t516: Tensor[(?, ?, ?, ?, ?), float32]) => {
      %1364 = arange(%lower1, %upper1, 1 /* ty=int32 */, start=meta[relay.Var][2], stop=meta[relay.Var][3], step=meta[relay.Constant][10], dtype="int32") /* ty=Tensor[(?), int32] */;
      %1365 = take(%t516, %1364, axis=0) /* ty=Tensor[(?, ?, ?, ?, ?), float32] */;
      tensor5_float32(%1365) /* ty=tensor_float32_t[] */
    },
    tensor6_float32(%t62: Tensor[(?, ?, ?, ?, ?, ?), float32]) => {
      %1366 = arange(%lower1, %upper1, 1 /* ty=int32 */, start=meta[relay.Var][2], stop=meta[relay.Var][3], step=meta[relay.Constant][11], dtype="int32") /* ty=Tensor[(?), int32] */;
      %1367 = take(%t62, %1366, axis=0) /* ty=Tensor[(?, ?, ?, ?, ?, ?), float32] */;
      tensor6_float32(%1367) /* ty=tensor_float32_t[] */
    },
  }
}

def @tensor_take_float64(%tensor56: tensor_float64_t[], %lower2: int32, %upper2: int32) -> tensor_float64_t[] {
  match? (%tensor56) {
    tensor1_float64(%t139: Tensor[(?), float64]) => {
      %1368 = arange(%lower2, %upper2, 1 /* ty=int32 */, start=meta[relay.Var][4], stop=meta[relay.Var][5], step=meta[relay.Constant][12], dtype="int32") /* ty=Tensor[(?), int32] */;
      %1369 = take(%t139, %1368) /* ty=Tensor[(?), float64] */;
      tensor1_float64(%1369) /* ty=tensor_float64_t[] */
    },
    tensor2_float64(%t239: Tensor[(?, ?), float64]) => {
      %1370 = arange(%lower2, %upper2, 1 /* ty=int32 */, start=meta[relay.Var][4], stop=meta[relay.Var][5], step=meta[relay.Constant][13], dtype="int32") /* ty=Tensor[(?), int32] */;
      %1371 = take(%t239, %1370, axis=0) /* ty=Tensor[(?, ?), float64] */;
      tensor2_float64(%1371) /* ty=tensor_float64_t[] */
    },
    tensor3_float64(%t339: Tensor[(?, ?, ?), float64]) => {
      %1372 = arange(%lower2, %upper2, 1 /* ty=int32 */, start=meta[relay.Var][4], stop=meta[relay.Var][5], step=meta[relay.Constant][14], dtype="int32") /* ty=Tensor[(?), int32] */;
      %1373 = take(%t339, %1372, axis=0) /* ty=Tensor[(?, ?, ?), float64] */;
      tensor3_float64(%1373) /* ty=tensor_float64_t[] */
    },
    tensor4_float64(%t439: Tensor[(?, ?, ?, ?), float64]) => {
      %1374 = arange(%lower2, %upper2, 1 /* ty=int32 */, start=meta[relay.Var][4], stop=meta[relay.Var][5], step=meta[relay.Constant][15], dtype="int32") /* ty=Tensor[(?), int32] */;
      %1375 = take(%t439, %1374, axis=0) /* ty=Tensor[(?, ?, ?, ?), float64] */;
      tensor4_float64(%1375) /* ty=tensor_float64_t[] */
    },
    tensor5_float64(%t517: Tensor[(?, ?, ?, ?, ?), float64]) => {
      %1376 = arange(%lower2, %upper2, 1 /* ty=int32 */, start=meta[relay.Var][4], stop=meta[relay.Var][5], step=meta[relay.Constant][16], dtype="int32") /* ty=Tensor[(?), int32] */;
      %1377 = take(%t517, %1376, axis=0) /* ty=Tensor[(?, ?, ?, ?, ?), float64] */;
      tensor5_float64(%1377) /* ty=tensor_float64_t[] */
    },
    tensor6_float64(%t63: Tensor[(?, ?, ?, ?, ?, ?), float64]) => {
      %1378 = arange(%lower2, %upper2, 1 /* ty=int32 */, start=meta[relay.Var][4], stop=meta[relay.Var][5], step=meta[relay.Constant][17], dtype="int32") /* ty=Tensor[(?), int32] */;
      %1379 = take(%t63, %1378, axis=0) /* ty=Tensor[(?, ?, ?, ?, ?, ?), float64] */;
      tensor6_float64(%1379) /* ty=tensor_float64_t[] */
    },
  }
}

def @tensor_take_int16(%tensor57: tensor_int16_t[], %lower3: int32, %upper3: int32) -> tensor_int16_t[] {
  match? (%tensor57) {
    tensor1_int16(%t140: Tensor[(?), int16]) => {
      %1380 = arange(%lower3, %upper3, 1 /* ty=int32 */, start=meta[relay.Var][6], stop=meta[relay.Var][7], step=meta[relay.Constant][18], dtype="int32") /* ty=Tensor[(?), int32] */;
      %1381 = take(%t140, %1380) /* ty=Tensor[(?), int16] */;
      tensor1_int16(%1381) /* ty=tensor_int16_t[] */
    },
    tensor2_int16(%t240: Tensor[(?, ?), int16]) => {
      %1382 = arange(%lower3, %upper3, 1 /* ty=int32 */, start=meta[relay.Var][6], stop=meta[relay.Var][7], step=meta[relay.Constant][19], dtype="int32") /* ty=Tensor[(?), int32] */;
      %1383 = take(%t240, %1382, axis=0) /* ty=Tensor[(?, ?), int16] */;
      tensor2_int16(%1383) /* ty=tensor_int16_t[] */
    },
    tensor3_int16(%t340: Tensor[(?, ?, ?), int16]) => {
      %1384 = arange(%lower3, %upper3, 1 /* ty=int32 */, start=meta[relay.Var][6], stop=meta[relay.Var][7], step=meta[relay.Constant][20], dtype="int32") /* ty=Tensor[(?), int32] */;
      %1385 = take(%t340, %1384, axis=0) /* ty=Tensor[(?, ?, ?), int16] */;
      tensor3_int16(%1385) /* ty=tensor_int16_t[] */
    },
    tensor4_int16(%t440: Tensor[(?, ?, ?, ?), int16]) => {
      %1386 = arange(%lower3, %upper3, 1 /* ty=int32 */, start=meta[relay.Var][6], stop=meta[relay.Var][7], step=meta[relay.Constant][21], dtype="int32") /* ty=Tensor[(?), int32] */;
      %1387 = take(%t440, %1386, axis=0) /* ty=Tensor[(?, ?, ?, ?), int16] */;
      tensor4_int16(%1387) /* ty=tensor_int16_t[] */
    },
    tensor5_int16(%t518: Tensor[(?, ?, ?, ?, ?), int16]) => {
      %1388 = arange(%lower3, %upper3, 1 /* ty=int32 */, start=meta[relay.Var][6], stop=meta[relay.Var][7], step=meta[relay.Constant][22], dtype="int32") /* ty=Tensor[(?), int32] */;
      %1389 = take(%t518, %1388, axis=0) /* ty=Tensor[(?, ?, ?, ?, ?), int16] */;
      tensor5_int16(%1389) /* ty=tensor_int16_t[] */
    },
    tensor6_int16(%t64: Tensor[(?, ?, ?, ?, ?, ?), int16]) => {
      %1390 = arange(%lower3, %upper3, 1 /* ty=int32 */, start=meta[relay.Var][6], stop=meta[relay.Var][7], step=meta[relay.Constant][23], dtype="int32") /* ty=Tensor[(?), int32] */;
      %1391 = take(%t64, %1390, axis=0) /* ty=Tensor[(?, ?, ?, ?, ?, ?), int16] */;
      tensor6_int16(%1391) /* ty=tensor_int16_t[] */
    },
  }
}

def @tensor_take_int32(%tensor58: tensor_int32_t[], %lower4: int32, %upper4: int32) -> tensor_int32_t[] {
  match? (%tensor58) {
    tensor1_int32(%t141: Tensor[(?), int32]) => {
      %1392 = arange(%lower4, %upper4, 1 /* ty=int32 */, start=meta[relay.Var][8], stop=meta[relay.Var][9], step=meta[relay.Constant][24], dtype="int32") /* ty=Tensor[(?), int32] */;
      %1393 = take(%t141, %1392) /* ty=Tensor[(?), int32] */;
      tensor1_int32(%1393) /* ty=tensor_int32_t[] */
    },
    tensor2_int32(%t241: Tensor[(?, ?), int32]) => {
      %1394 = arange(%lower4, %upper4, 1 /* ty=int32 */, start=meta[relay.Var][8], stop=meta[relay.Var][9], step=meta[relay.Constant][25], dtype="int32") /* ty=Tensor[(?), int32] */;
      %1395 = take(%t241, %1394, axis=0) /* ty=Tensor[(?, ?), int32] */;
      tensor2_int32(%1395) /* ty=tensor_int32_t[] */
    },
    tensor3_int32(%t341: Tensor[(?, ?, ?), int32]) => {
      %1396 = arange(%lower4, %upper4, 1 /* ty=int32 */, start=meta[relay.Var][8], stop=meta[relay.Var][9], step=meta[relay.Constant][26], dtype="int32") /* ty=Tensor[(?), int32] */;
      %1397 = take(%t341, %1396, axis=0) /* ty=Tensor[(?, ?, ?), int32] */;
      tensor3_int32(%1397) /* ty=tensor_int32_t[] */
    },
    tensor4_int32(%t441: Tensor[(?, ?, ?, ?), int32]) => {
      %1398 = arange(%lower4, %upper4, 1 /* ty=int32 */, start=meta[relay.Var][8], stop=meta[relay.Var][9], step=meta[relay.Constant][27], dtype="int32") /* ty=Tensor[(?), int32] */;
      %1399 = take(%t441, %1398, axis=0) /* ty=Tensor[(?, ?, ?, ?), int32] */;
      tensor4_int32(%1399) /* ty=tensor_int32_t[] */
    },
    tensor5_int32(%t519: Tensor[(?, ?, ?, ?, ?), int32]) => {
      %1400 = arange(%lower4, %upper4, 1 /* ty=int32 */, start=meta[relay.Var][8], stop=meta[relay.Var][9], step=meta[relay.Constant][28], dtype="int32") /* ty=Tensor[(?), int32] */;
      %1401 = take(%t519, %1400, axis=0) /* ty=Tensor[(?, ?, ?, ?, ?), int32] */;
      tensor5_int32(%1401) /* ty=tensor_int32_t[] */
    },
    tensor6_int32(%t65: Tensor[(?, ?, ?, ?, ?, ?), int32]) => {
      %1402 = arange(%lower4, %upper4, 1 /* ty=int32 */, start=meta[relay.Var][8], stop=meta[relay.Var][9], step=meta[relay.Constant][29], dtype="int32") /* ty=Tensor[(?), int32] */;
      %1403 = take(%t65, %1402, axis=0) /* ty=Tensor[(?, ?, ?, ?, ?, ?), int32] */;
      tensor6_int32(%1403) /* ty=tensor_int32_t[] */
    },
  }
}

def @tensor_take_int64(%tensor59: tensor_int64_t[], %lower5: int32, %upper5: int32) -> tensor_int64_t[] {
  match? (%tensor59) {
    tensor1_int64(%t142: Tensor[(?), int64]) => {
      %1404 = arange(%lower5, %upper5, 1 /* ty=int32 */, start=meta[relay.Var][10], stop=meta[relay.Var][11], step=meta[relay.Constant][30], dtype="int32") /* ty=Tensor[(?), int32] */;
      %1405 = take(%t142, %1404) /* ty=Tensor[(?), int64] */;
      tensor1_int64(%1405) /* ty=tensor_int64_t[] */
    },
    tensor2_int64(%t242: Tensor[(?, ?), int64]) => {
      %1406 = arange(%lower5, %upper5, 1 /* ty=int32 */, start=meta[relay.Var][10], stop=meta[relay.Var][11], step=meta[relay.Constant][31], dtype="int32") /* ty=Tensor[(?), int32] */;
      %1407 = take(%t242, %1406, axis=0) /* ty=Tensor[(?, ?), int64] */;
      tensor2_int64(%1407) /* ty=tensor_int64_t[] */
    },
    tensor3_int64(%t342: Tensor[(?, ?, ?), int64]) => {
      %1408 = arange(%lower5, %upper5, 1 /* ty=int32 */, start=meta[relay.Var][10], stop=meta[relay.Var][11], step=meta[relay.Constant][32], dtype="int32") /* ty=Tensor[(?), int32] */;
      %1409 = take(%t342, %1408, axis=0) /* ty=Tensor[(?, ?, ?), int64] */;
      tensor3_int64(%1409) /* ty=tensor_int64_t[] */
    },
    tensor4_int64(%t442: Tensor[(?, ?, ?, ?), int64]) => {
      %1410 = arange(%lower5, %upper5, 1 /* ty=int32 */, start=meta[relay.Var][10], stop=meta[relay.Var][11], step=meta[relay.Constant][33], dtype="int32") /* ty=Tensor[(?), int32] */;
      %1411 = take(%t442, %1410, axis=0) /* ty=Tensor[(?, ?, ?, ?), int64] */;
      tensor4_int64(%1411) /* ty=tensor_int64_t[] */
    },
    tensor5_int64(%t520: Tensor[(?, ?, ?, ?, ?), int64]) => {
      %1412 = arange(%lower5, %upper5, 1 /* ty=int32 */, start=meta[relay.Var][10], stop=meta[relay.Var][11], step=meta[relay.Constant][34], dtype="int32") /* ty=Tensor[(?), int32] */;
      %1413 = take(%t520, %1412, axis=0) /* ty=Tensor[(?, ?, ?, ?, ?), int64] */;
      tensor5_int64(%1413) /* ty=tensor_int64_t[] */
    },
    tensor6_int64(%t66: Tensor[(?, ?, ?, ?, ?, ?), int64]) => {
      %1414 = arange(%lower5, %upper5, 1 /* ty=int32 */, start=meta[relay.Var][10], stop=meta[relay.Var][11], step=meta[relay.Constant][35], dtype="int32") /* ty=Tensor[(?), int32] */;
      %1415 = take(%t66, %1414, axis=0) /* ty=Tensor[(?, ?, ?, ?, ?, ?), int64] */;
      tensor6_int64(%1415) /* ty=tensor_int64_t[] */
    },
  }
}

def @tensor_take_int8(%tensor60: tensor_int8_t[], %lower6: int32, %upper6: int32) -> tensor_int8_t[] {
  match? (%tensor60) {
    tensor1_int8(%t143: Tensor[(?), int8]) => {
      %1416 = arange(%lower6, %upper6, 1 /* ty=int32 */, start=meta[relay.Var][12], stop=meta[relay.Var][13], step=meta[relay.Constant][36], dtype="int32") /* ty=Tensor[(?), int32] */;
      %1417 = take(%t143, %1416) /* ty=Tensor[(?), int8] */;
      tensor1_int8(%1417) /* ty=tensor_int8_t[] */
    },
    tensor2_int8(%t243: Tensor[(?, ?), int8]) => {
      %1418 = arange(%lower6, %upper6, 1 /* ty=int32 */, start=meta[relay.Var][12], stop=meta[relay.Var][13], step=meta[relay.Constant][37], dtype="int32") /* ty=Tensor[(?), int32] */;
      %1419 = take(%t243, %1418, axis=0) /* ty=Tensor[(?, ?), int8] */;
      tensor2_int8(%1419) /* ty=tensor_int8_t[] */
    },
    tensor3_int8(%t343: Tensor[(?, ?, ?), int8]) => {
      %1420 = arange(%lower6, %upper6, 1 /* ty=int32 */, start=meta[relay.Var][12], stop=meta[relay.Var][13], step=meta[relay.Constant][38], dtype="int32") /* ty=Tensor[(?), int32] */;
      %1421 = take(%t343, %1420, axis=0) /* ty=Tensor[(?, ?, ?), int8] */;
      tensor3_int8(%1421) /* ty=tensor_int8_t[] */
    },
    tensor4_int8(%t443: Tensor[(?, ?, ?, ?), int8]) => {
      %1422 = arange(%lower6, %upper6, 1 /* ty=int32 */, start=meta[relay.Var][12], stop=meta[relay.Var][13], step=meta[relay.Constant][39], dtype="int32") /* ty=Tensor[(?), int32] */;
      %1423 = take(%t443, %1422, axis=0) /* ty=Tensor[(?, ?, ?, ?), int8] */;
      tensor4_int8(%1423) /* ty=tensor_int8_t[] */
    },
    tensor5_int8(%t521: Tensor[(?, ?, ?, ?, ?), int8]) => {
      %1424 = arange(%lower6, %upper6, 1 /* ty=int32 */, start=meta[relay.Var][12], stop=meta[relay.Var][13], step=meta[relay.Constant][40], dtype="int32") /* ty=Tensor[(?), int32] */;
      %1425 = take(%t521, %1424, axis=0) /* ty=Tensor[(?, ?, ?, ?, ?), int8] */;
      tensor5_int8(%1425) /* ty=tensor_int8_t[] */
    },
    tensor6_int8(%t67: Tensor[(?, ?, ?, ?, ?, ?), int8]) => {
      %1426 = arange(%lower6, %upper6, 1 /* ty=int32 */, start=meta[relay.Var][12], stop=meta[relay.Var][13], step=meta[relay.Constant][41], dtype="int32") /* ty=Tensor[(?), int32] */;
      %1427 = take(%t67, %1426, axis=0) /* ty=Tensor[(?, ?, ?, ?, ?, ?), int8] */;
      tensor6_int8(%1427) /* ty=tensor_int8_t[] */
    },
  }
}

def @tensor_take_uint16(%tensor61: tensor_uint16_t[], %lower7: int32, %upper7: int32) -> tensor_uint16_t[] {
  match? (%tensor61) {
    tensor1_uint16(%t144: Tensor[(?), uint16]) => {
      %1428 = arange(%lower7, %upper7, 1 /* ty=int32 */, start=meta[relay.Var][14], stop=meta[relay.Var][15], step=meta[relay.Constant][42], dtype="int32") /* ty=Tensor[(?), int32] */;
      %1429 = take(%t144, %1428) /* ty=Tensor[(?), uint16] */;
      tensor1_uint16(%1429) /* ty=tensor_uint16_t[] */
    },
    tensor2_uint16(%t244: Tensor[(?, ?), uint16]) => {
      %1430 = arange(%lower7, %upper7, 1 /* ty=int32 */, start=meta[relay.Var][14], stop=meta[relay.Var][15], step=meta[relay.Constant][43], dtype="int32") /* ty=Tensor[(?), int32] */;
      %1431 = take(%t244, %1430, axis=0) /* ty=Tensor[(?, ?), uint16] */;
      tensor2_uint16(%1431) /* ty=tensor_uint16_t[] */
    },
    tensor3_uint16(%t344: Tensor[(?, ?, ?), uint16]) => {
      %1432 = arange(%lower7, %upper7, 1 /* ty=int32 */, start=meta[relay.Var][14], stop=meta[relay.Var][15], step=meta[relay.Constant][44], dtype="int32") /* ty=Tensor[(?), int32] */;
      %1433 = take(%t344, %1432, axis=0) /* ty=Tensor[(?, ?, ?), uint16] */;
      tensor3_uint16(%1433) /* ty=tensor_uint16_t[] */
    },
    tensor4_uint16(%t444: Tensor[(?, ?, ?, ?), uint16]) => {
      %1434 = arange(%lower7, %upper7, 1 /* ty=int32 */, start=meta[relay.Var][14], stop=meta[relay.Var][15], step=meta[relay.Constant][45], dtype="int32") /* ty=Tensor[(?), int32] */;
      %1435 = take(%t444, %1434, axis=0) /* ty=Tensor[(?, ?, ?, ?), uint16] */;
      tensor4_uint16(%1435) /* ty=tensor_uint16_t[] */
    },
    tensor5_uint16(%t522: Tensor[(?, ?, ?, ?, ?), uint16]) => {
      %1436 = arange(%lower7, %upper7, 1 /* ty=int32 */, start=meta[relay.Var][14], stop=meta[relay.Var][15], step=meta[relay.Constant][46], dtype="int32") /* ty=Tensor[(?), int32] */;
      %1437 = take(%t522, %1436, axis=0) /* ty=Tensor[(?, ?, ?, ?, ?), uint16] */;
      tensor5_uint16(%1437) /* ty=tensor_uint16_t[] */
    },
    tensor6_uint16(%t68: Tensor[(?, ?, ?, ?, ?, ?), uint16]) => {
      %1438 = arange(%lower7, %upper7, 1 /* ty=int32 */, start=meta[relay.Var][14], stop=meta[relay.Var][15], step=meta[relay.Constant][47], dtype="int32") /* ty=Tensor[(?), int32] */;
      %1439 = take(%t68, %1438, axis=0) /* ty=Tensor[(?, ?, ?, ?, ?, ?), uint16] */;
      tensor6_uint16(%1439) /* ty=tensor_uint16_t[] */
    },
  }
}

def @tensor_take_uint8(%tensor62: tensor_uint8_t[], %lower8: int32, %upper8: int32) -> tensor_uint8_t[] {
  match? (%tensor62) {
    tensor1_uint8(%t145: Tensor[(?), uint8]) => {
      %1440 = arange(%lower8, %upper8, 1 /* ty=int32 */, start=meta[relay.Var][16], stop=meta[relay.Var][17], step=meta[relay.Constant][48], dtype="int32") /* ty=Tensor[(?), int32] */;
      %1441 = take(%t145, %1440) /* ty=Tensor[(?), uint8] */;
      tensor1_uint8(%1441) /* ty=tensor_uint8_t[] */
    },
    tensor2_uint8(%t245: Tensor[(?, ?), uint8]) => {
      %1442 = arange(%lower8, %upper8, 1 /* ty=int32 */, start=meta[relay.Var][16], stop=meta[relay.Var][17], step=meta[relay.Constant][49], dtype="int32") /* ty=Tensor[(?), int32] */;
      %1443 = take(%t245, %1442, axis=0) /* ty=Tensor[(?, ?), uint8] */;
      tensor2_uint8(%1443) /* ty=tensor_uint8_t[] */
    },
    tensor3_uint8(%t345: Tensor[(?, ?, ?), uint8]) => {
      %1444 = arange(%lower8, %upper8, 1 /* ty=int32 */, start=meta[relay.Var][16], stop=meta[relay.Var][17], step=meta[relay.Constant][50], dtype="int32") /* ty=Tensor[(?), int32] */;
      %1445 = take(%t345, %1444, axis=0) /* ty=Tensor[(?, ?, ?), uint8] */;
      tensor3_uint8(%1445) /* ty=tensor_uint8_t[] */
    },
    tensor4_uint8(%t445: Tensor[(?, ?, ?, ?), uint8]) => {
      %1446 = arange(%lower8, %upper8, 1 /* ty=int32 */, start=meta[relay.Var][16], stop=meta[relay.Var][17], step=meta[relay.Constant][51], dtype="int32") /* ty=Tensor[(?), int32] */;
      %1447 = take(%t445, %1446, axis=0) /* ty=Tensor[(?, ?, ?, ?), uint8] */;
      tensor4_uint8(%1447) /* ty=tensor_uint8_t[] */
    },
    tensor5_uint8(%t523: Tensor[(?, ?, ?, ?, ?), uint8]) => {
      %1448 = arange(%lower8, %upper8, 1 /* ty=int32 */, start=meta[relay.Var][16], stop=meta[relay.Var][17], step=meta[relay.Constant][52], dtype="int32") /* ty=Tensor[(?), int32] */;
      %1449 = take(%t523, %1448, axis=0) /* ty=Tensor[(?, ?, ?, ?, ?), uint8] */;
      tensor5_uint8(%1449) /* ty=tensor_uint8_t[] */
    },
    tensor6_uint8(%t69: Tensor[(?, ?, ?, ?, ?, ?), uint8]) => {
      %1450 = arange(%lower8, %upper8, 1 /* ty=int32 */, start=meta[relay.Var][16], stop=meta[relay.Var][17], step=meta[relay.Constant][53], dtype="int32") /* ty=Tensor[(?), int32] */;
      %1451 = take(%t69, %1450, axis=0) /* ty=Tensor[(?, ?, ?, ?, ?, ?), uint8] */;
      tensor6_uint8(%1451) /* ty=tensor_uint8_t[] */
    },
  }
}

def @tl[A](%xs13: List[A]) -> List[A] {
  match? (%xs13) {
    Cons(_, %rest6: List[A]) => {
      %rest6
    },
  }
}

def @tmap[A, B](%f10: fn (A) -> B, %t60: Tree[A]) -> Tree[B] {
  match (%t60) {
    Rose(%v9: A, %sub_trees1: List[Tree[A]]) => {
      let %list_f: fn (Tree[A]) -> Tree[B] = fn (%tt: Tree[A]) -> Tree[B] {
        @tmap(%f10, %tt) /* /root/tvm/python/tvm/relay/std/prelude.rly */ /* ty=Tree[B] */
      };
      %1452 = %f10(%v9) /* /root/tvm/python/tvm/relay/std/prelude.rly */ /* ty=B */;
      %1453 = @map(%list_f, %sub_trees1) /* /root/tvm/python/tvm/relay/std/prelude.rly */ /* ty=List[Tree[B]] */;
      Rose(%1452, %1453) /* /root/tvm/python/tvm/relay/std/prelude.rly */ /* ty=Tree[B] */
    },
  }
}

def @unfoldl[A, B](%f11: fn (A) -> Option[(A, B)], %seed: A) -> List[B] {
  %1454 = @unfoldr(%f11, %seed) /* /root/tvm/python/tvm/relay/std/prelude.rly */ /* ty=List[B] */;
  @rev(%1454) /* /root/tvm/python/tvm/relay/std/prelude.rly */ /* ty=List[B] */
}

def @unfoldr[A, B](%f12: fn (A) -> Option[(A, B)], %seed1: A) -> List[B] {
  %1455 = %f12(%seed1) /* /root/tvm/python/tvm/relay/std/prelude.rly */ /* ty=Option[(A, B)] */;
  match (%1455) {
    Some(%val: (A, B)) => {
      %1456 = %val.0;
      %1457 = %val.1;
      %1458 = @unfoldr(%f12, %1456) /* /root/tvm/python/tvm/relay/std/prelude.rly */ /* ty=List[B] */;
      Cons(%1457, %1458) /* /root/tvm/python/tvm/relay/std/prelude.rly */ /* ty=List[B] */
    },
    None => {
      Nil /* ty=List[B] */
    },
  }
}

def @update[A](%xs14: List[A], %n2: int32, %v10: A) -> List[A] {
  %1459 = equal(%n2, 0 /* ty=int32 */) /* /root/tvm/python/tvm/relay/std/prelude.rly */ /* ty=bool */;
  if (%1459) {
    %1460 = @tl(%xs14) /* /root/tvm/python/tvm/relay/std/prelude.rly */ /* ty=List[A] */;
    Cons(%v10, %1460) /* /root/tvm/python/tvm/relay/std/prelude.rly */ /* ty=List[A] */
  } else {
    %1461 = @tl(%xs14) /* /root/tvm/python/tvm/relay/std/prelude.rly */ /* ty=List[A] */;
    %1462 = subtract(%n2, 1 /* ty=int32 */) /* /root/tvm/python/tvm/relay/std/prelude.rly */ /* ty=int32 */;
    %1463 = @hd(%xs14) /* /root/tvm/python/tvm/relay/std/prelude.rly */ /* ty=A */;
    %1464 = @update(%1461, %1462, %v10) /* /root/tvm/python/tvm/relay/std/prelude.rly */ /* ty=List[A] */;
    Cons(%1463, %1464) /* /root/tvm/python/tvm/relay/std/prelude.rly */ /* ty=List[A] */
  }
}

def @zip[A, B](%xs15: List[A], %ys1: List[B]) -> List[(A, B)] {
  %1465 = (%xs15, %ys1);
  match (%1465) {
    (Cons(%x57: A, %x_rest: List[A]), Cons(%y10: B, %y_rest: List[B])) => {
      %1466 = (%x57, %y10);
      %1467 = @zip(%x_rest, %y_rest) /* /root/tvm/python/tvm/relay/std/prelude.rly */ /* ty=List[(A, B)] */;
      Cons(%1466, %1467) /* /root/tvm/python/tvm/relay/std/prelude.rly */ /* ty=List[(A, B)] */
    },
    _ => {
      Nil /* ty=List[(A, B)] */
    },
  }
}

