#[version = "0.0.5"]
def @main(%data: Tensor[(1, 3, 224, 224), float32], %efficientnet0_features_conv0_weight: Tensor[(32, 3, 3, 3), float32], %efficientnet0_features_batchnorm0_gamma: Tensor[(32), float32], %efficientnet0_features_batchnorm0_beta: Tensor[(32), float32], %efficientnet0_features_batchnorm0_running_mean: Tensor[(32), float32], %efficientnet0_features_batchnorm0_running_var: Tensor[(32), float32], %efficientnet0_features_mbconv0_conv0_weight: Tensor[(32, 32, 1, 1), float32], %efficientnet0_features_mbconv0_batchnorm0_gamma: Tensor[(32), float32], %efficientnet0_features_mbconv0_batchnorm0_beta: Tensor[(32), float32], %efficientnet0_features_mbconv0_batchnorm0_running_mean: Tensor[(32), float32], %efficientnet0_features_mbconv0_batchnorm0_running_var: Tensor[(32), float32], %efficientnet0_features_mbconv0_conv1_weight: Tensor[(32, 1, 3, 3), float32], %efficientnet0_features_mbconv0_batchnorm1_gamma: Tensor[(32), float32], %efficientnet0_features_mbconv0_batchnorm1_beta: Tensor[(32), float32], %efficientnet0_features_mbconv0_batchnorm1_running_mean: Tensor[(32), float32], %efficientnet0_features_mbconv0_batchnorm1_running_var: Tensor[(32), float32], %efficientnet0_features_mbconv0_conv2_weight: Tensor[(16, 32, 1, 1), float32], %efficientnet0_features_mbconv0_batchnorm2_gamma: Tensor[(16), float32], %efficientnet0_features_mbconv0_batchnorm2_beta: Tensor[(16), float32], %efficientnet0_features_mbconv0_batchnorm2_running_mean: Tensor[(16), float32], %efficientnet0_features_mbconv0_batchnorm2_running_var: Tensor[(16), float32], %efficientnet0_features_mbconv1_conv0_weight: Tensor[(96, 16, 1, 1), float32], %efficientnet0_features_mbconv1_batchnorm0_gamma: Tensor[(96), float32], %efficientnet0_features_mbconv1_batchnorm0_beta: Tensor[(96), float32], %efficientnet0_features_mbconv1_batchnorm0_running_mean: Tensor[(96), float32], %efficientnet0_features_mbconv1_batchnorm0_running_var: Tensor[(96), float32], %efficientnet0_features_mbconv1_conv1_weight: Tensor[(96, 1, 3, 3), float32], %efficientnet0_features_mbconv1_batchnorm1_gamma: Tensor[(96), float32], %efficientnet0_features_mbconv1_batchnorm1_beta: Tensor[(96), float32], %efficientnet0_features_mbconv1_batchnorm1_running_mean: Tensor[(96), float32], %efficientnet0_features_mbconv1_batchnorm1_running_var: Tensor[(96), float32], %efficientnet0_features_mbconv1_conv2_weight: Tensor[(24, 96, 1, 1), float32], %efficientnet0_features_mbconv1_batchnorm2_gamma: Tensor[(24), float32], %efficientnet0_features_mbconv1_batchnorm2_beta: Tensor[(24), float32], %efficientnet0_features_mbconv1_batchnorm2_running_mean: Tensor[(24), float32], %efficientnet0_features_mbconv1_batchnorm2_running_var: Tensor[(24), float32], %efficientnet0_features_mbconv2_conv0_weight: Tensor[(144, 24, 1, 1), float32], %efficientnet0_features_mbconv2_batchnorm0_gamma: Tensor[(144), float32], %efficientnet0_features_mbconv2_batchnorm0_beta: Tensor[(144), float32], %efficientnet0_features_mbconv2_batchnorm0_running_mean: Tensor[(144), float32], %efficientnet0_features_mbconv2_batchnorm0_running_var: Tensor[(144), float32], %efficientnet0_features_mbconv2_conv1_weight: Tensor[(144, 1, 3, 3), float32], %efficientnet0_features_mbconv2_batchnorm1_gamma: Tensor[(144), float32], %efficientnet0_features_mbconv2_batchnorm1_beta: Tensor[(144), float32], %efficientnet0_features_mbconv2_batchnorm1_running_mean: Tensor[(144), float32], %efficientnet0_features_mbconv2_batchnorm1_running_var: Tensor[(144), float32], %efficientnet0_features_mbconv2_conv2_weight: Tensor[(24, 144, 1, 1), float32], %efficientnet0_features_mbconv2_batchnorm2_gamma: Tensor[(24), float32], %efficientnet0_features_mbconv2_batchnorm2_beta: Tensor[(24), float32], %efficientnet0_features_mbconv2_batchnorm2_running_mean: Tensor[(24), float32], %efficientnet0_features_mbconv2_batchnorm2_running_var: Tensor[(24), float32], %efficientnet0_features_mbconv3_conv0_weight: Tensor[(144, 24, 1, 1), float32], %efficientnet0_features_mbconv3_batchnorm0_gamma: Tensor[(144), float32], %efficientnet0_features_mbconv3_batchnorm0_beta: Tensor[(144), float32], %efficientnet0_features_mbconv3_batchnorm0_running_mean: Tensor[(144), float32], %efficientnet0_features_mbconv3_batchnorm0_running_var: Tensor[(144), float32], %efficientnet0_features_mbconv3_conv1_weight: Tensor[(144, 1, 5, 5), float32], %efficientnet0_features_mbconv3_batchnorm1_gamma: Tensor[(144), float32], %efficientnet0_features_mbconv3_batchnorm1_beta: Tensor[(144), float32], %efficientnet0_features_mbconv3_batchnorm1_running_mean: Tensor[(144), float32], %efficientnet0_features_mbconv3_batchnorm1_running_var: Tensor[(144), float32], %efficientnet0_features_mbconv3_conv2_weight: Tensor[(40, 144, 1, 1), float32], %efficientnet0_features_mbconv3_batchnorm2_gamma: Tensor[(40), float32], %efficientnet0_features_mbconv3_batchnorm2_beta: Tensor[(40), float32], %efficientnet0_features_mbconv3_batchnorm2_running_mean: Tensor[(40), float32], %efficientnet0_features_mbconv3_batchnorm2_running_var: Tensor[(40), float32], %efficientnet0_features_mbconv4_conv0_weight: Tensor[(240, 40, 1, 1), float32], %efficientnet0_features_mbconv4_batchnorm0_gamma: Tensor[(240), float32], %efficientnet0_features_mbconv4_batchnorm0_beta: Tensor[(240), float32], %efficientnet0_features_mbconv4_batchnorm0_running_mean: Tensor[(240), float32], %efficientnet0_features_mbconv4_batchnorm0_running_var: Tensor[(240), float32], %efficientnet0_features_mbconv4_conv1_weight: Tensor[(240, 1, 5, 5), float32], %efficientnet0_features_mbconv4_batchnorm1_gamma: Tensor[(240), float32], %efficientnet0_features_mbconv4_batchnorm1_beta: Tensor[(240), float32], %efficientnet0_features_mbconv4_batchnorm1_running_mean: Tensor[(240), float32], %efficientnet0_features_mbconv4_batchnorm1_running_var: Tensor[(240), float32], %efficientnet0_features_mbconv4_conv2_weight: Tensor[(40, 240, 1, 1), float32], %efficientnet0_features_mbconv4_batchnorm2_gamma: Tensor[(40), float32], %efficientnet0_features_mbconv4_batchnorm2_beta: Tensor[(40), float32], %efficientnet0_features_mbconv4_batchnorm2_running_mean: Tensor[(40), float32], %efficientnet0_features_mbconv4_batchnorm2_running_var: Tensor[(40), float32], %efficientnet0_features_mbconv5_conv0_weight: Tensor[(240, 40, 1, 1), float32], %efficientnet0_features_mbconv5_batchnorm0_gamma: Tensor[(240), float32], %efficientnet0_features_mbconv5_batchnorm0_beta: Tensor[(240), float32], %efficientnet0_features_mbconv5_batchnorm0_running_mean: Tensor[(240), float32], %efficientnet0_features_mbconv5_batchnorm0_running_var: Tensor[(240), float32], %efficientnet0_features_mbconv5_conv1_weight: Tensor[(240, 1, 3, 3), float32], %efficientnet0_features_mbconv5_batchnorm1_gamma: Tensor[(240), float32], %efficientnet0_features_mbconv5_batchnorm1_beta: Tensor[(240), float32], %efficientnet0_features_mbconv5_batchnorm1_running_mean: Tensor[(240), float32], %efficientnet0_features_mbconv5_batchnorm1_running_var: Tensor[(240), float32], %efficientnet0_features_mbconv5_conv2_weight: Tensor[(80, 240, 1, 1), float32], %efficientnet0_features_mbconv5_batchnorm2_gamma: Tensor[(80), float32], %efficientnet0_features_mbconv5_batchnorm2_beta: Tensor[(80), float32], %efficientnet0_features_mbconv5_batchnorm2_running_mean: Tensor[(80), float32], %efficientnet0_features_mbconv5_batchnorm2_running_var: Tensor[(80), float32], %efficientnet0_features_mbconv6_conv0_weight: Tensor[(480, 80, 1, 1), float32], %efficientnet0_features_mbconv6_batchnorm0_gamma: Tensor[(480), float32], %efficientnet0_features_mbconv6_batchnorm0_beta: Tensor[(480), float32], %efficientnet0_features_mbconv6_batchnorm0_running_mean: Tensor[(480), float32], %efficientnet0_features_mbconv6_batchnorm0_running_var: Tensor[(480), float32], %efficientnet0_features_mbconv6_conv1_weight: Tensor[(480, 1, 3, 3), float32], %efficientnet0_features_mbconv6_batchnorm1_gamma: Tensor[(480), float32], %efficientnet0_features_mbconv6_batchnorm1_beta: Tensor[(480), float32], %efficientnet0_features_mbconv6_batchnorm1_running_mean: Tensor[(480), float32], %efficientnet0_features_mbconv6_batchnorm1_running_var: Tensor[(480), float32], %efficientnet0_features_mbconv6_conv2_weight: Tensor[(80, 480, 1, 1), float32], %efficientnet0_features_mbconv6_batchnorm2_gamma: Tensor[(80), float32], %efficientnet0_features_mbconv6_batchnorm2_beta: Tensor[(80), float32], %efficientnet0_features_mbconv6_batchnorm2_running_mean: Tensor[(80), float32], %efficientnet0_features_mbconv6_batchnorm2_running_var: Tensor[(80), float32], %efficientnet0_features_mbconv7_conv0_weight: Tensor[(480, 80, 1, 1), float32], %efficientnet0_features_mbconv7_batchnorm0_gamma: Tensor[(480), float32], %efficientnet0_features_mbconv7_batchnorm0_beta: Tensor[(480), float32], %efficientnet0_features_mbconv7_batchnorm0_running_mean: Tensor[(480), float32], %efficientnet0_features_mbconv7_batchnorm0_running_var: Tensor[(480), float32], %efficientnet0_features_mbconv7_conv1_weight: Tensor[(480, 1, 3, 3), float32], %efficientnet0_features_mbconv7_batchnorm1_gamma: Tensor[(480), float32], %efficientnet0_features_mbconv7_batchnorm1_beta: Tensor[(480), float32], %efficientnet0_features_mbconv7_batchnorm1_running_mean: Tensor[(480), float32], %efficientnet0_features_mbconv7_batchnorm1_running_var: Tensor[(480), float32], %efficientnet0_features_mbconv7_conv2_weight: Tensor[(80, 480, 1, 1), float32], %efficientnet0_features_mbconv7_batchnorm2_gamma: Tensor[(80), float32], %efficientnet0_features_mbconv7_batchnorm2_beta: Tensor[(80), float32], %efficientnet0_features_mbconv7_batchnorm2_running_mean: Tensor[(80), float32], %efficientnet0_features_mbconv7_batchnorm2_running_var: Tensor[(80), float32], %efficientnet0_features_mbconv8_conv0_weight: Tensor[(480, 80, 1, 1), float32], %efficientnet0_features_mbconv8_batchnorm0_gamma: Tensor[(480), float32], %efficientnet0_features_mbconv8_batchnorm0_beta: Tensor[(480), float32], %efficientnet0_features_mbconv8_batchnorm0_running_mean: Tensor[(480), float32], %efficientnet0_features_mbconv8_batchnorm0_running_var: Tensor[(480), float32], %efficientnet0_features_mbconv8_conv1_weight: Tensor[(480, 1, 5, 5), float32], %efficientnet0_features_mbconv8_batchnorm1_gamma: Tensor[(480), float32], %efficientnet0_features_mbconv8_batchnorm1_beta: Tensor[(480), float32], %efficientnet0_features_mbconv8_batchnorm1_running_mean: Tensor[(480), float32], %efficientnet0_features_mbconv8_batchnorm1_running_var: Tensor[(480), float32], %efficientnet0_features_mbconv8_conv2_weight: Tensor[(112, 480, 1, 1), float32], %efficientnet0_features_mbconv8_batchnorm2_gamma: Tensor[(112), float32], %efficientnet0_features_mbconv8_batchnorm2_beta: Tensor[(112), float32], %efficientnet0_features_mbconv8_batchnorm2_running_mean: Tensor[(112), float32], %efficientnet0_features_mbconv8_batchnorm2_running_var: Tensor[(112), float32], %efficientnet0_features_mbconv9_conv0_weight: Tensor[(672, 112, 1, 1), float32], %efficientnet0_features_mbconv9_batchnorm0_gamma: Tensor[(672), float32], %efficientnet0_features_mbconv9_batchnorm0_beta: Tensor[(672), float32], %efficientnet0_features_mbconv9_batchnorm0_running_mean: Tensor[(672), float32], %efficientnet0_features_mbconv9_batchnorm0_running_var: Tensor[(672), float32], %efficientnet0_features_mbconv9_conv1_weight: Tensor[(672, 1, 5, 5), float32], %efficientnet0_features_mbconv9_batchnorm1_gamma: Tensor[(672), float32], %efficientnet0_features_mbconv9_batchnorm1_beta: Tensor[(672), float32], %efficientnet0_features_mbconv9_batchnorm1_running_mean: Tensor[(672), float32], %efficientnet0_features_mbconv9_batchnorm1_running_var: Tensor[(672), float32], %efficientnet0_features_mbconv9_conv2_weight: Tensor[(112, 672, 1, 1), float32], %efficientnet0_features_mbconv9_batchnorm2_gamma: Tensor[(112), float32], %efficientnet0_features_mbconv9_batchnorm2_beta: Tensor[(112), float32], %efficientnet0_features_mbconv9_batchnorm2_running_mean: Tensor[(112), float32], %efficientnet0_features_mbconv9_batchnorm2_running_var: Tensor[(112), float32], %efficientnet0_features_mbconv10_conv0_weight: Tensor[(672, 112, 1, 1), float32], %efficientnet0_features_mbconv10_batchnorm0_gamma: Tensor[(672), float32], %efficientnet0_features_mbconv10_batchnorm0_beta: Tensor[(672), float32], %efficientnet0_features_mbconv10_batchnorm0_running_mean: Tensor[(672), float32], %efficientnet0_features_mbconv10_batchnorm0_running_var: Tensor[(672), float32], %efficientnet0_features_mbconv10_conv1_weight: Tensor[(672, 1, 5, 5), float32], %efficientnet0_features_mbconv10_batchnorm1_gamma: Tensor[(672), float32], %efficientnet0_features_mbconv10_batchnorm1_beta: Tensor[(672), float32], %efficientnet0_features_mbconv10_batchnorm1_running_mean: Tensor[(672), float32], %efficientnet0_features_mbconv10_batchnorm1_running_var: Tensor[(672), float32], %efficientnet0_features_mbconv10_conv2_weight: Tensor[(112, 672, 1, 1), float32], %efficientnet0_features_mbconv10_batchnorm2_gamma: Tensor[(112), float32], %efficientnet0_features_mbconv10_batchnorm2_beta: Tensor[(112), float32], %efficientnet0_features_mbconv10_batchnorm2_running_mean: Tensor[(112), float32], %efficientnet0_features_mbconv10_batchnorm2_running_var: Tensor[(112), float32], %efficientnet0_features_mbconv11_conv0_weight: Tensor[(672, 112, 1, 1), float32], %efficientnet0_features_mbconv11_batchnorm0_gamma: Tensor[(672), float32], %efficientnet0_features_mbconv11_batchnorm0_beta: Tensor[(672), float32], %efficientnet0_features_mbconv11_batchnorm0_running_mean: Tensor[(672), float32], %efficientnet0_features_mbconv11_batchnorm0_running_var: Tensor[(672), float32], %efficientnet0_features_mbconv11_conv1_weight: Tensor[(672, 1, 5, 5), float32], %efficientnet0_features_mbconv11_batchnorm1_gamma: Tensor[(672), float32], %efficientnet0_features_mbconv11_batchnorm1_beta: Tensor[(672), float32], %efficientnet0_features_mbconv11_batchnorm1_running_mean: Tensor[(672), float32], %efficientnet0_features_mbconv11_batchnorm1_running_var: Tensor[(672), float32], %efficientnet0_features_mbconv11_conv2_weight: Tensor[(192, 672, 1, 1), float32], %efficientnet0_features_mbconv11_batchnorm2_gamma: Tensor[(192), float32], %efficientnet0_features_mbconv11_batchnorm2_beta: Tensor[(192), float32], %efficientnet0_features_mbconv11_batchnorm2_running_mean: Tensor[(192), float32], %efficientnet0_features_mbconv11_batchnorm2_running_var: Tensor[(192), float32], %efficientnet0_features_mbconv12_conv0_weight: Tensor[(1152, 192, 1, 1), float32], %efficientnet0_features_mbconv12_batchnorm0_gamma: Tensor[(1152), float32], %efficientnet0_features_mbconv12_batchnorm0_beta: Tensor[(1152), float32], %efficientnet0_features_mbconv12_batchnorm0_running_mean: Tensor[(1152), float32], %efficientnet0_features_mbconv12_batchnorm0_running_var: Tensor[(1152), float32], %efficientnet0_features_mbconv12_conv1_weight: Tensor[(1152, 1, 5, 5), float32], %efficientnet0_features_mbconv12_batchnorm1_gamma: Tensor[(1152), float32], %efficientnet0_features_mbconv12_batchnorm1_beta: Tensor[(1152), float32], %efficientnet0_features_mbconv12_batchnorm1_running_mean: Tensor[(1152), float32], %efficientnet0_features_mbconv12_batchnorm1_running_var: Tensor[(1152), float32], %efficientnet0_features_mbconv12_conv2_weight: Tensor[(192, 1152, 1, 1), float32], %efficientnet0_features_mbconv12_batchnorm2_gamma: Tensor[(192), float32], %efficientnet0_features_mbconv12_batchnorm2_beta: Tensor[(192), float32], %efficientnet0_features_mbconv12_batchnorm2_running_mean: Tensor[(192), float32], %efficientnet0_features_mbconv12_batchnorm2_running_var: Tensor[(192), float32], %efficientnet0_features_mbconv13_conv0_weight: Tensor[(1152, 192, 1, 1), float32], %efficientnet0_features_mbconv13_batchnorm0_gamma: Tensor[(1152), float32], %efficientnet0_features_mbconv13_batchnorm0_beta: Tensor[(1152), float32], %efficientnet0_features_mbconv13_batchnorm0_running_mean: Tensor[(1152), float32], %efficientnet0_features_mbconv13_batchnorm0_running_var: Tensor[(1152), float32], %efficientnet0_features_mbconv13_conv1_weight: Tensor[(1152, 1, 5, 5), float32], %efficientnet0_features_mbconv13_batchnorm1_gamma: Tensor[(1152), float32], %efficientnet0_features_mbconv13_batchnorm1_beta: Tensor[(1152), float32], %efficientnet0_features_mbconv13_batchnorm1_running_mean: Tensor[(1152), float32], %efficientnet0_features_mbconv13_batchnorm1_running_var: Tensor[(1152), float32], %efficientnet0_features_mbconv13_conv2_weight: Tensor[(192, 1152, 1, 1), float32], %efficientnet0_features_mbconv13_batchnorm2_gamma: Tensor[(192), float32], %efficientnet0_features_mbconv13_batchnorm2_beta: Tensor[(192), float32], %efficientnet0_features_mbconv13_batchnorm2_running_mean: Tensor[(192), float32], %efficientnet0_features_mbconv13_batchnorm2_running_var: Tensor[(192), float32], %efficientnet0_features_mbconv14_conv0_weight: Tensor[(1152, 192, 1, 1), float32], %efficientnet0_features_mbconv14_batchnorm0_gamma: Tensor[(1152), float32], %efficientnet0_features_mbconv14_batchnorm0_beta: Tensor[(1152), float32], %efficientnet0_features_mbconv14_batchnorm0_running_mean: Tensor[(1152), float32], %efficientnet0_features_mbconv14_batchnorm0_running_var: Tensor[(1152), float32], %efficientnet0_features_mbconv14_conv1_weight: Tensor[(1152, 1, 5, 5), float32], %efficientnet0_features_mbconv14_batchnorm1_gamma: Tensor[(1152), float32], %efficientnet0_features_mbconv14_batchnorm1_beta: Tensor[(1152), float32], %efficientnet0_features_mbconv14_batchnorm1_running_mean: Tensor[(1152), float32], %efficientnet0_features_mbconv14_batchnorm1_running_var: Tensor[(1152), float32], %efficientnet0_features_mbconv14_conv2_weight: Tensor[(192, 1152, 1, 1), float32], %efficientnet0_features_mbconv14_batchnorm2_gamma: Tensor[(192), float32], %efficientnet0_features_mbconv14_batchnorm2_beta: Tensor[(192), float32], %efficientnet0_features_mbconv14_batchnorm2_running_mean: Tensor[(192), float32], %efficientnet0_features_mbconv14_batchnorm2_running_var: Tensor[(192), float32], %efficientnet0_features_mbconv15_conv0_weight: Tensor[(1152, 192, 1, 1), float32], %efficientnet0_features_mbconv15_batchnorm0_gamma: Tensor[(1152), float32], %efficientnet0_features_mbconv15_batchnorm0_beta: Tensor[(1152), float32], %efficientnet0_features_mbconv15_batchnorm0_running_mean: Tensor[(1152), float32], %efficientnet0_features_mbconv15_batchnorm0_running_var: Tensor[(1152), float32], %efficientnet0_features_mbconv15_conv1_weight: Tensor[(1152, 1, 3, 3), float32], %efficientnet0_features_mbconv15_batchnorm1_gamma: Tensor[(1152), float32], %efficientnet0_features_mbconv15_batchnorm1_beta: Tensor[(1152), float32], %efficientnet0_features_mbconv15_batchnorm1_running_mean: Tensor[(1152), float32], %efficientnet0_features_mbconv15_batchnorm1_running_var: Tensor[(1152), float32], %efficientnet0_features_mbconv15_conv2_weight: Tensor[(320, 1152, 1, 1), float32], %efficientnet0_features_mbconv15_batchnorm2_gamma: Tensor[(320), float32], %efficientnet0_features_mbconv15_batchnorm2_beta: Tensor[(320), float32], %efficientnet0_features_mbconv15_batchnorm2_running_mean: Tensor[(320), float32], %efficientnet0_features_mbconv15_batchnorm2_running_var: Tensor[(320), float32], %efficientnet0_features_conv1_weight: Tensor[(1280, 320, 1, 1), float32], %efficientnet0_features_batchnorm1_gamma: Tensor[(1280), float32], %efficientnet0_features_batchnorm1_beta: Tensor[(1280), float32], %efficientnet0_features_batchnorm1_running_mean: Tensor[(1280), float32], %efficientnet0_features_batchnorm1_running_var: Tensor[(1280), float32], %efficientnet0_output_pred_weight: Tensor[(1000, 1280, 1, 1), float32]) -> Tensor[(1, 1000), float32] {
  %0 = nn.pad(%data, 0 /* ty=int32 */, pad_width=[[0, 0], [0, 0], [1, 1], [1, 1]]) /* ty=Tensor[(1, 3, 226, 226), float32] */;
  %1 = add(%efficientnet0_features_batchnorm0_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(32), float32] */;
  %2 = sqrt(%1) /* ty=Tensor[(32), float32] */;
  %3 = divide(1f /* ty=float32 */, %2) /* ty=Tensor[(32), float32] */;
  %4 = multiply(%3, %efficientnet0_features_batchnorm0_gamma) /* ty=Tensor[(32), float32] */;
  %5 = nn.conv2d(%0, %efficientnet0_features_conv0_weight, strides=[2, 2], padding=[0, 0, 0, 0], channels=32, kernel_size=[3, 3]) /* ty=Tensor[(1, 32, 112, 112), float32] */;
  %6 = expand_dims(%4, axis=1, num_newaxis=2) /* ty=Tensor[(32, 1, 1), float32] */;
  %7 = negative(%efficientnet0_features_batchnorm0_running_mean) /* ty=Tensor[(32), float32] */;
  %8 = multiply(%7, %4) /* ty=Tensor[(32), float32] */;
  %9 = add(%8, %efficientnet0_features_batchnorm0_beta) /* ty=Tensor[(32), float32] */;
  %10 = multiply(%5, %6) /* ty=Tensor[(1, 32, 112, 112), float32] */;
  %11 = expand_dims(%9, axis=1, num_newaxis=2) /* ty=Tensor[(32, 1, 1), float32] */;
  %12 = add(%efficientnet0_features_batchnorm0_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(32), float32] */;
  %13 = sqrt(%12) /* ty=Tensor[(32), float32] */;
  %14 = divide(1f /* ty=float32 */, %13) /* ty=Tensor[(32), float32] */;
  %15 = multiply(%14, %efficientnet0_features_batchnorm0_gamma) /* ty=Tensor[(32), float32] */;
  %16 = expand_dims(%15, axis=1, num_newaxis=2) /* ty=Tensor[(32, 1, 1), float32] */;
  %17 = negative(%efficientnet0_features_batchnorm0_running_mean) /* ty=Tensor[(32), float32] */;
  %18 = multiply(%17, %15) /* ty=Tensor[(32), float32] */;
  %19 = add(%18, %efficientnet0_features_batchnorm0_beta) /* ty=Tensor[(32), float32] */;
  %20 = multiply(%5, %16) /* ty=Tensor[(1, 32, 112, 112), float32] */;
  %21 = expand_dims(%19, axis=1, num_newaxis=2) /* ty=Tensor[(32, 1, 1), float32] */;
  %22 = add(%20, %21) /* ty=Tensor[(1, 32, 112, 112), float32] */;
  %23 = multiply(%22, 1f /* ty=float32 */) /* ty=Tensor[(1, 32, 112, 112), float32] */;
  %24 = add(%10, %11) /* ty=Tensor[(1, 32, 112, 112), float32] */;
  %25 = sigmoid(%23) /* ty=Tensor[(1, 32, 112, 112), float32] */;
  %26 = multiply(%24, %25) /* ty=Tensor[(1, 32, 112, 112), float32] */;
  %27 = add(%efficientnet0_features_mbconv0_batchnorm0_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(32), float32] */;
  %28 = sqrt(%27) /* ty=Tensor[(32), float32] */;
  %29 = divide(1f /* ty=float32 */, %28) /* ty=Tensor[(32), float32] */;
  %30 = multiply(%29, %efficientnet0_features_mbconv0_batchnorm0_gamma) /* ty=Tensor[(32), float32] */;
  %31 = nn.conv2d(%26, %efficientnet0_features_mbconv0_conv0_weight, padding=[0, 0, 0, 0], channels=32, kernel_size=[1, 1]) /* ty=Tensor[(1, 32, 112, 112), float32] */;
  %32 = expand_dims(%30, axis=1, num_newaxis=2) /* ty=Tensor[(32, 1, 1), float32] */;
  %33 = negative(%efficientnet0_features_mbconv0_batchnorm0_running_mean) /* ty=Tensor[(32), float32] */;
  %34 = multiply(%33, %30) /* ty=Tensor[(32), float32] */;
  %35 = add(%34, %efficientnet0_features_mbconv0_batchnorm0_beta) /* ty=Tensor[(32), float32] */;
  %36 = multiply(%31, %32) /* ty=Tensor[(1, 32, 112, 112), float32] */;
  %37 = expand_dims(%35, axis=1, num_newaxis=2) /* ty=Tensor[(32, 1, 1), float32] */;
  %38 = add(%efficientnet0_features_mbconv0_batchnorm0_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(32), float32] */;
  %39 = sqrt(%38) /* ty=Tensor[(32), float32] */;
  %40 = divide(1f /* ty=float32 */, %39) /* ty=Tensor[(32), float32] */;
  %41 = multiply(%40, %efficientnet0_features_mbconv0_batchnorm0_gamma) /* ty=Tensor[(32), float32] */;
  %42 = expand_dims(%41, axis=1, num_newaxis=2) /* ty=Tensor[(32, 1, 1), float32] */;
  %43 = negative(%efficientnet0_features_mbconv0_batchnorm0_running_mean) /* ty=Tensor[(32), float32] */;
  %44 = multiply(%43, %41) /* ty=Tensor[(32), float32] */;
  %45 = add(%44, %efficientnet0_features_mbconv0_batchnorm0_beta) /* ty=Tensor[(32), float32] */;
  %46 = multiply(%31, %42) /* ty=Tensor[(1, 32, 112, 112), float32] */;
  %47 = expand_dims(%45, axis=1, num_newaxis=2) /* ty=Tensor[(32, 1, 1), float32] */;
  %48 = add(%46, %47) /* ty=Tensor[(1, 32, 112, 112), float32] */;
  %49 = multiply(%48, 1f /* ty=float32 */) /* ty=Tensor[(1, 32, 112, 112), float32] */;
  %50 = add(%36, %37) /* ty=Tensor[(1, 32, 112, 112), float32] */;
  %51 = sigmoid(%49) /* ty=Tensor[(1, 32, 112, 112), float32] */;
  %52 = multiply(%50, %51) /* ty=Tensor[(1, 32, 112, 112), float32] */;
  %53 = nn.pad(%52, 0 /* ty=int32 */, pad_width=[[0, 0], [0, 0], [1, 1], [1, 1]]) /* ty=Tensor[(1, 32, 114, 114), float32] */;
  %54 = add(%efficientnet0_features_mbconv0_batchnorm1_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(32), float32] */;
  %55 = sqrt(%54) /* ty=Tensor[(32), float32] */;
  %56 = divide(1f /* ty=float32 */, %55) /* ty=Tensor[(32), float32] */;
  %57 = multiply(%56, %efficientnet0_features_mbconv0_batchnorm1_gamma) /* ty=Tensor[(32), float32] */;
  %58 = nn.conv2d(%53, %efficientnet0_features_mbconv0_conv1_weight, padding=[0, 0, 0, 0], groups=32, channels=32, kernel_size=[3, 3]) /* ty=Tensor[(1, 32, 112, 112), float32] */;
  %59 = expand_dims(%57, axis=1, num_newaxis=2) /* ty=Tensor[(32, 1, 1), float32] */;
  %60 = negative(%efficientnet0_features_mbconv0_batchnorm1_running_mean) /* ty=Tensor[(32), float32] */;
  %61 = multiply(%60, %57) /* ty=Tensor[(32), float32] */;
  %62 = add(%61, %efficientnet0_features_mbconv0_batchnorm1_beta) /* ty=Tensor[(32), float32] */;
  %63 = multiply(%58, %59) /* ty=Tensor[(1, 32, 112, 112), float32] */;
  %64 = expand_dims(%62, axis=1, num_newaxis=2) /* ty=Tensor[(32, 1, 1), float32] */;
  %65 = add(%efficientnet0_features_mbconv0_batchnorm1_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(32), float32] */;
  %66 = sqrt(%65) /* ty=Tensor[(32), float32] */;
  %67 = divide(1f /* ty=float32 */, %66) /* ty=Tensor[(32), float32] */;
  %68 = multiply(%67, %efficientnet0_features_mbconv0_batchnorm1_gamma) /* ty=Tensor[(32), float32] */;
  %69 = expand_dims(%68, axis=1, num_newaxis=2) /* ty=Tensor[(32, 1, 1), float32] */;
  %70 = negative(%efficientnet0_features_mbconv0_batchnorm1_running_mean) /* ty=Tensor[(32), float32] */;
  %71 = multiply(%70, %68) /* ty=Tensor[(32), float32] */;
  %72 = add(%71, %efficientnet0_features_mbconv0_batchnorm1_beta) /* ty=Tensor[(32), float32] */;
  %73 = multiply(%58, %69) /* ty=Tensor[(1, 32, 112, 112), float32] */;
  %74 = expand_dims(%72, axis=1, num_newaxis=2) /* ty=Tensor[(32, 1, 1), float32] */;
  %75 = add(%73, %74) /* ty=Tensor[(1, 32, 112, 112), float32] */;
  %76 = multiply(%75, 1f /* ty=float32 */) /* ty=Tensor[(1, 32, 112, 112), float32] */;
  %77 = add(%63, %64) /* ty=Tensor[(1, 32, 112, 112), float32] */;
  %78 = sigmoid(%76) /* ty=Tensor[(1, 32, 112, 112), float32] */;
  %79 = multiply(%77, %78) /* ty=Tensor[(1, 32, 112, 112), float32] */;
  %80 = add(%efficientnet0_features_mbconv0_batchnorm2_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(16), float32] */;
  %81 = sqrt(%80) /* ty=Tensor[(16), float32] */;
  %82 = divide(1f /* ty=float32 */, %81) /* ty=Tensor[(16), float32] */;
  %83 = multiply(%82, %efficientnet0_features_mbconv0_batchnorm2_gamma) /* ty=Tensor[(16), float32] */;
  %84 = nn.conv2d(%79, %efficientnet0_features_mbconv0_conv2_weight, padding=[0, 0, 0, 0], channels=16, kernel_size=[1, 1]) /* ty=Tensor[(1, 16, 112, 112), float32] */;
  %85 = expand_dims(%83, axis=1, num_newaxis=2) /* ty=Tensor[(16, 1, 1), float32] */;
  %86 = negative(%efficientnet0_features_mbconv0_batchnorm2_running_mean) /* ty=Tensor[(16), float32] */;
  %87 = multiply(%86, %83) /* ty=Tensor[(16), float32] */;
  %88 = add(%87, %efficientnet0_features_mbconv0_batchnorm2_beta) /* ty=Tensor[(16), float32] */;
  %89 = multiply(%84, %85) /* ty=Tensor[(1, 16, 112, 112), float32] */;
  %90 = expand_dims(%88, axis=1, num_newaxis=2) /* ty=Tensor[(16, 1, 1), float32] */;
  %91 = add(%89, %90) /* ty=Tensor[(1, 16, 112, 112), float32] */;
  %92 = add(%efficientnet0_features_mbconv1_batchnorm0_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(96), float32] */;
  %93 = sqrt(%92) /* ty=Tensor[(96), float32] */;
  %94 = divide(1f /* ty=float32 */, %93) /* ty=Tensor[(96), float32] */;
  %95 = multiply(%94, %efficientnet0_features_mbconv1_batchnorm0_gamma) /* ty=Tensor[(96), float32] */;
  %96 = nn.conv2d(%91, %efficientnet0_features_mbconv1_conv0_weight, padding=[0, 0, 0, 0], channels=96, kernel_size=[1, 1]) /* ty=Tensor[(1, 96, 112, 112), float32] */;
  %97 = expand_dims(%95, axis=1, num_newaxis=2) /* ty=Tensor[(96, 1, 1), float32] */;
  %98 = negative(%efficientnet0_features_mbconv1_batchnorm0_running_mean) /* ty=Tensor[(96), float32] */;
  %99 = multiply(%98, %95) /* ty=Tensor[(96), float32] */;
  %100 = add(%99, %efficientnet0_features_mbconv1_batchnorm0_beta) /* ty=Tensor[(96), float32] */;
  %101 = multiply(%96, %97) /* ty=Tensor[(1, 96, 112, 112), float32] */;
  %102 = expand_dims(%100, axis=1, num_newaxis=2) /* ty=Tensor[(96, 1, 1), float32] */;
  %103 = add(%efficientnet0_features_mbconv1_batchnorm0_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(96), float32] */;
  %104 = sqrt(%103) /* ty=Tensor[(96), float32] */;
  %105 = divide(1f /* ty=float32 */, %104) /* ty=Tensor[(96), float32] */;
  %106 = multiply(%105, %efficientnet0_features_mbconv1_batchnorm0_gamma) /* ty=Tensor[(96), float32] */;
  %107 = expand_dims(%106, axis=1, num_newaxis=2) /* ty=Tensor[(96, 1, 1), float32] */;
  %108 = negative(%efficientnet0_features_mbconv1_batchnorm0_running_mean) /* ty=Tensor[(96), float32] */;
  %109 = multiply(%108, %106) /* ty=Tensor[(96), float32] */;
  %110 = add(%109, %efficientnet0_features_mbconv1_batchnorm0_beta) /* ty=Tensor[(96), float32] */;
  %111 = multiply(%96, %107) /* ty=Tensor[(1, 96, 112, 112), float32] */;
  %112 = expand_dims(%110, axis=1, num_newaxis=2) /* ty=Tensor[(96, 1, 1), float32] */;
  %113 = add(%111, %112) /* ty=Tensor[(1, 96, 112, 112), float32] */;
  %114 = multiply(%113, 1f /* ty=float32 */) /* ty=Tensor[(1, 96, 112, 112), float32] */;
  %115 = add(%101, %102) /* ty=Tensor[(1, 96, 112, 112), float32] */;
  %116 = sigmoid(%114) /* ty=Tensor[(1, 96, 112, 112), float32] */;
  %117 = multiply(%115, %116) /* ty=Tensor[(1, 96, 112, 112), float32] */;
  %118 = nn.pad(%117, 0 /* ty=int32 */, pad_width=[[0, 0], [0, 0], [1, 1], [1, 1]]) /* ty=Tensor[(1, 96, 114, 114), float32] */;
  %119 = add(%efficientnet0_features_mbconv1_batchnorm1_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(96), float32] */;
  %120 = sqrt(%119) /* ty=Tensor[(96), float32] */;
  %121 = divide(1f /* ty=float32 */, %120) /* ty=Tensor[(96), float32] */;
  %122 = multiply(%121, %efficientnet0_features_mbconv1_batchnorm1_gamma) /* ty=Tensor[(96), float32] */;
  %123 = nn.conv2d(%118, %efficientnet0_features_mbconv1_conv1_weight, strides=[2, 2], padding=[0, 0, 0, 0], groups=96, channels=96, kernel_size=[3, 3]) /* ty=Tensor[(1, 96, 56, 56), float32] */;
  %124 = expand_dims(%122, axis=1, num_newaxis=2) /* ty=Tensor[(96, 1, 1), float32] */;
  %125 = negative(%efficientnet0_features_mbconv1_batchnorm1_running_mean) /* ty=Tensor[(96), float32] */;
  %126 = multiply(%125, %122) /* ty=Tensor[(96), float32] */;
  %127 = add(%126, %efficientnet0_features_mbconv1_batchnorm1_beta) /* ty=Tensor[(96), float32] */;
  %128 = multiply(%123, %124) /* ty=Tensor[(1, 96, 56, 56), float32] */;
  %129 = expand_dims(%127, axis=1, num_newaxis=2) /* ty=Tensor[(96, 1, 1), float32] */;
  %130 = add(%efficientnet0_features_mbconv1_batchnorm1_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(96), float32] */;
  %131 = sqrt(%130) /* ty=Tensor[(96), float32] */;
  %132 = divide(1f /* ty=float32 */, %131) /* ty=Tensor[(96), float32] */;
  %133 = multiply(%132, %efficientnet0_features_mbconv1_batchnorm1_gamma) /* ty=Tensor[(96), float32] */;
  %134 = expand_dims(%133, axis=1, num_newaxis=2) /* ty=Tensor[(96, 1, 1), float32] */;
  %135 = negative(%efficientnet0_features_mbconv1_batchnorm1_running_mean) /* ty=Tensor[(96), float32] */;
  %136 = multiply(%135, %133) /* ty=Tensor[(96), float32] */;
  %137 = add(%136, %efficientnet0_features_mbconv1_batchnorm1_beta) /* ty=Tensor[(96), float32] */;
  %138 = multiply(%123, %134) /* ty=Tensor[(1, 96, 56, 56), float32] */;
  %139 = expand_dims(%137, axis=1, num_newaxis=2) /* ty=Tensor[(96, 1, 1), float32] */;
  %140 = add(%138, %139) /* ty=Tensor[(1, 96, 56, 56), float32] */;
  %141 = multiply(%140, 1f /* ty=float32 */) /* ty=Tensor[(1, 96, 56, 56), float32] */;
  %142 = add(%128, %129) /* ty=Tensor[(1, 96, 56, 56), float32] */;
  %143 = sigmoid(%141) /* ty=Tensor[(1, 96, 56, 56), float32] */;
  %144 = multiply(%142, %143) /* ty=Tensor[(1, 96, 56, 56), float32] */;
  %145 = add(%efficientnet0_features_mbconv1_batchnorm2_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(24), float32] */;
  %146 = sqrt(%145) /* ty=Tensor[(24), float32] */;
  %147 = divide(1f /* ty=float32 */, %146) /* ty=Tensor[(24), float32] */;
  %148 = multiply(%147, %efficientnet0_features_mbconv1_batchnorm2_gamma) /* ty=Tensor[(24), float32] */;
  %149 = nn.conv2d(%144, %efficientnet0_features_mbconv1_conv2_weight, padding=[0, 0, 0, 0], channels=24, kernel_size=[1, 1]) /* ty=Tensor[(1, 24, 56, 56), float32] */;
  %150 = expand_dims(%148, axis=1, num_newaxis=2) /* ty=Tensor[(24, 1, 1), float32] */;
  %151 = negative(%efficientnet0_features_mbconv1_batchnorm2_running_mean) /* ty=Tensor[(24), float32] */;
  %152 = multiply(%151, %148) /* ty=Tensor[(24), float32] */;
  %153 = add(%152, %efficientnet0_features_mbconv1_batchnorm2_beta) /* ty=Tensor[(24), float32] */;
  %154 = multiply(%149, %150) /* ty=Tensor[(1, 24, 56, 56), float32] */;
  %155 = expand_dims(%153, axis=1, num_newaxis=2) /* ty=Tensor[(24, 1, 1), float32] */;
  %156 = add(%154, %155) /* ty=Tensor[(1, 24, 56, 56), float32] */;
  %157 = add(%efficientnet0_features_mbconv2_batchnorm0_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(144), float32] */;
  %158 = sqrt(%157) /* ty=Tensor[(144), float32] */;
  %159 = divide(1f /* ty=float32 */, %158) /* ty=Tensor[(144), float32] */;
  %160 = multiply(%159, %efficientnet0_features_mbconv2_batchnorm0_gamma) /* ty=Tensor[(144), float32] */;
  %161 = nn.conv2d(%156, %efficientnet0_features_mbconv2_conv0_weight, padding=[0, 0, 0, 0], channels=144, kernel_size=[1, 1]) /* ty=Tensor[(1, 144, 56, 56), float32] */;
  %162 = expand_dims(%160, axis=1, num_newaxis=2) /* ty=Tensor[(144, 1, 1), float32] */;
  %163 = negative(%efficientnet0_features_mbconv2_batchnorm0_running_mean) /* ty=Tensor[(144), float32] */;
  %164 = multiply(%163, %160) /* ty=Tensor[(144), float32] */;
  %165 = add(%164, %efficientnet0_features_mbconv2_batchnorm0_beta) /* ty=Tensor[(144), float32] */;
  %166 = multiply(%161, %162) /* ty=Tensor[(1, 144, 56, 56), float32] */;
  %167 = expand_dims(%165, axis=1, num_newaxis=2) /* ty=Tensor[(144, 1, 1), float32] */;
  %168 = add(%efficientnet0_features_mbconv2_batchnorm0_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(144), float32] */;
  %169 = sqrt(%168) /* ty=Tensor[(144), float32] */;
  %170 = divide(1f /* ty=float32 */, %169) /* ty=Tensor[(144), float32] */;
  %171 = multiply(%170, %efficientnet0_features_mbconv2_batchnorm0_gamma) /* ty=Tensor[(144), float32] */;
  %172 = expand_dims(%171, axis=1, num_newaxis=2) /* ty=Tensor[(144, 1, 1), float32] */;
  %173 = negative(%efficientnet0_features_mbconv2_batchnorm0_running_mean) /* ty=Tensor[(144), float32] */;
  %174 = multiply(%173, %171) /* ty=Tensor[(144), float32] */;
  %175 = add(%174, %efficientnet0_features_mbconv2_batchnorm0_beta) /* ty=Tensor[(144), float32] */;
  %176 = multiply(%161, %172) /* ty=Tensor[(1, 144, 56, 56), float32] */;
  %177 = expand_dims(%175, axis=1, num_newaxis=2) /* ty=Tensor[(144, 1, 1), float32] */;
  %178 = add(%176, %177) /* ty=Tensor[(1, 144, 56, 56), float32] */;
  %179 = multiply(%178, 1f /* ty=float32 */) /* ty=Tensor[(1, 144, 56, 56), float32] */;
  %180 = add(%166, %167) /* ty=Tensor[(1, 144, 56, 56), float32] */;
  %181 = sigmoid(%179) /* ty=Tensor[(1, 144, 56, 56), float32] */;
  %182 = multiply(%180, %181) /* ty=Tensor[(1, 144, 56, 56), float32] */;
  %183 = nn.pad(%182, 0 /* ty=int32 */, pad_width=[[0, 0], [0, 0], [1, 1], [1, 1]]) /* ty=Tensor[(1, 144, 58, 58), float32] */;
  %184 = add(%efficientnet0_features_mbconv2_batchnorm1_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(144), float32] */;
  %185 = sqrt(%184) /* ty=Tensor[(144), float32] */;
  %186 = divide(1f /* ty=float32 */, %185) /* ty=Tensor[(144), float32] */;
  %187 = multiply(%186, %efficientnet0_features_mbconv2_batchnorm1_gamma) /* ty=Tensor[(144), float32] */;
  %188 = nn.conv2d(%183, %efficientnet0_features_mbconv2_conv1_weight, padding=[0, 0, 0, 0], groups=144, channels=144, kernel_size=[3, 3]) /* ty=Tensor[(1, 144, 56, 56), float32] */;
  %189 = expand_dims(%187, axis=1, num_newaxis=2) /* ty=Tensor[(144, 1, 1), float32] */;
  %190 = negative(%efficientnet0_features_mbconv2_batchnorm1_running_mean) /* ty=Tensor[(144), float32] */;
  %191 = multiply(%190, %187) /* ty=Tensor[(144), float32] */;
  %192 = add(%191, %efficientnet0_features_mbconv2_batchnorm1_beta) /* ty=Tensor[(144), float32] */;
  %193 = multiply(%188, %189) /* ty=Tensor[(1, 144, 56, 56), float32] */;
  %194 = expand_dims(%192, axis=1, num_newaxis=2) /* ty=Tensor[(144, 1, 1), float32] */;
  %195 = add(%efficientnet0_features_mbconv2_batchnorm1_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(144), float32] */;
  %196 = sqrt(%195) /* ty=Tensor[(144), float32] */;
  %197 = divide(1f /* ty=float32 */, %196) /* ty=Tensor[(144), float32] */;
  %198 = multiply(%197, %efficientnet0_features_mbconv2_batchnorm1_gamma) /* ty=Tensor[(144), float32] */;
  %199 = expand_dims(%198, axis=1, num_newaxis=2) /* ty=Tensor[(144, 1, 1), float32] */;
  %200 = negative(%efficientnet0_features_mbconv2_batchnorm1_running_mean) /* ty=Tensor[(144), float32] */;
  %201 = multiply(%200, %198) /* ty=Tensor[(144), float32] */;
  %202 = add(%201, %efficientnet0_features_mbconv2_batchnorm1_beta) /* ty=Tensor[(144), float32] */;
  %203 = multiply(%188, %199) /* ty=Tensor[(1, 144, 56, 56), float32] */;
  %204 = expand_dims(%202, axis=1, num_newaxis=2) /* ty=Tensor[(144, 1, 1), float32] */;
  %205 = add(%203, %204) /* ty=Tensor[(1, 144, 56, 56), float32] */;
  %206 = multiply(%205, 1f /* ty=float32 */) /* ty=Tensor[(1, 144, 56, 56), float32] */;
  %207 = add(%193, %194) /* ty=Tensor[(1, 144, 56, 56), float32] */;
  %208 = sigmoid(%206) /* ty=Tensor[(1, 144, 56, 56), float32] */;
  %209 = multiply(%207, %208) /* ty=Tensor[(1, 144, 56, 56), float32] */;
  %210 = add(%efficientnet0_features_mbconv2_batchnorm2_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(24), float32] */;
  %211 = sqrt(%210) /* ty=Tensor[(24), float32] */;
  %212 = divide(1f /* ty=float32 */, %211) /* ty=Tensor[(24), float32] */;
  %213 = multiply(%212, %efficientnet0_features_mbconv2_batchnorm2_gamma) /* ty=Tensor[(24), float32] */;
  %214 = nn.conv2d(%209, %efficientnet0_features_mbconv2_conv2_weight, padding=[0, 0, 0, 0], channels=24, kernel_size=[1, 1]) /* ty=Tensor[(1, 24, 56, 56), float32] */;
  %215 = expand_dims(%213, axis=1, num_newaxis=2) /* ty=Tensor[(24, 1, 1), float32] */;
  %216 = negative(%efficientnet0_features_mbconv2_batchnorm2_running_mean) /* ty=Tensor[(24), float32] */;
  %217 = multiply(%216, %213) /* ty=Tensor[(24), float32] */;
  %218 = add(%217, %efficientnet0_features_mbconv2_batchnorm2_beta) /* ty=Tensor[(24), float32] */;
  %219 = multiply(%214, %215) /* ty=Tensor[(1, 24, 56, 56), float32] */;
  %220 = expand_dims(%218, axis=1, num_newaxis=2) /* ty=Tensor[(24, 1, 1), float32] */;
  %221 = add(%efficientnet0_features_mbconv1_batchnorm2_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(24), float32] */;
  %222 = sqrt(%221) /* ty=Tensor[(24), float32] */;
  %223 = divide(1f /* ty=float32 */, %222) /* ty=Tensor[(24), float32] */;
  %224 = multiply(%223, %efficientnet0_features_mbconv1_batchnorm2_gamma) /* ty=Tensor[(24), float32] */;
  %225 = expand_dims(%224, axis=1, num_newaxis=2) /* ty=Tensor[(24, 1, 1), float32] */;
  %226 = negative(%efficientnet0_features_mbconv1_batchnorm2_running_mean) /* ty=Tensor[(24), float32] */;
  %227 = multiply(%226, %224) /* ty=Tensor[(24), float32] */;
  %228 = add(%227, %efficientnet0_features_mbconv1_batchnorm2_beta) /* ty=Tensor[(24), float32] */;
  %229 = multiply(%149, %225) /* ty=Tensor[(1, 24, 56, 56), float32] */;
  %230 = expand_dims(%228, axis=1, num_newaxis=2) /* ty=Tensor[(24, 1, 1), float32] */;
  %231 = add(%219, %220) /* ty=Tensor[(1, 24, 56, 56), float32] */;
  %232 = add(%229, %230) /* ty=Tensor[(1, 24, 56, 56), float32] */;
  %233 = add(%231, %232) /* ty=Tensor[(1, 24, 56, 56), float32] */;
  %234 = add(%efficientnet0_features_mbconv3_batchnorm0_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(144), float32] */;
  %235 = sqrt(%234) /* ty=Tensor[(144), float32] */;
  %236 = divide(1f /* ty=float32 */, %235) /* ty=Tensor[(144), float32] */;
  %237 = multiply(%236, %efficientnet0_features_mbconv3_batchnorm0_gamma) /* ty=Tensor[(144), float32] */;
  %238 = nn.conv2d(%233, %efficientnet0_features_mbconv3_conv0_weight, padding=[0, 0, 0, 0], channels=144, kernel_size=[1, 1]) /* ty=Tensor[(1, 144, 56, 56), float32] */;
  %239 = expand_dims(%237, axis=1, num_newaxis=2) /* ty=Tensor[(144, 1, 1), float32] */;
  %240 = negative(%efficientnet0_features_mbconv3_batchnorm0_running_mean) /* ty=Tensor[(144), float32] */;
  %241 = multiply(%240, %237) /* ty=Tensor[(144), float32] */;
  %242 = add(%241, %efficientnet0_features_mbconv3_batchnorm0_beta) /* ty=Tensor[(144), float32] */;
  %243 = multiply(%238, %239) /* ty=Tensor[(1, 144, 56, 56), float32] */;
  %244 = expand_dims(%242, axis=1, num_newaxis=2) /* ty=Tensor[(144, 1, 1), float32] */;
  %245 = add(%efficientnet0_features_mbconv3_batchnorm0_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(144), float32] */;
  %246 = sqrt(%245) /* ty=Tensor[(144), float32] */;
  %247 = divide(1f /* ty=float32 */, %246) /* ty=Tensor[(144), float32] */;
  %248 = multiply(%247, %efficientnet0_features_mbconv3_batchnorm0_gamma) /* ty=Tensor[(144), float32] */;
  %249 = expand_dims(%248, axis=1, num_newaxis=2) /* ty=Tensor[(144, 1, 1), float32] */;
  %250 = negative(%efficientnet0_features_mbconv3_batchnorm0_running_mean) /* ty=Tensor[(144), float32] */;
  %251 = multiply(%250, %248) /* ty=Tensor[(144), float32] */;
  %252 = add(%251, %efficientnet0_features_mbconv3_batchnorm0_beta) /* ty=Tensor[(144), float32] */;
  %253 = multiply(%238, %249) /* ty=Tensor[(1, 144, 56, 56), float32] */;
  %254 = expand_dims(%252, axis=1, num_newaxis=2) /* ty=Tensor[(144, 1, 1), float32] */;
  %255 = add(%253, %254) /* ty=Tensor[(1, 144, 56, 56), float32] */;
  %256 = multiply(%255, 1f /* ty=float32 */) /* ty=Tensor[(1, 144, 56, 56), float32] */;
  %257 = add(%243, %244) /* ty=Tensor[(1, 144, 56, 56), float32] */;
  %258 = sigmoid(%256) /* ty=Tensor[(1, 144, 56, 56), float32] */;
  %259 = multiply(%257, %258) /* ty=Tensor[(1, 144, 56, 56), float32] */;
  %260 = nn.pad(%259, 0 /* ty=int32 */, pad_width=[[0, 0], [0, 0], [2, 2], [2, 2]]) /* ty=Tensor[(1, 144, 60, 60), float32] */;
  %261 = add(%efficientnet0_features_mbconv3_batchnorm1_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(144), float32] */;
  %262 = sqrt(%261) /* ty=Tensor[(144), float32] */;
  %263 = divide(1f /* ty=float32 */, %262) /* ty=Tensor[(144), float32] */;
  %264 = multiply(%263, %efficientnet0_features_mbconv3_batchnorm1_gamma) /* ty=Tensor[(144), float32] */;
  %265 = nn.conv2d(%260, %efficientnet0_features_mbconv3_conv1_weight, strides=[2, 2], padding=[0, 0, 0, 0], groups=144, channels=144, kernel_size=[5, 5]) /* ty=Tensor[(1, 144, 28, 28), float32] */;
  %266 = expand_dims(%264, axis=1, num_newaxis=2) /* ty=Tensor[(144, 1, 1), float32] */;
  %267 = negative(%efficientnet0_features_mbconv3_batchnorm1_running_mean) /* ty=Tensor[(144), float32] */;
  %268 = multiply(%267, %264) /* ty=Tensor[(144), float32] */;
  %269 = add(%268, %efficientnet0_features_mbconv3_batchnorm1_beta) /* ty=Tensor[(144), float32] */;
  %270 = multiply(%265, %266) /* ty=Tensor[(1, 144, 28, 28), float32] */;
  %271 = expand_dims(%269, axis=1, num_newaxis=2) /* ty=Tensor[(144, 1, 1), float32] */;
  %272 = add(%efficientnet0_features_mbconv3_batchnorm1_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(144), float32] */;
  %273 = sqrt(%272) /* ty=Tensor[(144), float32] */;
  %274 = divide(1f /* ty=float32 */, %273) /* ty=Tensor[(144), float32] */;
  %275 = multiply(%274, %efficientnet0_features_mbconv3_batchnorm1_gamma) /* ty=Tensor[(144), float32] */;
  %276 = expand_dims(%275, axis=1, num_newaxis=2) /* ty=Tensor[(144, 1, 1), float32] */;
  %277 = negative(%efficientnet0_features_mbconv3_batchnorm1_running_mean) /* ty=Tensor[(144), float32] */;
  %278 = multiply(%277, %275) /* ty=Tensor[(144), float32] */;
  %279 = add(%278, %efficientnet0_features_mbconv3_batchnorm1_beta) /* ty=Tensor[(144), float32] */;
  %280 = multiply(%265, %276) /* ty=Tensor[(1, 144, 28, 28), float32] */;
  %281 = expand_dims(%279, axis=1, num_newaxis=2) /* ty=Tensor[(144, 1, 1), float32] */;
  %282 = add(%280, %281) /* ty=Tensor[(1, 144, 28, 28), float32] */;
  %283 = multiply(%282, 1f /* ty=float32 */) /* ty=Tensor[(1, 144, 28, 28), float32] */;
  %284 = add(%270, %271) /* ty=Tensor[(1, 144, 28, 28), float32] */;
  %285 = sigmoid(%283) /* ty=Tensor[(1, 144, 28, 28), float32] */;
  %286 = multiply(%284, %285) /* ty=Tensor[(1, 144, 28, 28), float32] */;
  %287 = add(%efficientnet0_features_mbconv3_batchnorm2_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(40), float32] */;
  %288 = sqrt(%287) /* ty=Tensor[(40), float32] */;
  %289 = divide(1f /* ty=float32 */, %288) /* ty=Tensor[(40), float32] */;
  %290 = multiply(%289, %efficientnet0_features_mbconv3_batchnorm2_gamma) /* ty=Tensor[(40), float32] */;
  %291 = nn.conv2d(%286, %efficientnet0_features_mbconv3_conv2_weight, padding=[0, 0, 0, 0], channels=40, kernel_size=[1, 1]) /* ty=Tensor[(1, 40, 28, 28), float32] */;
  %292 = expand_dims(%290, axis=1, num_newaxis=2) /* ty=Tensor[(40, 1, 1), float32] */;
  %293 = negative(%efficientnet0_features_mbconv3_batchnorm2_running_mean) /* ty=Tensor[(40), float32] */;
  %294 = multiply(%293, %290) /* ty=Tensor[(40), float32] */;
  %295 = add(%294, %efficientnet0_features_mbconv3_batchnorm2_beta) /* ty=Tensor[(40), float32] */;
  %296 = multiply(%291, %292) /* ty=Tensor[(1, 40, 28, 28), float32] */;
  %297 = expand_dims(%295, axis=1, num_newaxis=2) /* ty=Tensor[(40, 1, 1), float32] */;
  %298 = add(%296, %297) /* ty=Tensor[(1, 40, 28, 28), float32] */;
  %299 = add(%efficientnet0_features_mbconv4_batchnorm0_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(240), float32] */;
  %300 = sqrt(%299) /* ty=Tensor[(240), float32] */;
  %301 = divide(1f /* ty=float32 */, %300) /* ty=Tensor[(240), float32] */;
  %302 = multiply(%301, %efficientnet0_features_mbconv4_batchnorm0_gamma) /* ty=Tensor[(240), float32] */;
  %303 = nn.conv2d(%298, %efficientnet0_features_mbconv4_conv0_weight, padding=[0, 0, 0, 0], channels=240, kernel_size=[1, 1]) /* ty=Tensor[(1, 240, 28, 28), float32] */;
  %304 = expand_dims(%302, axis=1, num_newaxis=2) /* ty=Tensor[(240, 1, 1), float32] */;
  %305 = negative(%efficientnet0_features_mbconv4_batchnorm0_running_mean) /* ty=Tensor[(240), float32] */;
  %306 = multiply(%305, %302) /* ty=Tensor[(240), float32] */;
  %307 = add(%306, %efficientnet0_features_mbconv4_batchnorm0_beta) /* ty=Tensor[(240), float32] */;
  %308 = multiply(%303, %304) /* ty=Tensor[(1, 240, 28, 28), float32] */;
  %309 = expand_dims(%307, axis=1, num_newaxis=2) /* ty=Tensor[(240, 1, 1), float32] */;
  %310 = add(%efficientnet0_features_mbconv4_batchnorm0_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(240), float32] */;
  %311 = sqrt(%310) /* ty=Tensor[(240), float32] */;
  %312 = divide(1f /* ty=float32 */, %311) /* ty=Tensor[(240), float32] */;
  %313 = multiply(%312, %efficientnet0_features_mbconv4_batchnorm0_gamma) /* ty=Tensor[(240), float32] */;
  %314 = expand_dims(%313, axis=1, num_newaxis=2) /* ty=Tensor[(240, 1, 1), float32] */;
  %315 = negative(%efficientnet0_features_mbconv4_batchnorm0_running_mean) /* ty=Tensor[(240), float32] */;
  %316 = multiply(%315, %313) /* ty=Tensor[(240), float32] */;
  %317 = add(%316, %efficientnet0_features_mbconv4_batchnorm0_beta) /* ty=Tensor[(240), float32] */;
  %318 = multiply(%303, %314) /* ty=Tensor[(1, 240, 28, 28), float32] */;
  %319 = expand_dims(%317, axis=1, num_newaxis=2) /* ty=Tensor[(240, 1, 1), float32] */;
  %320 = add(%318, %319) /* ty=Tensor[(1, 240, 28, 28), float32] */;
  %321 = multiply(%320, 1f /* ty=float32 */) /* ty=Tensor[(1, 240, 28, 28), float32] */;
  %322 = add(%308, %309) /* ty=Tensor[(1, 240, 28, 28), float32] */;
  %323 = sigmoid(%321) /* ty=Tensor[(1, 240, 28, 28), float32] */;
  %324 = multiply(%322, %323) /* ty=Tensor[(1, 240, 28, 28), float32] */;
  %325 = nn.pad(%324, 0 /* ty=int32 */, pad_width=[[0, 0], [0, 0], [2, 2], [2, 2]]) /* ty=Tensor[(1, 240, 32, 32), float32] */;
  %326 = add(%efficientnet0_features_mbconv4_batchnorm1_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(240), float32] */;
  %327 = sqrt(%326) /* ty=Tensor[(240), float32] */;
  %328 = divide(1f /* ty=float32 */, %327) /* ty=Tensor[(240), float32] */;
  %329 = multiply(%328, %efficientnet0_features_mbconv4_batchnorm1_gamma) /* ty=Tensor[(240), float32] */;
  %330 = nn.conv2d(%325, %efficientnet0_features_mbconv4_conv1_weight, padding=[0, 0, 0, 0], groups=240, channels=240, kernel_size=[5, 5]) /* ty=Tensor[(1, 240, 28, 28), float32] */;
  %331 = expand_dims(%329, axis=1, num_newaxis=2) /* ty=Tensor[(240, 1, 1), float32] */;
  %332 = negative(%efficientnet0_features_mbconv4_batchnorm1_running_mean) /* ty=Tensor[(240), float32] */;
  %333 = multiply(%332, %329) /* ty=Tensor[(240), float32] */;
  %334 = add(%333, %efficientnet0_features_mbconv4_batchnorm1_beta) /* ty=Tensor[(240), float32] */;
  %335 = multiply(%330, %331) /* ty=Tensor[(1, 240, 28, 28), float32] */;
  %336 = expand_dims(%334, axis=1, num_newaxis=2) /* ty=Tensor[(240, 1, 1), float32] */;
  %337 = add(%efficientnet0_features_mbconv4_batchnorm1_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(240), float32] */;
  %338 = sqrt(%337) /* ty=Tensor[(240), float32] */;
  %339 = divide(1f /* ty=float32 */, %338) /* ty=Tensor[(240), float32] */;
  %340 = multiply(%339, %efficientnet0_features_mbconv4_batchnorm1_gamma) /* ty=Tensor[(240), float32] */;
  %341 = expand_dims(%340, axis=1, num_newaxis=2) /* ty=Tensor[(240, 1, 1), float32] */;
  %342 = negative(%efficientnet0_features_mbconv4_batchnorm1_running_mean) /* ty=Tensor[(240), float32] */;
  %343 = multiply(%342, %340) /* ty=Tensor[(240), float32] */;
  %344 = add(%343, %efficientnet0_features_mbconv4_batchnorm1_beta) /* ty=Tensor[(240), float32] */;
  %345 = multiply(%330, %341) /* ty=Tensor[(1, 240, 28, 28), float32] */;
  %346 = expand_dims(%344, axis=1, num_newaxis=2) /* ty=Tensor[(240, 1, 1), float32] */;
  %347 = add(%345, %346) /* ty=Tensor[(1, 240, 28, 28), float32] */;
  %348 = multiply(%347, 1f /* ty=float32 */) /* ty=Tensor[(1, 240, 28, 28), float32] */;
  %349 = add(%335, %336) /* ty=Tensor[(1, 240, 28, 28), float32] */;
  %350 = sigmoid(%348) /* ty=Tensor[(1, 240, 28, 28), float32] */;
  %351 = multiply(%349, %350) /* ty=Tensor[(1, 240, 28, 28), float32] */;
  %352 = add(%efficientnet0_features_mbconv4_batchnorm2_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(40), float32] */;
  %353 = sqrt(%352) /* ty=Tensor[(40), float32] */;
  %354 = divide(1f /* ty=float32 */, %353) /* ty=Tensor[(40), float32] */;
  %355 = multiply(%354, %efficientnet0_features_mbconv4_batchnorm2_gamma) /* ty=Tensor[(40), float32] */;
  %356 = nn.conv2d(%351, %efficientnet0_features_mbconv4_conv2_weight, padding=[0, 0, 0, 0], channels=40, kernel_size=[1, 1]) /* ty=Tensor[(1, 40, 28, 28), float32] */;
  %357 = expand_dims(%355, axis=1, num_newaxis=2) /* ty=Tensor[(40, 1, 1), float32] */;
  %358 = negative(%efficientnet0_features_mbconv4_batchnorm2_running_mean) /* ty=Tensor[(40), float32] */;
  %359 = multiply(%358, %355) /* ty=Tensor[(40), float32] */;
  %360 = add(%359, %efficientnet0_features_mbconv4_batchnorm2_beta) /* ty=Tensor[(40), float32] */;
  %361 = multiply(%356, %357) /* ty=Tensor[(1, 40, 28, 28), float32] */;
  %362 = expand_dims(%360, axis=1, num_newaxis=2) /* ty=Tensor[(40, 1, 1), float32] */;
  %363 = add(%efficientnet0_features_mbconv3_batchnorm2_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(40), float32] */;
  %364 = sqrt(%363) /* ty=Tensor[(40), float32] */;
  %365 = divide(1f /* ty=float32 */, %364) /* ty=Tensor[(40), float32] */;
  %366 = multiply(%365, %efficientnet0_features_mbconv3_batchnorm2_gamma) /* ty=Tensor[(40), float32] */;
  %367 = expand_dims(%366, axis=1, num_newaxis=2) /* ty=Tensor[(40, 1, 1), float32] */;
  %368 = negative(%efficientnet0_features_mbconv3_batchnorm2_running_mean) /* ty=Tensor[(40), float32] */;
  %369 = multiply(%368, %366) /* ty=Tensor[(40), float32] */;
  %370 = add(%369, %efficientnet0_features_mbconv3_batchnorm2_beta) /* ty=Tensor[(40), float32] */;
  %371 = multiply(%291, %367) /* ty=Tensor[(1, 40, 28, 28), float32] */;
  %372 = expand_dims(%370, axis=1, num_newaxis=2) /* ty=Tensor[(40, 1, 1), float32] */;
  %373 = add(%361, %362) /* ty=Tensor[(1, 40, 28, 28), float32] */;
  %374 = add(%371, %372) /* ty=Tensor[(1, 40, 28, 28), float32] */;
  %375 = add(%373, %374) /* ty=Tensor[(1, 40, 28, 28), float32] */;
  %376 = add(%efficientnet0_features_mbconv5_batchnorm0_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(240), float32] */;
  %377 = sqrt(%376) /* ty=Tensor[(240), float32] */;
  %378 = divide(1f /* ty=float32 */, %377) /* ty=Tensor[(240), float32] */;
  %379 = multiply(%378, %efficientnet0_features_mbconv5_batchnorm0_gamma) /* ty=Tensor[(240), float32] */;
  %380 = nn.conv2d(%375, %efficientnet0_features_mbconv5_conv0_weight, padding=[0, 0, 0, 0], channels=240, kernel_size=[1, 1]) /* ty=Tensor[(1, 240, 28, 28), float32] */;
  %381 = expand_dims(%379, axis=1, num_newaxis=2) /* ty=Tensor[(240, 1, 1), float32] */;
  %382 = negative(%efficientnet0_features_mbconv5_batchnorm0_running_mean) /* ty=Tensor[(240), float32] */;
  %383 = multiply(%382, %379) /* ty=Tensor[(240), float32] */;
  %384 = add(%383, %efficientnet0_features_mbconv5_batchnorm0_beta) /* ty=Tensor[(240), float32] */;
  %385 = multiply(%380, %381) /* ty=Tensor[(1, 240, 28, 28), float32] */;
  %386 = expand_dims(%384, axis=1, num_newaxis=2) /* ty=Tensor[(240, 1, 1), float32] */;
  %387 = add(%efficientnet0_features_mbconv5_batchnorm0_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(240), float32] */;
  %388 = sqrt(%387) /* ty=Tensor[(240), float32] */;
  %389 = divide(1f /* ty=float32 */, %388) /* ty=Tensor[(240), float32] */;
  %390 = multiply(%389, %efficientnet0_features_mbconv5_batchnorm0_gamma) /* ty=Tensor[(240), float32] */;
  %391 = expand_dims(%390, axis=1, num_newaxis=2) /* ty=Tensor[(240, 1, 1), float32] */;
  %392 = negative(%efficientnet0_features_mbconv5_batchnorm0_running_mean) /* ty=Tensor[(240), float32] */;
  %393 = multiply(%392, %390) /* ty=Tensor[(240), float32] */;
  %394 = add(%393, %efficientnet0_features_mbconv5_batchnorm0_beta) /* ty=Tensor[(240), float32] */;
  %395 = multiply(%380, %391) /* ty=Tensor[(1, 240, 28, 28), float32] */;
  %396 = expand_dims(%394, axis=1, num_newaxis=2) /* ty=Tensor[(240, 1, 1), float32] */;
  %397 = add(%395, %396) /* ty=Tensor[(1, 240, 28, 28), float32] */;
  %398 = multiply(%397, 1f /* ty=float32 */) /* ty=Tensor[(1, 240, 28, 28), float32] */;
  %399 = add(%385, %386) /* ty=Tensor[(1, 240, 28, 28), float32] */;
  %400 = sigmoid(%398) /* ty=Tensor[(1, 240, 28, 28), float32] */;
  %401 = multiply(%399, %400) /* ty=Tensor[(1, 240, 28, 28), float32] */;
  %402 = nn.pad(%401, 0 /* ty=int32 */, pad_width=[[0, 0], [0, 0], [1, 1], [1, 1]]) /* ty=Tensor[(1, 240, 30, 30), float32] */;
  %403 = add(%efficientnet0_features_mbconv5_batchnorm1_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(240), float32] */;
  %404 = sqrt(%403) /* ty=Tensor[(240), float32] */;
  %405 = divide(1f /* ty=float32 */, %404) /* ty=Tensor[(240), float32] */;
  %406 = multiply(%405, %efficientnet0_features_mbconv5_batchnorm1_gamma) /* ty=Tensor[(240), float32] */;
  %407 = nn.conv2d(%402, %efficientnet0_features_mbconv5_conv1_weight, padding=[0, 0, 0, 0], groups=240, channels=240, kernel_size=[3, 3]) /* ty=Tensor[(1, 240, 28, 28), float32] */;
  %408 = expand_dims(%406, axis=1, num_newaxis=2) /* ty=Tensor[(240, 1, 1), float32] */;
  %409 = negative(%efficientnet0_features_mbconv5_batchnorm1_running_mean) /* ty=Tensor[(240), float32] */;
  %410 = multiply(%409, %406) /* ty=Tensor[(240), float32] */;
  %411 = add(%410, %efficientnet0_features_mbconv5_batchnorm1_beta) /* ty=Tensor[(240), float32] */;
  %412 = multiply(%407, %408) /* ty=Tensor[(1, 240, 28, 28), float32] */;
  %413 = expand_dims(%411, axis=1, num_newaxis=2) /* ty=Tensor[(240, 1, 1), float32] */;
  %414 = add(%efficientnet0_features_mbconv5_batchnorm1_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(240), float32] */;
  %415 = sqrt(%414) /* ty=Tensor[(240), float32] */;
  %416 = divide(1f /* ty=float32 */, %415) /* ty=Tensor[(240), float32] */;
  %417 = multiply(%416, %efficientnet0_features_mbconv5_batchnorm1_gamma) /* ty=Tensor[(240), float32] */;
  %418 = expand_dims(%417, axis=1, num_newaxis=2) /* ty=Tensor[(240, 1, 1), float32] */;
  %419 = negative(%efficientnet0_features_mbconv5_batchnorm1_running_mean) /* ty=Tensor[(240), float32] */;
  %420 = multiply(%419, %417) /* ty=Tensor[(240), float32] */;
  %421 = add(%420, %efficientnet0_features_mbconv5_batchnorm1_beta) /* ty=Tensor[(240), float32] */;
  %422 = multiply(%407, %418) /* ty=Tensor[(1, 240, 28, 28), float32] */;
  %423 = expand_dims(%421, axis=1, num_newaxis=2) /* ty=Tensor[(240, 1, 1), float32] */;
  %424 = add(%422, %423) /* ty=Tensor[(1, 240, 28, 28), float32] */;
  %425 = multiply(%424, 1f /* ty=float32 */) /* ty=Tensor[(1, 240, 28, 28), float32] */;
  %426 = add(%412, %413) /* ty=Tensor[(1, 240, 28, 28), float32] */;
  %427 = sigmoid(%425) /* ty=Tensor[(1, 240, 28, 28), float32] */;
  %428 = multiply(%426, %427) /* ty=Tensor[(1, 240, 28, 28), float32] */;
  %429 = add(%efficientnet0_features_mbconv5_batchnorm2_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(80), float32] */;
  %430 = sqrt(%429) /* ty=Tensor[(80), float32] */;
  %431 = divide(1f /* ty=float32 */, %430) /* ty=Tensor[(80), float32] */;
  %432 = multiply(%431, %efficientnet0_features_mbconv5_batchnorm2_gamma) /* ty=Tensor[(80), float32] */;
  %433 = nn.conv2d(%428, %efficientnet0_features_mbconv5_conv2_weight, padding=[0, 0, 0, 0], channels=80, kernel_size=[1, 1]) /* ty=Tensor[(1, 80, 28, 28), float32] */;
  %434 = expand_dims(%432, axis=1, num_newaxis=2) /* ty=Tensor[(80, 1, 1), float32] */;
  %435 = negative(%efficientnet0_features_mbconv5_batchnorm2_running_mean) /* ty=Tensor[(80), float32] */;
  %436 = multiply(%435, %432) /* ty=Tensor[(80), float32] */;
  %437 = add(%436, %efficientnet0_features_mbconv5_batchnorm2_beta) /* ty=Tensor[(80), float32] */;
  %438 = multiply(%433, %434) /* ty=Tensor[(1, 80, 28, 28), float32] */;
  %439 = expand_dims(%437, axis=1, num_newaxis=2) /* ty=Tensor[(80, 1, 1), float32] */;
  %440 = add(%438, %439) /* ty=Tensor[(1, 80, 28, 28), float32] */;
  %441 = add(%efficientnet0_features_mbconv6_batchnorm0_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(480), float32] */;
  %442 = sqrt(%441) /* ty=Tensor[(480), float32] */;
  %443 = divide(1f /* ty=float32 */, %442) /* ty=Tensor[(480), float32] */;
  %444 = multiply(%443, %efficientnet0_features_mbconv6_batchnorm0_gamma) /* ty=Tensor[(480), float32] */;
  %445 = nn.conv2d(%440, %efficientnet0_features_mbconv6_conv0_weight, padding=[0, 0, 0, 0], channels=480, kernel_size=[1, 1]) /* ty=Tensor[(1, 480, 28, 28), float32] */;
  %446 = expand_dims(%444, axis=1, num_newaxis=2) /* ty=Tensor[(480, 1, 1), float32] */;
  %447 = negative(%efficientnet0_features_mbconv6_batchnorm0_running_mean) /* ty=Tensor[(480), float32] */;
  %448 = multiply(%447, %444) /* ty=Tensor[(480), float32] */;
  %449 = add(%448, %efficientnet0_features_mbconv6_batchnorm0_beta) /* ty=Tensor[(480), float32] */;
  %450 = multiply(%445, %446) /* ty=Tensor[(1, 480, 28, 28), float32] */;
  %451 = expand_dims(%449, axis=1, num_newaxis=2) /* ty=Tensor[(480, 1, 1), float32] */;
  %452 = add(%efficientnet0_features_mbconv6_batchnorm0_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(480), float32] */;
  %453 = sqrt(%452) /* ty=Tensor[(480), float32] */;
  %454 = divide(1f /* ty=float32 */, %453) /* ty=Tensor[(480), float32] */;
  %455 = multiply(%454, %efficientnet0_features_mbconv6_batchnorm0_gamma) /* ty=Tensor[(480), float32] */;
  %456 = expand_dims(%455, axis=1, num_newaxis=2) /* ty=Tensor[(480, 1, 1), float32] */;
  %457 = negative(%efficientnet0_features_mbconv6_batchnorm0_running_mean) /* ty=Tensor[(480), float32] */;
  %458 = multiply(%457, %455) /* ty=Tensor[(480), float32] */;
  %459 = add(%458, %efficientnet0_features_mbconv6_batchnorm0_beta) /* ty=Tensor[(480), float32] */;
  %460 = multiply(%445, %456) /* ty=Tensor[(1, 480, 28, 28), float32] */;
  %461 = expand_dims(%459, axis=1, num_newaxis=2) /* ty=Tensor[(480, 1, 1), float32] */;
  %462 = add(%460, %461) /* ty=Tensor[(1, 480, 28, 28), float32] */;
  %463 = multiply(%462, 1f /* ty=float32 */) /* ty=Tensor[(1, 480, 28, 28), float32] */;
  %464 = add(%450, %451) /* ty=Tensor[(1, 480, 28, 28), float32] */;
  %465 = sigmoid(%463) /* ty=Tensor[(1, 480, 28, 28), float32] */;
  %466 = multiply(%464, %465) /* ty=Tensor[(1, 480, 28, 28), float32] */;
  %467 = nn.pad(%466, 0 /* ty=int32 */, pad_width=[[0, 0], [0, 0], [1, 1], [1, 1]]) /* ty=Tensor[(1, 480, 30, 30), float32] */;
  %468 = add(%efficientnet0_features_mbconv6_batchnorm1_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(480), float32] */;
  %469 = sqrt(%468) /* ty=Tensor[(480), float32] */;
  %470 = divide(1f /* ty=float32 */, %469) /* ty=Tensor[(480), float32] */;
  %471 = multiply(%470, %efficientnet0_features_mbconv6_batchnorm1_gamma) /* ty=Tensor[(480), float32] */;
  %472 = nn.conv2d(%467, %efficientnet0_features_mbconv6_conv1_weight, padding=[0, 0, 0, 0], groups=480, channels=480, kernel_size=[3, 3]) /* ty=Tensor[(1, 480, 28, 28), float32] */;
  %473 = expand_dims(%471, axis=1, num_newaxis=2) /* ty=Tensor[(480, 1, 1), float32] */;
  %474 = negative(%efficientnet0_features_mbconv6_batchnorm1_running_mean) /* ty=Tensor[(480), float32] */;
  %475 = multiply(%474, %471) /* ty=Tensor[(480), float32] */;
  %476 = add(%475, %efficientnet0_features_mbconv6_batchnorm1_beta) /* ty=Tensor[(480), float32] */;
  %477 = multiply(%472, %473) /* ty=Tensor[(1, 480, 28, 28), float32] */;
  %478 = expand_dims(%476, axis=1, num_newaxis=2) /* ty=Tensor[(480, 1, 1), float32] */;
  %479 = add(%efficientnet0_features_mbconv6_batchnorm1_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(480), float32] */;
  %480 = sqrt(%479) /* ty=Tensor[(480), float32] */;
  %481 = divide(1f /* ty=float32 */, %480) /* ty=Tensor[(480), float32] */;
  %482 = multiply(%481, %efficientnet0_features_mbconv6_batchnorm1_gamma) /* ty=Tensor[(480), float32] */;
  %483 = expand_dims(%482, axis=1, num_newaxis=2) /* ty=Tensor[(480, 1, 1), float32] */;
  %484 = negative(%efficientnet0_features_mbconv6_batchnorm1_running_mean) /* ty=Tensor[(480), float32] */;
  %485 = multiply(%484, %482) /* ty=Tensor[(480), float32] */;
  %486 = add(%485, %efficientnet0_features_mbconv6_batchnorm1_beta) /* ty=Tensor[(480), float32] */;
  %487 = multiply(%472, %483) /* ty=Tensor[(1, 480, 28, 28), float32] */;
  %488 = expand_dims(%486, axis=1, num_newaxis=2) /* ty=Tensor[(480, 1, 1), float32] */;
  %489 = add(%487, %488) /* ty=Tensor[(1, 480, 28, 28), float32] */;
  %490 = multiply(%489, 1f /* ty=float32 */) /* ty=Tensor[(1, 480, 28, 28), float32] */;
  %491 = add(%477, %478) /* ty=Tensor[(1, 480, 28, 28), float32] */;
  %492 = sigmoid(%490) /* ty=Tensor[(1, 480, 28, 28), float32] */;
  %493 = multiply(%491, %492) /* ty=Tensor[(1, 480, 28, 28), float32] */;
  %494 = add(%efficientnet0_features_mbconv6_batchnorm2_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(80), float32] */;
  %495 = sqrt(%494) /* ty=Tensor[(80), float32] */;
  %496 = divide(1f /* ty=float32 */, %495) /* ty=Tensor[(80), float32] */;
  %497 = multiply(%496, %efficientnet0_features_mbconv6_batchnorm2_gamma) /* ty=Tensor[(80), float32] */;
  %498 = nn.conv2d(%493, %efficientnet0_features_mbconv6_conv2_weight, padding=[0, 0, 0, 0], channels=80, kernel_size=[1, 1]) /* ty=Tensor[(1, 80, 28, 28), float32] */;
  %499 = expand_dims(%497, axis=1, num_newaxis=2) /* ty=Tensor[(80, 1, 1), float32] */;
  %500 = negative(%efficientnet0_features_mbconv6_batchnorm2_running_mean) /* ty=Tensor[(80), float32] */;
  %501 = multiply(%500, %497) /* ty=Tensor[(80), float32] */;
  %502 = add(%501, %efficientnet0_features_mbconv6_batchnorm2_beta) /* ty=Tensor[(80), float32] */;
  %503 = multiply(%498, %499) /* ty=Tensor[(1, 80, 28, 28), float32] */;
  %504 = expand_dims(%502, axis=1, num_newaxis=2) /* ty=Tensor[(80, 1, 1), float32] */;
  %505 = add(%efficientnet0_features_mbconv5_batchnorm2_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(80), float32] */;
  %506 = sqrt(%505) /* ty=Tensor[(80), float32] */;
  %507 = divide(1f /* ty=float32 */, %506) /* ty=Tensor[(80), float32] */;
  %508 = multiply(%507, %efficientnet0_features_mbconv5_batchnorm2_gamma) /* ty=Tensor[(80), float32] */;
  %509 = expand_dims(%508, axis=1, num_newaxis=2) /* ty=Tensor[(80, 1, 1), float32] */;
  %510 = negative(%efficientnet0_features_mbconv5_batchnorm2_running_mean) /* ty=Tensor[(80), float32] */;
  %511 = multiply(%510, %508) /* ty=Tensor[(80), float32] */;
  %512 = add(%511, %efficientnet0_features_mbconv5_batchnorm2_beta) /* ty=Tensor[(80), float32] */;
  %513 = multiply(%433, %509) /* ty=Tensor[(1, 80, 28, 28), float32] */;
  %514 = expand_dims(%512, axis=1, num_newaxis=2) /* ty=Tensor[(80, 1, 1), float32] */;
  %515 = add(%503, %504) /* ty=Tensor[(1, 80, 28, 28), float32] */;
  %516 = add(%513, %514) /* ty=Tensor[(1, 80, 28, 28), float32] */;
  %517 = add(%515, %516) /* ty=Tensor[(1, 80, 28, 28), float32] */;
  %518 = add(%efficientnet0_features_mbconv7_batchnorm0_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(480), float32] */;
  %519 = sqrt(%518) /* ty=Tensor[(480), float32] */;
  %520 = divide(1f /* ty=float32 */, %519) /* ty=Tensor[(480), float32] */;
  %521 = multiply(%520, %efficientnet0_features_mbconv7_batchnorm0_gamma) /* ty=Tensor[(480), float32] */;
  %522 = nn.conv2d(%517, %efficientnet0_features_mbconv7_conv0_weight, padding=[0, 0, 0, 0], channels=480, kernel_size=[1, 1]) /* ty=Tensor[(1, 480, 28, 28), float32] */;
  %523 = expand_dims(%521, axis=1, num_newaxis=2) /* ty=Tensor[(480, 1, 1), float32] */;
  %524 = negative(%efficientnet0_features_mbconv7_batchnorm0_running_mean) /* ty=Tensor[(480), float32] */;
  %525 = multiply(%524, %521) /* ty=Tensor[(480), float32] */;
  %526 = add(%525, %efficientnet0_features_mbconv7_batchnorm0_beta) /* ty=Tensor[(480), float32] */;
  %527 = multiply(%522, %523) /* ty=Tensor[(1, 480, 28, 28), float32] */;
  %528 = expand_dims(%526, axis=1, num_newaxis=2) /* ty=Tensor[(480, 1, 1), float32] */;
  %529 = add(%efficientnet0_features_mbconv7_batchnorm0_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(480), float32] */;
  %530 = sqrt(%529) /* ty=Tensor[(480), float32] */;
  %531 = divide(1f /* ty=float32 */, %530) /* ty=Tensor[(480), float32] */;
  %532 = multiply(%531, %efficientnet0_features_mbconv7_batchnorm0_gamma) /* ty=Tensor[(480), float32] */;
  %533 = expand_dims(%532, axis=1, num_newaxis=2) /* ty=Tensor[(480, 1, 1), float32] */;
  %534 = negative(%efficientnet0_features_mbconv7_batchnorm0_running_mean) /* ty=Tensor[(480), float32] */;
  %535 = multiply(%534, %532) /* ty=Tensor[(480), float32] */;
  %536 = add(%535, %efficientnet0_features_mbconv7_batchnorm0_beta) /* ty=Tensor[(480), float32] */;
  %537 = multiply(%522, %533) /* ty=Tensor[(1, 480, 28, 28), float32] */;
  %538 = expand_dims(%536, axis=1, num_newaxis=2) /* ty=Tensor[(480, 1, 1), float32] */;
  %539 = add(%537, %538) /* ty=Tensor[(1, 480, 28, 28), float32] */;
  %540 = multiply(%539, 1f /* ty=float32 */) /* ty=Tensor[(1, 480, 28, 28), float32] */;
  %541 = add(%527, %528) /* ty=Tensor[(1, 480, 28, 28), float32] */;
  %542 = sigmoid(%540) /* ty=Tensor[(1, 480, 28, 28), float32] */;
  %543 = multiply(%541, %542) /* ty=Tensor[(1, 480, 28, 28), float32] */;
  %544 = nn.pad(%543, 0 /* ty=int32 */, pad_width=[[0, 0], [0, 0], [1, 1], [1, 1]]) /* ty=Tensor[(1, 480, 30, 30), float32] */;
  %545 = add(%efficientnet0_features_mbconv7_batchnorm1_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(480), float32] */;
  %546 = sqrt(%545) /* ty=Tensor[(480), float32] */;
  %547 = divide(1f /* ty=float32 */, %546) /* ty=Tensor[(480), float32] */;
  %548 = multiply(%547, %efficientnet0_features_mbconv7_batchnorm1_gamma) /* ty=Tensor[(480), float32] */;
  %549 = nn.conv2d(%544, %efficientnet0_features_mbconv7_conv1_weight, padding=[0, 0, 0, 0], groups=480, channels=480, kernel_size=[3, 3]) /* ty=Tensor[(1, 480, 28, 28), float32] */;
  %550 = expand_dims(%548, axis=1, num_newaxis=2) /* ty=Tensor[(480, 1, 1), float32] */;
  %551 = negative(%efficientnet0_features_mbconv7_batchnorm1_running_mean) /* ty=Tensor[(480), float32] */;
  %552 = multiply(%551, %548) /* ty=Tensor[(480), float32] */;
  %553 = add(%552, %efficientnet0_features_mbconv7_batchnorm1_beta) /* ty=Tensor[(480), float32] */;
  %554 = multiply(%549, %550) /* ty=Tensor[(1, 480, 28, 28), float32] */;
  %555 = expand_dims(%553, axis=1, num_newaxis=2) /* ty=Tensor[(480, 1, 1), float32] */;
  %556 = add(%efficientnet0_features_mbconv7_batchnorm1_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(480), float32] */;
  %557 = sqrt(%556) /* ty=Tensor[(480), float32] */;
  %558 = divide(1f /* ty=float32 */, %557) /* ty=Tensor[(480), float32] */;
  %559 = multiply(%558, %efficientnet0_features_mbconv7_batchnorm1_gamma) /* ty=Tensor[(480), float32] */;
  %560 = expand_dims(%559, axis=1, num_newaxis=2) /* ty=Tensor[(480, 1, 1), float32] */;
  %561 = negative(%efficientnet0_features_mbconv7_batchnorm1_running_mean) /* ty=Tensor[(480), float32] */;
  %562 = multiply(%561, %559) /* ty=Tensor[(480), float32] */;
  %563 = add(%562, %efficientnet0_features_mbconv7_batchnorm1_beta) /* ty=Tensor[(480), float32] */;
  %564 = multiply(%549, %560) /* ty=Tensor[(1, 480, 28, 28), float32] */;
  %565 = expand_dims(%563, axis=1, num_newaxis=2) /* ty=Tensor[(480, 1, 1), float32] */;
  %566 = add(%564, %565) /* ty=Tensor[(1, 480, 28, 28), float32] */;
  %567 = multiply(%566, 1f /* ty=float32 */) /* ty=Tensor[(1, 480, 28, 28), float32] */;
  %568 = add(%554, %555) /* ty=Tensor[(1, 480, 28, 28), float32] */;
  %569 = sigmoid(%567) /* ty=Tensor[(1, 480, 28, 28), float32] */;
  %570 = multiply(%568, %569) /* ty=Tensor[(1, 480, 28, 28), float32] */;
  %571 = add(%efficientnet0_features_mbconv7_batchnorm2_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(80), float32] */;
  %572 = sqrt(%571) /* ty=Tensor[(80), float32] */;
  %573 = divide(1f /* ty=float32 */, %572) /* ty=Tensor[(80), float32] */;
  %574 = multiply(%573, %efficientnet0_features_mbconv7_batchnorm2_gamma) /* ty=Tensor[(80), float32] */;
  %575 = nn.conv2d(%570, %efficientnet0_features_mbconv7_conv2_weight, padding=[0, 0, 0, 0], channels=80, kernel_size=[1, 1]) /* ty=Tensor[(1, 80, 28, 28), float32] */;
  %576 = expand_dims(%574, axis=1, num_newaxis=2) /* ty=Tensor[(80, 1, 1), float32] */;
  %577 = negative(%efficientnet0_features_mbconv7_batchnorm2_running_mean) /* ty=Tensor[(80), float32] */;
  %578 = multiply(%577, %574) /* ty=Tensor[(80), float32] */;
  %579 = add(%578, %efficientnet0_features_mbconv7_batchnorm2_beta) /* ty=Tensor[(80), float32] */;
  %580 = multiply(%575, %576) /* ty=Tensor[(1, 80, 28, 28), float32] */;
  %581 = expand_dims(%579, axis=1, num_newaxis=2) /* ty=Tensor[(80, 1, 1), float32] */;
  %582 = add(%580, %581) /* ty=Tensor[(1, 80, 28, 28), float32] */;
  %583 = add(%582, %517) /* ty=Tensor[(1, 80, 28, 28), float32] */;
  %584 = add(%efficientnet0_features_mbconv8_batchnorm0_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(480), float32] */;
  %585 = sqrt(%584) /* ty=Tensor[(480), float32] */;
  %586 = divide(1f /* ty=float32 */, %585) /* ty=Tensor[(480), float32] */;
  %587 = multiply(%586, %efficientnet0_features_mbconv8_batchnorm0_gamma) /* ty=Tensor[(480), float32] */;
  %588 = nn.conv2d(%583, %efficientnet0_features_mbconv8_conv0_weight, padding=[0, 0, 0, 0], channels=480, kernel_size=[1, 1]) /* ty=Tensor[(1, 480, 28, 28), float32] */;
  %589 = expand_dims(%587, axis=1, num_newaxis=2) /* ty=Tensor[(480, 1, 1), float32] */;
  %590 = negative(%efficientnet0_features_mbconv8_batchnorm0_running_mean) /* ty=Tensor[(480), float32] */;
  %591 = multiply(%590, %587) /* ty=Tensor[(480), float32] */;
  %592 = add(%591, %efficientnet0_features_mbconv8_batchnorm0_beta) /* ty=Tensor[(480), float32] */;
  %593 = multiply(%588, %589) /* ty=Tensor[(1, 480, 28, 28), float32] */;
  %594 = expand_dims(%592, axis=1, num_newaxis=2) /* ty=Tensor[(480, 1, 1), float32] */;
  %595 = add(%efficientnet0_features_mbconv8_batchnorm0_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(480), float32] */;
  %596 = sqrt(%595) /* ty=Tensor[(480), float32] */;
  %597 = divide(1f /* ty=float32 */, %596) /* ty=Tensor[(480), float32] */;
  %598 = multiply(%597, %efficientnet0_features_mbconv8_batchnorm0_gamma) /* ty=Tensor[(480), float32] */;
  %599 = expand_dims(%598, axis=1, num_newaxis=2) /* ty=Tensor[(480, 1, 1), float32] */;
  %600 = negative(%efficientnet0_features_mbconv8_batchnorm0_running_mean) /* ty=Tensor[(480), float32] */;
  %601 = multiply(%600, %598) /* ty=Tensor[(480), float32] */;
  %602 = add(%601, %efficientnet0_features_mbconv8_batchnorm0_beta) /* ty=Tensor[(480), float32] */;
  %603 = multiply(%588, %599) /* ty=Tensor[(1, 480, 28, 28), float32] */;
  %604 = expand_dims(%602, axis=1, num_newaxis=2) /* ty=Tensor[(480, 1, 1), float32] */;
  %605 = add(%603, %604) /* ty=Tensor[(1, 480, 28, 28), float32] */;
  %606 = multiply(%605, 1f /* ty=float32 */) /* ty=Tensor[(1, 480, 28, 28), float32] */;
  %607 = add(%593, %594) /* ty=Tensor[(1, 480, 28, 28), float32] */;
  %608 = sigmoid(%606) /* ty=Tensor[(1, 480, 28, 28), float32] */;
  %609 = multiply(%607, %608) /* ty=Tensor[(1, 480, 28, 28), float32] */;
  %610 = nn.pad(%609, 0 /* ty=int32 */, pad_width=[[0, 0], [0, 0], [2, 2], [2, 2]]) /* ty=Tensor[(1, 480, 32, 32), float32] */;
  %611 = add(%efficientnet0_features_mbconv8_batchnorm1_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(480), float32] */;
  %612 = sqrt(%611) /* ty=Tensor[(480), float32] */;
  %613 = divide(1f /* ty=float32 */, %612) /* ty=Tensor[(480), float32] */;
  %614 = multiply(%613, %efficientnet0_features_mbconv8_batchnorm1_gamma) /* ty=Tensor[(480), float32] */;
  %615 = nn.conv2d(%610, %efficientnet0_features_mbconv8_conv1_weight, strides=[2, 2], padding=[0, 0, 0, 0], groups=480, channels=480, kernel_size=[5, 5]) /* ty=Tensor[(1, 480, 14, 14), float32] */;
  %616 = expand_dims(%614, axis=1, num_newaxis=2) /* ty=Tensor[(480, 1, 1), float32] */;
  %617 = negative(%efficientnet0_features_mbconv8_batchnorm1_running_mean) /* ty=Tensor[(480), float32] */;
  %618 = multiply(%617, %614) /* ty=Tensor[(480), float32] */;
  %619 = add(%618, %efficientnet0_features_mbconv8_batchnorm1_beta) /* ty=Tensor[(480), float32] */;
  %620 = multiply(%615, %616) /* ty=Tensor[(1, 480, 14, 14), float32] */;
  %621 = expand_dims(%619, axis=1, num_newaxis=2) /* ty=Tensor[(480, 1, 1), float32] */;
  %622 = add(%efficientnet0_features_mbconv8_batchnorm1_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(480), float32] */;
  %623 = sqrt(%622) /* ty=Tensor[(480), float32] */;
  %624 = divide(1f /* ty=float32 */, %623) /* ty=Tensor[(480), float32] */;
  %625 = multiply(%624, %efficientnet0_features_mbconv8_batchnorm1_gamma) /* ty=Tensor[(480), float32] */;
  %626 = expand_dims(%625, axis=1, num_newaxis=2) /* ty=Tensor[(480, 1, 1), float32] */;
  %627 = negative(%efficientnet0_features_mbconv8_batchnorm1_running_mean) /* ty=Tensor[(480), float32] */;
  %628 = multiply(%627, %625) /* ty=Tensor[(480), float32] */;
  %629 = add(%628, %efficientnet0_features_mbconv8_batchnorm1_beta) /* ty=Tensor[(480), float32] */;
  %630 = multiply(%615, %626) /* ty=Tensor[(1, 480, 14, 14), float32] */;
  %631 = expand_dims(%629, axis=1, num_newaxis=2) /* ty=Tensor[(480, 1, 1), float32] */;
  %632 = add(%630, %631) /* ty=Tensor[(1, 480, 14, 14), float32] */;
  %633 = multiply(%632, 1f /* ty=float32 */) /* ty=Tensor[(1, 480, 14, 14), float32] */;
  %634 = add(%620, %621) /* ty=Tensor[(1, 480, 14, 14), float32] */;
  %635 = sigmoid(%633) /* ty=Tensor[(1, 480, 14, 14), float32] */;
  %636 = multiply(%634, %635) /* ty=Tensor[(1, 480, 14, 14), float32] */;
  %637 = add(%efficientnet0_features_mbconv8_batchnorm2_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(112), float32] */;
  %638 = sqrt(%637) /* ty=Tensor[(112), float32] */;
  %639 = divide(1f /* ty=float32 */, %638) /* ty=Tensor[(112), float32] */;
  %640 = multiply(%639, %efficientnet0_features_mbconv8_batchnorm2_gamma) /* ty=Tensor[(112), float32] */;
  %641 = nn.conv2d(%636, %efficientnet0_features_mbconv8_conv2_weight, padding=[0, 0, 0, 0], channels=112, kernel_size=[1, 1]) /* ty=Tensor[(1, 112, 14, 14), float32] */;
  %642 = expand_dims(%640, axis=1, num_newaxis=2) /* ty=Tensor[(112, 1, 1), float32] */;
  %643 = negative(%efficientnet0_features_mbconv8_batchnorm2_running_mean) /* ty=Tensor[(112), float32] */;
  %644 = multiply(%643, %640) /* ty=Tensor[(112), float32] */;
  %645 = add(%644, %efficientnet0_features_mbconv8_batchnorm2_beta) /* ty=Tensor[(112), float32] */;
  %646 = multiply(%641, %642) /* ty=Tensor[(1, 112, 14, 14), float32] */;
  %647 = expand_dims(%645, axis=1, num_newaxis=2) /* ty=Tensor[(112, 1, 1), float32] */;
  %648 = add(%646, %647) /* ty=Tensor[(1, 112, 14, 14), float32] */;
  %649 = add(%efficientnet0_features_mbconv9_batchnorm0_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(672), float32] */;
  %650 = sqrt(%649) /* ty=Tensor[(672), float32] */;
  %651 = divide(1f /* ty=float32 */, %650) /* ty=Tensor[(672), float32] */;
  %652 = multiply(%651, %efficientnet0_features_mbconv9_batchnorm0_gamma) /* ty=Tensor[(672), float32] */;
  %653 = nn.conv2d(%648, %efficientnet0_features_mbconv9_conv0_weight, padding=[0, 0, 0, 0], channels=672, kernel_size=[1, 1]) /* ty=Tensor[(1, 672, 14, 14), float32] */;
  %654 = expand_dims(%652, axis=1, num_newaxis=2) /* ty=Tensor[(672, 1, 1), float32] */;
  %655 = negative(%efficientnet0_features_mbconv9_batchnorm0_running_mean) /* ty=Tensor[(672), float32] */;
  %656 = multiply(%655, %652) /* ty=Tensor[(672), float32] */;
  %657 = add(%656, %efficientnet0_features_mbconv9_batchnorm0_beta) /* ty=Tensor[(672), float32] */;
  %658 = multiply(%653, %654) /* ty=Tensor[(1, 672, 14, 14), float32] */;
  %659 = expand_dims(%657, axis=1, num_newaxis=2) /* ty=Tensor[(672, 1, 1), float32] */;
  %660 = add(%efficientnet0_features_mbconv9_batchnorm0_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(672), float32] */;
  %661 = sqrt(%660) /* ty=Tensor[(672), float32] */;
  %662 = divide(1f /* ty=float32 */, %661) /* ty=Tensor[(672), float32] */;
  %663 = multiply(%662, %efficientnet0_features_mbconv9_batchnorm0_gamma) /* ty=Tensor[(672), float32] */;
  %664 = expand_dims(%663, axis=1, num_newaxis=2) /* ty=Tensor[(672, 1, 1), float32] */;
  %665 = negative(%efficientnet0_features_mbconv9_batchnorm0_running_mean) /* ty=Tensor[(672), float32] */;
  %666 = multiply(%665, %663) /* ty=Tensor[(672), float32] */;
  %667 = add(%666, %efficientnet0_features_mbconv9_batchnorm0_beta) /* ty=Tensor[(672), float32] */;
  %668 = multiply(%653, %664) /* ty=Tensor[(1, 672, 14, 14), float32] */;
  %669 = expand_dims(%667, axis=1, num_newaxis=2) /* ty=Tensor[(672, 1, 1), float32] */;
  %670 = add(%668, %669) /* ty=Tensor[(1, 672, 14, 14), float32] */;
  %671 = multiply(%670, 1f /* ty=float32 */) /* ty=Tensor[(1, 672, 14, 14), float32] */;
  %672 = add(%658, %659) /* ty=Tensor[(1, 672, 14, 14), float32] */;
  %673 = sigmoid(%671) /* ty=Tensor[(1, 672, 14, 14), float32] */;
  %674 = multiply(%672, %673) /* ty=Tensor[(1, 672, 14, 14), float32] */;
  %675 = nn.pad(%674, 0 /* ty=int32 */, pad_width=[[0, 0], [0, 0], [2, 2], [2, 2]]) /* ty=Tensor[(1, 672, 18, 18), float32] */;
  %676 = add(%efficientnet0_features_mbconv9_batchnorm1_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(672), float32] */;
  %677 = sqrt(%676) /* ty=Tensor[(672), float32] */;
  %678 = divide(1f /* ty=float32 */, %677) /* ty=Tensor[(672), float32] */;
  %679 = multiply(%678, %efficientnet0_features_mbconv9_batchnorm1_gamma) /* ty=Tensor[(672), float32] */;
  %680 = nn.conv2d(%675, %efficientnet0_features_mbconv9_conv1_weight, padding=[0, 0, 0, 0], groups=672, channels=672, kernel_size=[5, 5]) /* ty=Tensor[(1, 672, 14, 14), float32] */;
  %681 = expand_dims(%679, axis=1, num_newaxis=2) /* ty=Tensor[(672, 1, 1), float32] */;
  %682 = negative(%efficientnet0_features_mbconv9_batchnorm1_running_mean) /* ty=Tensor[(672), float32] */;
  %683 = multiply(%682, %679) /* ty=Tensor[(672), float32] */;
  %684 = add(%683, %efficientnet0_features_mbconv9_batchnorm1_beta) /* ty=Tensor[(672), float32] */;
  %685 = multiply(%680, %681) /* ty=Tensor[(1, 672, 14, 14), float32] */;
  %686 = expand_dims(%684, axis=1, num_newaxis=2) /* ty=Tensor[(672, 1, 1), float32] */;
  %687 = add(%efficientnet0_features_mbconv9_batchnorm1_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(672), float32] */;
  %688 = sqrt(%687) /* ty=Tensor[(672), float32] */;
  %689 = divide(1f /* ty=float32 */, %688) /* ty=Tensor[(672), float32] */;
  %690 = multiply(%689, %efficientnet0_features_mbconv9_batchnorm1_gamma) /* ty=Tensor[(672), float32] */;
  %691 = expand_dims(%690, axis=1, num_newaxis=2) /* ty=Tensor[(672, 1, 1), float32] */;
  %692 = negative(%efficientnet0_features_mbconv9_batchnorm1_running_mean) /* ty=Tensor[(672), float32] */;
  %693 = multiply(%692, %690) /* ty=Tensor[(672), float32] */;
  %694 = add(%693, %efficientnet0_features_mbconv9_batchnorm1_beta) /* ty=Tensor[(672), float32] */;
  %695 = multiply(%680, %691) /* ty=Tensor[(1, 672, 14, 14), float32] */;
  %696 = expand_dims(%694, axis=1, num_newaxis=2) /* ty=Tensor[(672, 1, 1), float32] */;
  %697 = add(%695, %696) /* ty=Tensor[(1, 672, 14, 14), float32] */;
  %698 = multiply(%697, 1f /* ty=float32 */) /* ty=Tensor[(1, 672, 14, 14), float32] */;
  %699 = add(%685, %686) /* ty=Tensor[(1, 672, 14, 14), float32] */;
  %700 = sigmoid(%698) /* ty=Tensor[(1, 672, 14, 14), float32] */;
  %701 = multiply(%699, %700) /* ty=Tensor[(1, 672, 14, 14), float32] */;
  %702 = add(%efficientnet0_features_mbconv9_batchnorm2_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(112), float32] */;
  %703 = sqrt(%702) /* ty=Tensor[(112), float32] */;
  %704 = divide(1f /* ty=float32 */, %703) /* ty=Tensor[(112), float32] */;
  %705 = multiply(%704, %efficientnet0_features_mbconv9_batchnorm2_gamma) /* ty=Tensor[(112), float32] */;
  %706 = nn.conv2d(%701, %efficientnet0_features_mbconv9_conv2_weight, padding=[0, 0, 0, 0], channels=112, kernel_size=[1, 1]) /* ty=Tensor[(1, 112, 14, 14), float32] */;
  %707 = expand_dims(%705, axis=1, num_newaxis=2) /* ty=Tensor[(112, 1, 1), float32] */;
  %708 = negative(%efficientnet0_features_mbconv9_batchnorm2_running_mean) /* ty=Tensor[(112), float32] */;
  %709 = multiply(%708, %705) /* ty=Tensor[(112), float32] */;
  %710 = add(%709, %efficientnet0_features_mbconv9_batchnorm2_beta) /* ty=Tensor[(112), float32] */;
  %711 = multiply(%706, %707) /* ty=Tensor[(1, 112, 14, 14), float32] */;
  %712 = expand_dims(%710, axis=1, num_newaxis=2) /* ty=Tensor[(112, 1, 1), float32] */;
  %713 = add(%efficientnet0_features_mbconv8_batchnorm2_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(112), float32] */;
  %714 = sqrt(%713) /* ty=Tensor[(112), float32] */;
  %715 = divide(1f /* ty=float32 */, %714) /* ty=Tensor[(112), float32] */;
  %716 = multiply(%715, %efficientnet0_features_mbconv8_batchnorm2_gamma) /* ty=Tensor[(112), float32] */;
  %717 = expand_dims(%716, axis=1, num_newaxis=2) /* ty=Tensor[(112, 1, 1), float32] */;
  %718 = negative(%efficientnet0_features_mbconv8_batchnorm2_running_mean) /* ty=Tensor[(112), float32] */;
  %719 = multiply(%718, %716) /* ty=Tensor[(112), float32] */;
  %720 = add(%719, %efficientnet0_features_mbconv8_batchnorm2_beta) /* ty=Tensor[(112), float32] */;
  %721 = multiply(%641, %717) /* ty=Tensor[(1, 112, 14, 14), float32] */;
  %722 = expand_dims(%720, axis=1, num_newaxis=2) /* ty=Tensor[(112, 1, 1), float32] */;
  %723 = add(%711, %712) /* ty=Tensor[(1, 112, 14, 14), float32] */;
  %724 = add(%721, %722) /* ty=Tensor[(1, 112, 14, 14), float32] */;
  %725 = add(%723, %724) /* ty=Tensor[(1, 112, 14, 14), float32] */;
  %726 = add(%efficientnet0_features_mbconv10_batchnorm0_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(672), float32] */;
  %727 = sqrt(%726) /* ty=Tensor[(672), float32] */;
  %728 = divide(1f /* ty=float32 */, %727) /* ty=Tensor[(672), float32] */;
  %729 = multiply(%728, %efficientnet0_features_mbconv10_batchnorm0_gamma) /* ty=Tensor[(672), float32] */;
  %730 = nn.conv2d(%725, %efficientnet0_features_mbconv10_conv0_weight, padding=[0, 0, 0, 0], channels=672, kernel_size=[1, 1]) /* ty=Tensor[(1, 672, 14, 14), float32] */;
  %731 = expand_dims(%729, axis=1, num_newaxis=2) /* ty=Tensor[(672, 1, 1), float32] */;
  %732 = negative(%efficientnet0_features_mbconv10_batchnorm0_running_mean) /* ty=Tensor[(672), float32] */;
  %733 = multiply(%732, %729) /* ty=Tensor[(672), float32] */;
  %734 = add(%733, %efficientnet0_features_mbconv10_batchnorm0_beta) /* ty=Tensor[(672), float32] */;
  %735 = multiply(%730, %731) /* ty=Tensor[(1, 672, 14, 14), float32] */;
  %736 = expand_dims(%734, axis=1, num_newaxis=2) /* ty=Tensor[(672, 1, 1), float32] */;
  %737 = add(%efficientnet0_features_mbconv10_batchnorm0_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(672), float32] */;
  %738 = sqrt(%737) /* ty=Tensor[(672), float32] */;
  %739 = divide(1f /* ty=float32 */, %738) /* ty=Tensor[(672), float32] */;
  %740 = multiply(%739, %efficientnet0_features_mbconv10_batchnorm0_gamma) /* ty=Tensor[(672), float32] */;
  %741 = expand_dims(%740, axis=1, num_newaxis=2) /* ty=Tensor[(672, 1, 1), float32] */;
  %742 = negative(%efficientnet0_features_mbconv10_batchnorm0_running_mean) /* ty=Tensor[(672), float32] */;
  %743 = multiply(%742, %740) /* ty=Tensor[(672), float32] */;
  %744 = add(%743, %efficientnet0_features_mbconv10_batchnorm0_beta) /* ty=Tensor[(672), float32] */;
  %745 = multiply(%730, %741) /* ty=Tensor[(1, 672, 14, 14), float32] */;
  %746 = expand_dims(%744, axis=1, num_newaxis=2) /* ty=Tensor[(672, 1, 1), float32] */;
  %747 = add(%745, %746) /* ty=Tensor[(1, 672, 14, 14), float32] */;
  %748 = multiply(%747, 1f /* ty=float32 */) /* ty=Tensor[(1, 672, 14, 14), float32] */;
  %749 = add(%735, %736) /* ty=Tensor[(1, 672, 14, 14), float32] */;
  %750 = sigmoid(%748) /* ty=Tensor[(1, 672, 14, 14), float32] */;
  %751 = multiply(%749, %750) /* ty=Tensor[(1, 672, 14, 14), float32] */;
  %752 = nn.pad(%751, 0 /* ty=int32 */, pad_width=[[0, 0], [0, 0], [2, 2], [2, 2]]) /* ty=Tensor[(1, 672, 18, 18), float32] */;
  %753 = add(%efficientnet0_features_mbconv10_batchnorm1_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(672), float32] */;
  %754 = sqrt(%753) /* ty=Tensor[(672), float32] */;
  %755 = divide(1f /* ty=float32 */, %754) /* ty=Tensor[(672), float32] */;
  %756 = multiply(%755, %efficientnet0_features_mbconv10_batchnorm1_gamma) /* ty=Tensor[(672), float32] */;
  %757 = nn.conv2d(%752, %efficientnet0_features_mbconv10_conv1_weight, padding=[0, 0, 0, 0], groups=672, channels=672, kernel_size=[5, 5]) /* ty=Tensor[(1, 672, 14, 14), float32] */;
  %758 = expand_dims(%756, axis=1, num_newaxis=2) /* ty=Tensor[(672, 1, 1), float32] */;
  %759 = negative(%efficientnet0_features_mbconv10_batchnorm1_running_mean) /* ty=Tensor[(672), float32] */;
  %760 = multiply(%759, %756) /* ty=Tensor[(672), float32] */;
  %761 = add(%760, %efficientnet0_features_mbconv10_batchnorm1_beta) /* ty=Tensor[(672), float32] */;
  %762 = multiply(%757, %758) /* ty=Tensor[(1, 672, 14, 14), float32] */;
  %763 = expand_dims(%761, axis=1, num_newaxis=2) /* ty=Tensor[(672, 1, 1), float32] */;
  %764 = add(%efficientnet0_features_mbconv10_batchnorm1_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(672), float32] */;
  %765 = sqrt(%764) /* ty=Tensor[(672), float32] */;
  %766 = divide(1f /* ty=float32 */, %765) /* ty=Tensor[(672), float32] */;
  %767 = multiply(%766, %efficientnet0_features_mbconv10_batchnorm1_gamma) /* ty=Tensor[(672), float32] */;
  %768 = expand_dims(%767, axis=1, num_newaxis=2) /* ty=Tensor[(672, 1, 1), float32] */;
  %769 = negative(%efficientnet0_features_mbconv10_batchnorm1_running_mean) /* ty=Tensor[(672), float32] */;
  %770 = multiply(%769, %767) /* ty=Tensor[(672), float32] */;
  %771 = add(%770, %efficientnet0_features_mbconv10_batchnorm1_beta) /* ty=Tensor[(672), float32] */;
  %772 = multiply(%757, %768) /* ty=Tensor[(1, 672, 14, 14), float32] */;
  %773 = expand_dims(%771, axis=1, num_newaxis=2) /* ty=Tensor[(672, 1, 1), float32] */;
  %774 = add(%772, %773) /* ty=Tensor[(1, 672, 14, 14), float32] */;
  %775 = multiply(%774, 1f /* ty=float32 */) /* ty=Tensor[(1, 672, 14, 14), float32] */;
  %776 = add(%762, %763) /* ty=Tensor[(1, 672, 14, 14), float32] */;
  %777 = sigmoid(%775) /* ty=Tensor[(1, 672, 14, 14), float32] */;
  %778 = multiply(%776, %777) /* ty=Tensor[(1, 672, 14, 14), float32] */;
  %779 = add(%efficientnet0_features_mbconv10_batchnorm2_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(112), float32] */;
  %780 = sqrt(%779) /* ty=Tensor[(112), float32] */;
  %781 = divide(1f /* ty=float32 */, %780) /* ty=Tensor[(112), float32] */;
  %782 = multiply(%781, %efficientnet0_features_mbconv10_batchnorm2_gamma) /* ty=Tensor[(112), float32] */;
  %783 = nn.conv2d(%778, %efficientnet0_features_mbconv10_conv2_weight, padding=[0, 0, 0, 0], channels=112, kernel_size=[1, 1]) /* ty=Tensor[(1, 112, 14, 14), float32] */;
  %784 = expand_dims(%782, axis=1, num_newaxis=2) /* ty=Tensor[(112, 1, 1), float32] */;
  %785 = negative(%efficientnet0_features_mbconv10_batchnorm2_running_mean) /* ty=Tensor[(112), float32] */;
  %786 = multiply(%785, %782) /* ty=Tensor[(112), float32] */;
  %787 = add(%786, %efficientnet0_features_mbconv10_batchnorm2_beta) /* ty=Tensor[(112), float32] */;
  %788 = multiply(%783, %784) /* ty=Tensor[(1, 112, 14, 14), float32] */;
  %789 = expand_dims(%787, axis=1, num_newaxis=2) /* ty=Tensor[(112, 1, 1), float32] */;
  %790 = add(%788, %789) /* ty=Tensor[(1, 112, 14, 14), float32] */;
  %791 = add(%790, %725) /* ty=Tensor[(1, 112, 14, 14), float32] */;
  %792 = add(%efficientnet0_features_mbconv11_batchnorm0_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(672), float32] */;
  %793 = sqrt(%792) /* ty=Tensor[(672), float32] */;
  %794 = divide(1f /* ty=float32 */, %793) /* ty=Tensor[(672), float32] */;
  %795 = multiply(%794, %efficientnet0_features_mbconv11_batchnorm0_gamma) /* ty=Tensor[(672), float32] */;
  %796 = nn.conv2d(%791, %efficientnet0_features_mbconv11_conv0_weight, padding=[0, 0, 0, 0], channels=672, kernel_size=[1, 1]) /* ty=Tensor[(1, 672, 14, 14), float32] */;
  %797 = expand_dims(%795, axis=1, num_newaxis=2) /* ty=Tensor[(672, 1, 1), float32] */;
  %798 = negative(%efficientnet0_features_mbconv11_batchnorm0_running_mean) /* ty=Tensor[(672), float32] */;
  %799 = multiply(%798, %795) /* ty=Tensor[(672), float32] */;
  %800 = add(%799, %efficientnet0_features_mbconv11_batchnorm0_beta) /* ty=Tensor[(672), float32] */;
  %801 = multiply(%796, %797) /* ty=Tensor[(1, 672, 14, 14), float32] */;
  %802 = expand_dims(%800, axis=1, num_newaxis=2) /* ty=Tensor[(672, 1, 1), float32] */;
  %803 = add(%efficientnet0_features_mbconv11_batchnorm0_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(672), float32] */;
  %804 = sqrt(%803) /* ty=Tensor[(672), float32] */;
  %805 = divide(1f /* ty=float32 */, %804) /* ty=Tensor[(672), float32] */;
  %806 = multiply(%805, %efficientnet0_features_mbconv11_batchnorm0_gamma) /* ty=Tensor[(672), float32] */;
  %807 = expand_dims(%806, axis=1, num_newaxis=2) /* ty=Tensor[(672, 1, 1), float32] */;
  %808 = negative(%efficientnet0_features_mbconv11_batchnorm0_running_mean) /* ty=Tensor[(672), float32] */;
  %809 = multiply(%808, %806) /* ty=Tensor[(672), float32] */;
  %810 = add(%809, %efficientnet0_features_mbconv11_batchnorm0_beta) /* ty=Tensor[(672), float32] */;
  %811 = multiply(%796, %807) /* ty=Tensor[(1, 672, 14, 14), float32] */;
  %812 = expand_dims(%810, axis=1, num_newaxis=2) /* ty=Tensor[(672, 1, 1), float32] */;
  %813 = add(%811, %812) /* ty=Tensor[(1, 672, 14, 14), float32] */;
  %814 = multiply(%813, 1f /* ty=float32 */) /* ty=Tensor[(1, 672, 14, 14), float32] */;
  %815 = add(%801, %802) /* ty=Tensor[(1, 672, 14, 14), float32] */;
  %816 = sigmoid(%814) /* ty=Tensor[(1, 672, 14, 14), float32] */;
  %817 = multiply(%815, %816) /* ty=Tensor[(1, 672, 14, 14), float32] */;
  %818 = nn.pad(%817, 0 /* ty=int32 */, pad_width=[[0, 0], [0, 0], [2, 2], [2, 2]]) /* ty=Tensor[(1, 672, 18, 18), float32] */;
  %819 = add(%efficientnet0_features_mbconv11_batchnorm1_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(672), float32] */;
  %820 = sqrt(%819) /* ty=Tensor[(672), float32] */;
  %821 = divide(1f /* ty=float32 */, %820) /* ty=Tensor[(672), float32] */;
  %822 = multiply(%821, %efficientnet0_features_mbconv11_batchnorm1_gamma) /* ty=Tensor[(672), float32] */;
  %823 = nn.conv2d(%818, %efficientnet0_features_mbconv11_conv1_weight, strides=[2, 2], padding=[0, 0, 0, 0], groups=672, channels=672, kernel_size=[5, 5]) /* ty=Tensor[(1, 672, 7, 7), float32] */;
  %824 = expand_dims(%822, axis=1, num_newaxis=2) /* ty=Tensor[(672, 1, 1), float32] */;
  %825 = negative(%efficientnet0_features_mbconv11_batchnorm1_running_mean) /* ty=Tensor[(672), float32] */;
  %826 = multiply(%825, %822) /* ty=Tensor[(672), float32] */;
  %827 = add(%826, %efficientnet0_features_mbconv11_batchnorm1_beta) /* ty=Tensor[(672), float32] */;
  %828 = multiply(%823, %824) /* ty=Tensor[(1, 672, 7, 7), float32] */;
  %829 = expand_dims(%827, axis=1, num_newaxis=2) /* ty=Tensor[(672, 1, 1), float32] */;
  %830 = add(%efficientnet0_features_mbconv11_batchnorm1_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(672), float32] */;
  %831 = sqrt(%830) /* ty=Tensor[(672), float32] */;
  %832 = divide(1f /* ty=float32 */, %831) /* ty=Tensor[(672), float32] */;
  %833 = multiply(%832, %efficientnet0_features_mbconv11_batchnorm1_gamma) /* ty=Tensor[(672), float32] */;
  %834 = expand_dims(%833, axis=1, num_newaxis=2) /* ty=Tensor[(672, 1, 1), float32] */;
  %835 = negative(%efficientnet0_features_mbconv11_batchnorm1_running_mean) /* ty=Tensor[(672), float32] */;
  %836 = multiply(%835, %833) /* ty=Tensor[(672), float32] */;
  %837 = add(%836, %efficientnet0_features_mbconv11_batchnorm1_beta) /* ty=Tensor[(672), float32] */;
  %838 = multiply(%823, %834) /* ty=Tensor[(1, 672, 7, 7), float32] */;
  %839 = expand_dims(%837, axis=1, num_newaxis=2) /* ty=Tensor[(672, 1, 1), float32] */;
  %840 = add(%838, %839) /* ty=Tensor[(1, 672, 7, 7), float32] */;
  %841 = multiply(%840, 1f /* ty=float32 */) /* ty=Tensor[(1, 672, 7, 7), float32] */;
  %842 = add(%828, %829) /* ty=Tensor[(1, 672, 7, 7), float32] */;
  %843 = sigmoid(%841) /* ty=Tensor[(1, 672, 7, 7), float32] */;
  %844 = multiply(%842, %843) /* ty=Tensor[(1, 672, 7, 7), float32] */;
  %845 = add(%efficientnet0_features_mbconv11_batchnorm2_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(192), float32] */;
  %846 = sqrt(%845) /* ty=Tensor[(192), float32] */;
  %847 = divide(1f /* ty=float32 */, %846) /* ty=Tensor[(192), float32] */;
  %848 = multiply(%847, %efficientnet0_features_mbconv11_batchnorm2_gamma) /* ty=Tensor[(192), float32] */;
  %849 = nn.conv2d(%844, %efficientnet0_features_mbconv11_conv2_weight, padding=[0, 0, 0, 0], channels=192, kernel_size=[1, 1]) /* ty=Tensor[(1, 192, 7, 7), float32] */;
  %850 = expand_dims(%848, axis=1, num_newaxis=2) /* ty=Tensor[(192, 1, 1), float32] */;
  %851 = negative(%efficientnet0_features_mbconv11_batchnorm2_running_mean) /* ty=Tensor[(192), float32] */;
  %852 = multiply(%851, %848) /* ty=Tensor[(192), float32] */;
  %853 = add(%852, %efficientnet0_features_mbconv11_batchnorm2_beta) /* ty=Tensor[(192), float32] */;
  %854 = multiply(%849, %850) /* ty=Tensor[(1, 192, 7, 7), float32] */;
  %855 = expand_dims(%853, axis=1, num_newaxis=2) /* ty=Tensor[(192, 1, 1), float32] */;
  %856 = add(%854, %855) /* ty=Tensor[(1, 192, 7, 7), float32] */;
  %857 = add(%efficientnet0_features_mbconv12_batchnorm0_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(1152), float32] */;
  %858 = sqrt(%857) /* ty=Tensor[(1152), float32] */;
  %859 = divide(1f /* ty=float32 */, %858) /* ty=Tensor[(1152), float32] */;
  %860 = multiply(%859, %efficientnet0_features_mbconv12_batchnorm0_gamma) /* ty=Tensor[(1152), float32] */;
  %861 = nn.conv2d(%856, %efficientnet0_features_mbconv12_conv0_weight, padding=[0, 0, 0, 0], channels=1152, kernel_size=[1, 1]) /* ty=Tensor[(1, 1152, 7, 7), float32] */;
  %862 = expand_dims(%860, axis=1, num_newaxis=2) /* ty=Tensor[(1152, 1, 1), float32] */;
  %863 = negative(%efficientnet0_features_mbconv12_batchnorm0_running_mean) /* ty=Tensor[(1152), float32] */;
  %864 = multiply(%863, %860) /* ty=Tensor[(1152), float32] */;
  %865 = add(%864, %efficientnet0_features_mbconv12_batchnorm0_beta) /* ty=Tensor[(1152), float32] */;
  %866 = multiply(%861, %862) /* ty=Tensor[(1, 1152, 7, 7), float32] */;
  %867 = expand_dims(%865, axis=1, num_newaxis=2) /* ty=Tensor[(1152, 1, 1), float32] */;
  %868 = add(%efficientnet0_features_mbconv12_batchnorm0_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(1152), float32] */;
  %869 = sqrt(%868) /* ty=Tensor[(1152), float32] */;
  %870 = divide(1f /* ty=float32 */, %869) /* ty=Tensor[(1152), float32] */;
  %871 = multiply(%870, %efficientnet0_features_mbconv12_batchnorm0_gamma) /* ty=Tensor[(1152), float32] */;
  %872 = expand_dims(%871, axis=1, num_newaxis=2) /* ty=Tensor[(1152, 1, 1), float32] */;
  %873 = negative(%efficientnet0_features_mbconv12_batchnorm0_running_mean) /* ty=Tensor[(1152), float32] */;
  %874 = multiply(%873, %871) /* ty=Tensor[(1152), float32] */;
  %875 = add(%874, %efficientnet0_features_mbconv12_batchnorm0_beta) /* ty=Tensor[(1152), float32] */;
  %876 = multiply(%861, %872) /* ty=Tensor[(1, 1152, 7, 7), float32] */;
  %877 = expand_dims(%875, axis=1, num_newaxis=2) /* ty=Tensor[(1152, 1, 1), float32] */;
  %878 = add(%876, %877) /* ty=Tensor[(1, 1152, 7, 7), float32] */;
  %879 = multiply(%878, 1f /* ty=float32 */) /* ty=Tensor[(1, 1152, 7, 7), float32] */;
  %880 = add(%866, %867) /* ty=Tensor[(1, 1152, 7, 7), float32] */;
  %881 = sigmoid(%879) /* ty=Tensor[(1, 1152, 7, 7), float32] */;
  %882 = multiply(%880, %881) /* ty=Tensor[(1, 1152, 7, 7), float32] */;
  %883 = nn.pad(%882, 0 /* ty=int32 */, pad_width=[[0, 0], [0, 0], [2, 2], [2, 2]]) /* ty=Tensor[(1, 1152, 11, 11), float32] */;
  %884 = add(%efficientnet0_features_mbconv12_batchnorm1_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(1152), float32] */;
  %885 = sqrt(%884) /* ty=Tensor[(1152), float32] */;
  %886 = divide(1f /* ty=float32 */, %885) /* ty=Tensor[(1152), float32] */;
  %887 = multiply(%886, %efficientnet0_features_mbconv12_batchnorm1_gamma) /* ty=Tensor[(1152), float32] */;
  %888 = nn.conv2d(%883, %efficientnet0_features_mbconv12_conv1_weight, padding=[0, 0, 0, 0], groups=1152, channels=1152, kernel_size=[5, 5]) /* ty=Tensor[(1, 1152, 7, 7), float32] */;
  %889 = expand_dims(%887, axis=1, num_newaxis=2) /* ty=Tensor[(1152, 1, 1), float32] */;
  %890 = negative(%efficientnet0_features_mbconv12_batchnorm1_running_mean) /* ty=Tensor[(1152), float32] */;
  %891 = multiply(%890, %887) /* ty=Tensor[(1152), float32] */;
  %892 = add(%891, %efficientnet0_features_mbconv12_batchnorm1_beta) /* ty=Tensor[(1152), float32] */;
  %893 = multiply(%888, %889) /* ty=Tensor[(1, 1152, 7, 7), float32] */;
  %894 = expand_dims(%892, axis=1, num_newaxis=2) /* ty=Tensor[(1152, 1, 1), float32] */;
  %895 = add(%efficientnet0_features_mbconv12_batchnorm1_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(1152), float32] */;
  %896 = sqrt(%895) /* ty=Tensor[(1152), float32] */;
  %897 = divide(1f /* ty=float32 */, %896) /* ty=Tensor[(1152), float32] */;
  %898 = multiply(%897, %efficientnet0_features_mbconv12_batchnorm1_gamma) /* ty=Tensor[(1152), float32] */;
  %899 = expand_dims(%898, axis=1, num_newaxis=2) /* ty=Tensor[(1152, 1, 1), float32] */;
  %900 = negative(%efficientnet0_features_mbconv12_batchnorm1_running_mean) /* ty=Tensor[(1152), float32] */;
  %901 = multiply(%900, %898) /* ty=Tensor[(1152), float32] */;
  %902 = add(%901, %efficientnet0_features_mbconv12_batchnorm1_beta) /* ty=Tensor[(1152), float32] */;
  %903 = multiply(%888, %899) /* ty=Tensor[(1, 1152, 7, 7), float32] */;
  %904 = expand_dims(%902, axis=1, num_newaxis=2) /* ty=Tensor[(1152, 1, 1), float32] */;
  %905 = add(%903, %904) /* ty=Tensor[(1, 1152, 7, 7), float32] */;
  %906 = multiply(%905, 1f /* ty=float32 */) /* ty=Tensor[(1, 1152, 7, 7), float32] */;
  %907 = add(%893, %894) /* ty=Tensor[(1, 1152, 7, 7), float32] */;
  %908 = sigmoid(%906) /* ty=Tensor[(1, 1152, 7, 7), float32] */;
  %909 = multiply(%907, %908) /* ty=Tensor[(1, 1152, 7, 7), float32] */;
  %910 = add(%efficientnet0_features_mbconv12_batchnorm2_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(192), float32] */;
  %911 = sqrt(%910) /* ty=Tensor[(192), float32] */;
  %912 = divide(1f /* ty=float32 */, %911) /* ty=Tensor[(192), float32] */;
  %913 = multiply(%912, %efficientnet0_features_mbconv12_batchnorm2_gamma) /* ty=Tensor[(192), float32] */;
  %914 = nn.conv2d(%909, %efficientnet0_features_mbconv12_conv2_weight, padding=[0, 0, 0, 0], channels=192, kernel_size=[1, 1]) /* ty=Tensor[(1, 192, 7, 7), float32] */;
  %915 = expand_dims(%913, axis=1, num_newaxis=2) /* ty=Tensor[(192, 1, 1), float32] */;
  %916 = negative(%efficientnet0_features_mbconv12_batchnorm2_running_mean) /* ty=Tensor[(192), float32] */;
  %917 = multiply(%916, %913) /* ty=Tensor[(192), float32] */;
  %918 = add(%917, %efficientnet0_features_mbconv12_batchnorm2_beta) /* ty=Tensor[(192), float32] */;
  %919 = multiply(%914, %915) /* ty=Tensor[(1, 192, 7, 7), float32] */;
  %920 = expand_dims(%918, axis=1, num_newaxis=2) /* ty=Tensor[(192, 1, 1), float32] */;
  %921 = add(%efficientnet0_features_mbconv11_batchnorm2_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(192), float32] */;
  %922 = sqrt(%921) /* ty=Tensor[(192), float32] */;
  %923 = divide(1f /* ty=float32 */, %922) /* ty=Tensor[(192), float32] */;
  %924 = multiply(%923, %efficientnet0_features_mbconv11_batchnorm2_gamma) /* ty=Tensor[(192), float32] */;
  %925 = expand_dims(%924, axis=1, num_newaxis=2) /* ty=Tensor[(192, 1, 1), float32] */;
  %926 = negative(%efficientnet0_features_mbconv11_batchnorm2_running_mean) /* ty=Tensor[(192), float32] */;
  %927 = multiply(%926, %924) /* ty=Tensor[(192), float32] */;
  %928 = add(%927, %efficientnet0_features_mbconv11_batchnorm2_beta) /* ty=Tensor[(192), float32] */;
  %929 = multiply(%849, %925) /* ty=Tensor[(1, 192, 7, 7), float32] */;
  %930 = expand_dims(%928, axis=1, num_newaxis=2) /* ty=Tensor[(192, 1, 1), float32] */;
  %931 = add(%919, %920) /* ty=Tensor[(1, 192, 7, 7), float32] */;
  %932 = add(%929, %930) /* ty=Tensor[(1, 192, 7, 7), float32] */;
  %933 = add(%931, %932) /* ty=Tensor[(1, 192, 7, 7), float32] */;
  %934 = add(%efficientnet0_features_mbconv13_batchnorm0_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(1152), float32] */;
  %935 = sqrt(%934) /* ty=Tensor[(1152), float32] */;
  %936 = divide(1f /* ty=float32 */, %935) /* ty=Tensor[(1152), float32] */;
  %937 = multiply(%936, %efficientnet0_features_mbconv13_batchnorm0_gamma) /* ty=Tensor[(1152), float32] */;
  %938 = nn.conv2d(%933, %efficientnet0_features_mbconv13_conv0_weight, padding=[0, 0, 0, 0], channels=1152, kernel_size=[1, 1]) /* ty=Tensor[(1, 1152, 7, 7), float32] */;
  %939 = expand_dims(%937, axis=1, num_newaxis=2) /* ty=Tensor[(1152, 1, 1), float32] */;
  %940 = negative(%efficientnet0_features_mbconv13_batchnorm0_running_mean) /* ty=Tensor[(1152), float32] */;
  %941 = multiply(%940, %937) /* ty=Tensor[(1152), float32] */;
  %942 = add(%941, %efficientnet0_features_mbconv13_batchnorm0_beta) /* ty=Tensor[(1152), float32] */;
  %943 = multiply(%938, %939) /* ty=Tensor[(1, 1152, 7, 7), float32] */;
  %944 = expand_dims(%942, axis=1, num_newaxis=2) /* ty=Tensor[(1152, 1, 1), float32] */;
  %945 = add(%efficientnet0_features_mbconv13_batchnorm0_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(1152), float32] */;
  %946 = sqrt(%945) /* ty=Tensor[(1152), float32] */;
  %947 = divide(1f /* ty=float32 */, %946) /* ty=Tensor[(1152), float32] */;
  %948 = multiply(%947, %efficientnet0_features_mbconv13_batchnorm0_gamma) /* ty=Tensor[(1152), float32] */;
  %949 = expand_dims(%948, axis=1, num_newaxis=2) /* ty=Tensor[(1152, 1, 1), float32] */;
  %950 = negative(%efficientnet0_features_mbconv13_batchnorm0_running_mean) /* ty=Tensor[(1152), float32] */;
  %951 = multiply(%950, %948) /* ty=Tensor[(1152), float32] */;
  %952 = add(%951, %efficientnet0_features_mbconv13_batchnorm0_beta) /* ty=Tensor[(1152), float32] */;
  %953 = multiply(%938, %949) /* ty=Tensor[(1, 1152, 7, 7), float32] */;
  %954 = expand_dims(%952, axis=1, num_newaxis=2) /* ty=Tensor[(1152, 1, 1), float32] */;
  %955 = add(%953, %954) /* ty=Tensor[(1, 1152, 7, 7), float32] */;
  %956 = multiply(%955, 1f /* ty=float32 */) /* ty=Tensor[(1, 1152, 7, 7), float32] */;
  %957 = add(%943, %944) /* ty=Tensor[(1, 1152, 7, 7), float32] */;
  %958 = sigmoid(%956) /* ty=Tensor[(1, 1152, 7, 7), float32] */;
  %959 = multiply(%957, %958) /* ty=Tensor[(1, 1152, 7, 7), float32] */;
  %960 = nn.pad(%959, 0 /* ty=int32 */, pad_width=[[0, 0], [0, 0], [2, 2], [2, 2]]) /* ty=Tensor[(1, 1152, 11, 11), float32] */;
  %961 = add(%efficientnet0_features_mbconv13_batchnorm1_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(1152), float32] */;
  %962 = sqrt(%961) /* ty=Tensor[(1152), float32] */;
  %963 = divide(1f /* ty=float32 */, %962) /* ty=Tensor[(1152), float32] */;
  %964 = multiply(%963, %efficientnet0_features_mbconv13_batchnorm1_gamma) /* ty=Tensor[(1152), float32] */;
  %965 = nn.conv2d(%960, %efficientnet0_features_mbconv13_conv1_weight, padding=[0, 0, 0, 0], groups=1152, channels=1152, kernel_size=[5, 5]) /* ty=Tensor[(1, 1152, 7, 7), float32] */;
  %966 = expand_dims(%964, axis=1, num_newaxis=2) /* ty=Tensor[(1152, 1, 1), float32] */;
  %967 = negative(%efficientnet0_features_mbconv13_batchnorm1_running_mean) /* ty=Tensor[(1152), float32] */;
  %968 = multiply(%967, %964) /* ty=Tensor[(1152), float32] */;
  %969 = add(%968, %efficientnet0_features_mbconv13_batchnorm1_beta) /* ty=Tensor[(1152), float32] */;
  %970 = multiply(%965, %966) /* ty=Tensor[(1, 1152, 7, 7), float32] */;
  %971 = expand_dims(%969, axis=1, num_newaxis=2) /* ty=Tensor[(1152, 1, 1), float32] */;
  %972 = add(%efficientnet0_features_mbconv13_batchnorm1_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(1152), float32] */;
  %973 = sqrt(%972) /* ty=Tensor[(1152), float32] */;
  %974 = divide(1f /* ty=float32 */, %973) /* ty=Tensor[(1152), float32] */;
  %975 = multiply(%974, %efficientnet0_features_mbconv13_batchnorm1_gamma) /* ty=Tensor[(1152), float32] */;
  %976 = expand_dims(%975, axis=1, num_newaxis=2) /* ty=Tensor[(1152, 1, 1), float32] */;
  %977 = negative(%efficientnet0_features_mbconv13_batchnorm1_running_mean) /* ty=Tensor[(1152), float32] */;
  %978 = multiply(%977, %975) /* ty=Tensor[(1152), float32] */;
  %979 = add(%978, %efficientnet0_features_mbconv13_batchnorm1_beta) /* ty=Tensor[(1152), float32] */;
  %980 = multiply(%965, %976) /* ty=Tensor[(1, 1152, 7, 7), float32] */;
  %981 = expand_dims(%979, axis=1, num_newaxis=2) /* ty=Tensor[(1152, 1, 1), float32] */;
  %982 = add(%980, %981) /* ty=Tensor[(1, 1152, 7, 7), float32] */;
  %983 = multiply(%982, 1f /* ty=float32 */) /* ty=Tensor[(1, 1152, 7, 7), float32] */;
  %984 = add(%970, %971) /* ty=Tensor[(1, 1152, 7, 7), float32] */;
  %985 = sigmoid(%983) /* ty=Tensor[(1, 1152, 7, 7), float32] */;
  %986 = multiply(%984, %985) /* ty=Tensor[(1, 1152, 7, 7), float32] */;
  %987 = add(%efficientnet0_features_mbconv13_batchnorm2_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(192), float32] */;
  %988 = sqrt(%987) /* ty=Tensor[(192), float32] */;
  %989 = divide(1f /* ty=float32 */, %988) /* ty=Tensor[(192), float32] */;
  %990 = multiply(%989, %efficientnet0_features_mbconv13_batchnorm2_gamma) /* ty=Tensor[(192), float32] */;
  %991 = nn.conv2d(%986, %efficientnet0_features_mbconv13_conv2_weight, padding=[0, 0, 0, 0], channels=192, kernel_size=[1, 1]) /* ty=Tensor[(1, 192, 7, 7), float32] */;
  %992 = expand_dims(%990, axis=1, num_newaxis=2) /* ty=Tensor[(192, 1, 1), float32] */;
  %993 = negative(%efficientnet0_features_mbconv13_batchnorm2_running_mean) /* ty=Tensor[(192), float32] */;
  %994 = multiply(%993, %990) /* ty=Tensor[(192), float32] */;
  %995 = add(%994, %efficientnet0_features_mbconv13_batchnorm2_beta) /* ty=Tensor[(192), float32] */;
  %996 = multiply(%991, %992) /* ty=Tensor[(1, 192, 7, 7), float32] */;
  %997 = expand_dims(%995, axis=1, num_newaxis=2) /* ty=Tensor[(192, 1, 1), float32] */;
  %998 = add(%996, %997) /* ty=Tensor[(1, 192, 7, 7), float32] */;
  %999 = add(%998, %933) /* ty=Tensor[(1, 192, 7, 7), float32] */;
  %1000 = add(%efficientnet0_features_mbconv14_batchnorm0_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(1152), float32] */;
  %1001 = sqrt(%1000) /* ty=Tensor[(1152), float32] */;
  %1002 = divide(1f /* ty=float32 */, %1001) /* ty=Tensor[(1152), float32] */;
  %1003 = multiply(%1002, %efficientnet0_features_mbconv14_batchnorm0_gamma) /* ty=Tensor[(1152), float32] */;
  %1004 = nn.conv2d(%999, %efficientnet0_features_mbconv14_conv0_weight, padding=[0, 0, 0, 0], channels=1152, kernel_size=[1, 1]) /* ty=Tensor[(1, 1152, 7, 7), float32] */;
  %1005 = expand_dims(%1003, axis=1, num_newaxis=2) /* ty=Tensor[(1152, 1, 1), float32] */;
  %1006 = negative(%efficientnet0_features_mbconv14_batchnorm0_running_mean) /* ty=Tensor[(1152), float32] */;
  %1007 = multiply(%1006, %1003) /* ty=Tensor[(1152), float32] */;
  %1008 = add(%1007, %efficientnet0_features_mbconv14_batchnorm0_beta) /* ty=Tensor[(1152), float32] */;
  %1009 = multiply(%1004, %1005) /* ty=Tensor[(1, 1152, 7, 7), float32] */;
  %1010 = expand_dims(%1008, axis=1, num_newaxis=2) /* ty=Tensor[(1152, 1, 1), float32] */;
  %1011 = add(%efficientnet0_features_mbconv14_batchnorm0_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(1152), float32] */;
  %1012 = sqrt(%1011) /* ty=Tensor[(1152), float32] */;
  %1013 = divide(1f /* ty=float32 */, %1012) /* ty=Tensor[(1152), float32] */;
  %1014 = multiply(%1013, %efficientnet0_features_mbconv14_batchnorm0_gamma) /* ty=Tensor[(1152), float32] */;
  %1015 = expand_dims(%1014, axis=1, num_newaxis=2) /* ty=Tensor[(1152, 1, 1), float32] */;
  %1016 = negative(%efficientnet0_features_mbconv14_batchnorm0_running_mean) /* ty=Tensor[(1152), float32] */;
  %1017 = multiply(%1016, %1014) /* ty=Tensor[(1152), float32] */;
  %1018 = add(%1017, %efficientnet0_features_mbconv14_batchnorm0_beta) /* ty=Tensor[(1152), float32] */;
  %1019 = multiply(%1004, %1015) /* ty=Tensor[(1, 1152, 7, 7), float32] */;
  %1020 = expand_dims(%1018, axis=1, num_newaxis=2) /* ty=Tensor[(1152, 1, 1), float32] */;
  %1021 = add(%1019, %1020) /* ty=Tensor[(1, 1152, 7, 7), float32] */;
  %1022 = multiply(%1021, 1f /* ty=float32 */) /* ty=Tensor[(1, 1152, 7, 7), float32] */;
  %1023 = add(%1009, %1010) /* ty=Tensor[(1, 1152, 7, 7), float32] */;
  %1024 = sigmoid(%1022) /* ty=Tensor[(1, 1152, 7, 7), float32] */;
  %1025 = multiply(%1023, %1024) /* ty=Tensor[(1, 1152, 7, 7), float32] */;
  %1026 = nn.pad(%1025, 0 /* ty=int32 */, pad_width=[[0, 0], [0, 0], [2, 2], [2, 2]]) /* ty=Tensor[(1, 1152, 11, 11), float32] */;
  %1027 = add(%efficientnet0_features_mbconv14_batchnorm1_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(1152), float32] */;
  %1028 = sqrt(%1027) /* ty=Tensor[(1152), float32] */;
  %1029 = divide(1f /* ty=float32 */, %1028) /* ty=Tensor[(1152), float32] */;
  %1030 = multiply(%1029, %efficientnet0_features_mbconv14_batchnorm1_gamma) /* ty=Tensor[(1152), float32] */;
  %1031 = nn.conv2d(%1026, %efficientnet0_features_mbconv14_conv1_weight, padding=[0, 0, 0, 0], groups=1152, channels=1152, kernel_size=[5, 5]) /* ty=Tensor[(1, 1152, 7, 7), float32] */;
  %1032 = expand_dims(%1030, axis=1, num_newaxis=2) /* ty=Tensor[(1152, 1, 1), float32] */;
  %1033 = negative(%efficientnet0_features_mbconv14_batchnorm1_running_mean) /* ty=Tensor[(1152), float32] */;
  %1034 = multiply(%1033, %1030) /* ty=Tensor[(1152), float32] */;
  %1035 = add(%1034, %efficientnet0_features_mbconv14_batchnorm1_beta) /* ty=Tensor[(1152), float32] */;
  %1036 = multiply(%1031, %1032) /* ty=Tensor[(1, 1152, 7, 7), float32] */;
  %1037 = expand_dims(%1035, axis=1, num_newaxis=2) /* ty=Tensor[(1152, 1, 1), float32] */;
  %1038 = add(%efficientnet0_features_mbconv14_batchnorm1_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(1152), float32] */;
  %1039 = sqrt(%1038) /* ty=Tensor[(1152), float32] */;
  %1040 = divide(1f /* ty=float32 */, %1039) /* ty=Tensor[(1152), float32] */;
  %1041 = multiply(%1040, %efficientnet0_features_mbconv14_batchnorm1_gamma) /* ty=Tensor[(1152), float32] */;
  %1042 = expand_dims(%1041, axis=1, num_newaxis=2) /* ty=Tensor[(1152, 1, 1), float32] */;
  %1043 = negative(%efficientnet0_features_mbconv14_batchnorm1_running_mean) /* ty=Tensor[(1152), float32] */;
  %1044 = multiply(%1043, %1041) /* ty=Tensor[(1152), float32] */;
  %1045 = add(%1044, %efficientnet0_features_mbconv14_batchnorm1_beta) /* ty=Tensor[(1152), float32] */;
  %1046 = multiply(%1031, %1042) /* ty=Tensor[(1, 1152, 7, 7), float32] */;
  %1047 = expand_dims(%1045, axis=1, num_newaxis=2) /* ty=Tensor[(1152, 1, 1), float32] */;
  %1048 = add(%1046, %1047) /* ty=Tensor[(1, 1152, 7, 7), float32] */;
  %1049 = multiply(%1048, 1f /* ty=float32 */) /* ty=Tensor[(1, 1152, 7, 7), float32] */;
  %1050 = add(%1036, %1037) /* ty=Tensor[(1, 1152, 7, 7), float32] */;
  %1051 = sigmoid(%1049) /* ty=Tensor[(1, 1152, 7, 7), float32] */;
  %1052 = multiply(%1050, %1051) /* ty=Tensor[(1, 1152, 7, 7), float32] */;
  %1053 = add(%efficientnet0_features_mbconv14_batchnorm2_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(192), float32] */;
  %1054 = sqrt(%1053) /* ty=Tensor[(192), float32] */;
  %1055 = divide(1f /* ty=float32 */, %1054) /* ty=Tensor[(192), float32] */;
  %1056 = multiply(%1055, %efficientnet0_features_mbconv14_batchnorm2_gamma) /* ty=Tensor[(192), float32] */;
  %1057 = nn.conv2d(%1052, %efficientnet0_features_mbconv14_conv2_weight, padding=[0, 0, 0, 0], channels=192, kernel_size=[1, 1]) /* ty=Tensor[(1, 192, 7, 7), float32] */;
  %1058 = expand_dims(%1056, axis=1, num_newaxis=2) /* ty=Tensor[(192, 1, 1), float32] */;
  %1059 = negative(%efficientnet0_features_mbconv14_batchnorm2_running_mean) /* ty=Tensor[(192), float32] */;
  %1060 = multiply(%1059, %1056) /* ty=Tensor[(192), float32] */;
  %1061 = add(%1060, %efficientnet0_features_mbconv14_batchnorm2_beta) /* ty=Tensor[(192), float32] */;
  %1062 = multiply(%1057, %1058) /* ty=Tensor[(1, 192, 7, 7), float32] */;
  %1063 = expand_dims(%1061, axis=1, num_newaxis=2) /* ty=Tensor[(192, 1, 1), float32] */;
  %1064 = add(%1062, %1063) /* ty=Tensor[(1, 192, 7, 7), float32] */;
  %1065 = add(%1064, %999) /* ty=Tensor[(1, 192, 7, 7), float32] */;
  %1066 = add(%efficientnet0_features_mbconv15_batchnorm0_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(1152), float32] */;
  %1067 = sqrt(%1066) /* ty=Tensor[(1152), float32] */;
  %1068 = divide(1f /* ty=float32 */, %1067) /* ty=Tensor[(1152), float32] */;
  %1069 = multiply(%1068, %efficientnet0_features_mbconv15_batchnorm0_gamma) /* ty=Tensor[(1152), float32] */;
  %1070 = nn.conv2d(%1065, %efficientnet0_features_mbconv15_conv0_weight, padding=[0, 0, 0, 0], channels=1152, kernel_size=[1, 1]) /* ty=Tensor[(1, 1152, 7, 7), float32] */;
  %1071 = expand_dims(%1069, axis=1, num_newaxis=2) /* ty=Tensor[(1152, 1, 1), float32] */;
  %1072 = negative(%efficientnet0_features_mbconv15_batchnorm0_running_mean) /* ty=Tensor[(1152), float32] */;
  %1073 = multiply(%1072, %1069) /* ty=Tensor[(1152), float32] */;
  %1074 = add(%1073, %efficientnet0_features_mbconv15_batchnorm0_beta) /* ty=Tensor[(1152), float32] */;
  %1075 = multiply(%1070, %1071) /* ty=Tensor[(1, 1152, 7, 7), float32] */;
  %1076 = expand_dims(%1074, axis=1, num_newaxis=2) /* ty=Tensor[(1152, 1, 1), float32] */;
  %1077 = add(%efficientnet0_features_mbconv15_batchnorm0_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(1152), float32] */;
  %1078 = sqrt(%1077) /* ty=Tensor[(1152), float32] */;
  %1079 = divide(1f /* ty=float32 */, %1078) /* ty=Tensor[(1152), float32] */;
  %1080 = multiply(%1079, %efficientnet0_features_mbconv15_batchnorm0_gamma) /* ty=Tensor[(1152), float32] */;
  %1081 = expand_dims(%1080, axis=1, num_newaxis=2) /* ty=Tensor[(1152, 1, 1), float32] */;
  %1082 = negative(%efficientnet0_features_mbconv15_batchnorm0_running_mean) /* ty=Tensor[(1152), float32] */;
  %1083 = multiply(%1082, %1080) /* ty=Tensor[(1152), float32] */;
  %1084 = add(%1083, %efficientnet0_features_mbconv15_batchnorm0_beta) /* ty=Tensor[(1152), float32] */;
  %1085 = multiply(%1070, %1081) /* ty=Tensor[(1, 1152, 7, 7), float32] */;
  %1086 = expand_dims(%1084, axis=1, num_newaxis=2) /* ty=Tensor[(1152, 1, 1), float32] */;
  %1087 = add(%1085, %1086) /* ty=Tensor[(1, 1152, 7, 7), float32] */;
  %1088 = multiply(%1087, 1f /* ty=float32 */) /* ty=Tensor[(1, 1152, 7, 7), float32] */;
  %1089 = add(%1075, %1076) /* ty=Tensor[(1, 1152, 7, 7), float32] */;
  %1090 = sigmoid(%1088) /* ty=Tensor[(1, 1152, 7, 7), float32] */;
  %1091 = multiply(%1089, %1090) /* ty=Tensor[(1, 1152, 7, 7), float32] */;
  %1092 = nn.pad(%1091, 0 /* ty=int32 */, pad_width=[[0, 0], [0, 0], [1, 1], [1, 1]]) /* ty=Tensor[(1, 1152, 9, 9), float32] */;
  %1093 = add(%efficientnet0_features_mbconv15_batchnorm1_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(1152), float32] */;
  %1094 = sqrt(%1093) /* ty=Tensor[(1152), float32] */;
  %1095 = divide(1f /* ty=float32 */, %1094) /* ty=Tensor[(1152), float32] */;
  %1096 = multiply(%1095, %efficientnet0_features_mbconv15_batchnorm1_gamma) /* ty=Tensor[(1152), float32] */;
  %1097 = nn.conv2d(%1092, %efficientnet0_features_mbconv15_conv1_weight, padding=[0, 0, 0, 0], groups=1152, channels=1152, kernel_size=[3, 3]) /* ty=Tensor[(1, 1152, 7, 7), float32] */;
  %1098 = expand_dims(%1096, axis=1, num_newaxis=2) /* ty=Tensor[(1152, 1, 1), float32] */;
  %1099 = negative(%efficientnet0_features_mbconv15_batchnorm1_running_mean) /* ty=Tensor[(1152), float32] */;
  %1100 = multiply(%1099, %1096) /* ty=Tensor[(1152), float32] */;
  %1101 = add(%1100, %efficientnet0_features_mbconv15_batchnorm1_beta) /* ty=Tensor[(1152), float32] */;
  %1102 = multiply(%1097, %1098) /* ty=Tensor[(1, 1152, 7, 7), float32] */;
  %1103 = expand_dims(%1101, axis=1, num_newaxis=2) /* ty=Tensor[(1152, 1, 1), float32] */;
  %1104 = add(%efficientnet0_features_mbconv15_batchnorm1_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(1152), float32] */;
  %1105 = sqrt(%1104) /* ty=Tensor[(1152), float32] */;
  %1106 = divide(1f /* ty=float32 */, %1105) /* ty=Tensor[(1152), float32] */;
  %1107 = multiply(%1106, %efficientnet0_features_mbconv15_batchnorm1_gamma) /* ty=Tensor[(1152), float32] */;
  %1108 = expand_dims(%1107, axis=1, num_newaxis=2) /* ty=Tensor[(1152, 1, 1), float32] */;
  %1109 = negative(%efficientnet0_features_mbconv15_batchnorm1_running_mean) /* ty=Tensor[(1152), float32] */;
  %1110 = multiply(%1109, %1107) /* ty=Tensor[(1152), float32] */;
  %1111 = add(%1110, %efficientnet0_features_mbconv15_batchnorm1_beta) /* ty=Tensor[(1152), float32] */;
  %1112 = multiply(%1097, %1108) /* ty=Tensor[(1, 1152, 7, 7), float32] */;
  %1113 = expand_dims(%1111, axis=1, num_newaxis=2) /* ty=Tensor[(1152, 1, 1), float32] */;
  %1114 = add(%1112, %1113) /* ty=Tensor[(1, 1152, 7, 7), float32] */;
  %1115 = multiply(%1114, 1f /* ty=float32 */) /* ty=Tensor[(1, 1152, 7, 7), float32] */;
  %1116 = add(%1102, %1103) /* ty=Tensor[(1, 1152, 7, 7), float32] */;
  %1117 = sigmoid(%1115) /* ty=Tensor[(1, 1152, 7, 7), float32] */;
  %1118 = multiply(%1116, %1117) /* ty=Tensor[(1, 1152, 7, 7), float32] */;
  %1119 = add(%efficientnet0_features_mbconv15_batchnorm2_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(320), float32] */;
  %1120 = sqrt(%1119) /* ty=Tensor[(320), float32] */;
  %1121 = divide(1f /* ty=float32 */, %1120) /* ty=Tensor[(320), float32] */;
  %1122 = multiply(%1121, %efficientnet0_features_mbconv15_batchnorm2_gamma) /* ty=Tensor[(320), float32] */;
  %1123 = nn.conv2d(%1118, %efficientnet0_features_mbconv15_conv2_weight, padding=[0, 0, 0, 0], channels=320, kernel_size=[1, 1]) /* ty=Tensor[(1, 320, 7, 7), float32] */;
  %1124 = expand_dims(%1122, axis=1, num_newaxis=2) /* ty=Tensor[(320, 1, 1), float32] */;
  %1125 = negative(%efficientnet0_features_mbconv15_batchnorm2_running_mean) /* ty=Tensor[(320), float32] */;
  %1126 = multiply(%1125, %1122) /* ty=Tensor[(320), float32] */;
  %1127 = add(%1126, %efficientnet0_features_mbconv15_batchnorm2_beta) /* ty=Tensor[(320), float32] */;
  %1128 = multiply(%1123, %1124) /* ty=Tensor[(1, 320, 7, 7), float32] */;
  %1129 = expand_dims(%1127, axis=1, num_newaxis=2) /* ty=Tensor[(320, 1, 1), float32] */;
  %1130 = add(%1128, %1129) /* ty=Tensor[(1, 320, 7, 7), float32] */;
  %1131 = add(%efficientnet0_features_batchnorm1_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(1280), float32] */;
  %1132 = sqrt(%1131) /* ty=Tensor[(1280), float32] */;
  %1133 = divide(1f /* ty=float32 */, %1132) /* ty=Tensor[(1280), float32] */;
  %1134 = multiply(%1133, %efficientnet0_features_batchnorm1_gamma) /* ty=Tensor[(1280), float32] */;
  %1135 = nn.conv2d(%1130, %efficientnet0_features_conv1_weight, padding=[0, 0, 0, 0], channels=1280, kernel_size=[1, 1]) /* ty=Tensor[(1, 1280, 7, 7), float32] */;
  %1136 = expand_dims(%1134, axis=1, num_newaxis=2) /* ty=Tensor[(1280, 1, 1), float32] */;
  %1137 = negative(%efficientnet0_features_batchnorm1_running_mean) /* ty=Tensor[(1280), float32] */;
  %1138 = multiply(%1137, %1134) /* ty=Tensor[(1280), float32] */;
  %1139 = add(%1138, %efficientnet0_features_batchnorm1_beta) /* ty=Tensor[(1280), float32] */;
  %1140 = multiply(%1135, %1136) /* ty=Tensor[(1, 1280, 7, 7), float32] */;
  %1141 = expand_dims(%1139, axis=1, num_newaxis=2) /* ty=Tensor[(1280, 1, 1), float32] */;
  %1142 = add(%efficientnet0_features_batchnorm1_running_var, 0.001f /* ty=float32 */) /* ty=Tensor[(1280), float32] */;
  %1143 = sqrt(%1142) /* ty=Tensor[(1280), float32] */;
  %1144 = divide(1f /* ty=float32 */, %1143) /* ty=Tensor[(1280), float32] */;
  %1145 = multiply(%1144, %efficientnet0_features_batchnorm1_gamma) /* ty=Tensor[(1280), float32] */;
  %1146 = expand_dims(%1145, axis=1, num_newaxis=2) /* ty=Tensor[(1280, 1, 1), float32] */;
  %1147 = negative(%efficientnet0_features_batchnorm1_running_mean) /* ty=Tensor[(1280), float32] */;
  %1148 = multiply(%1147, %1145) /* ty=Tensor[(1280), float32] */;
  %1149 = add(%1148, %efficientnet0_features_batchnorm1_beta) /* ty=Tensor[(1280), float32] */;
  %1150 = multiply(%1135, %1146) /* ty=Tensor[(1, 1280, 7, 7), float32] */;
  %1151 = expand_dims(%1149, axis=1, num_newaxis=2) /* ty=Tensor[(1280, 1, 1), float32] */;
  %1152 = add(%1150, %1151) /* ty=Tensor[(1, 1280, 7, 7), float32] */;
  %1153 = multiply(%1152, 1f /* ty=float32 */) /* ty=Tensor[(1, 1280, 7, 7), float32] */;
  %1154 = add(%1140, %1141) /* ty=Tensor[(1, 1280, 7, 7), float32] */;
  %1155 = sigmoid(%1153) /* ty=Tensor[(1, 1280, 7, 7), float32] */;
  %1156 = multiply(%1154, %1155) /* ty=Tensor[(1, 1280, 7, 7), float32] */;
  %1157 = nn.global_avg_pool2d(%1156) /* ty=Tensor[(1, 1280, 1, 1), float32] */;
  %1158 = nn.conv2d(%1157, %efficientnet0_output_pred_weight, padding=[0, 0, 0, 0], channels=1000, kernel_size=[1, 1]) /* ty=Tensor[(1, 1000, 1, 1), float32] */;
  nn.batch_flatten(%1158) /* ty=Tensor[(1, 1000), float32] */
}
